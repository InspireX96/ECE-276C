{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 276C HW3 P2\n",
    "Mingwei Xu A53270271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gym\n",
    "import pybulletgym.envs\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cuda\n",
      "GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "# setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device :', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Policy Network using MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        :param env: object, gym environment\n",
    "        \"\"\"\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        # get state space and action space dimension\n",
    "        self.state_space_n = env.observation_space.shape[0] - 1   # should be 8 (TODO: bug in env showing wrong observation space?)\n",
    "        self.action_space_n = env.action_space.shape[0]   # should be 2\n",
    "\n",
    "        # define layers\n",
    "        self.l1 = nn.Linear(self.state_space_n, 128)\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.l3 = nn.Linear(64, self.action_space_n)\n",
    "\n",
    "        self.sigma = nn.Parameter(torch.eye(2))     # initalize cov matrix with grad fn\n",
    "#         self.sigma = nn.Parameter(torch.diag(torch.rand(2)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Feed forward\n",
    "        \n",
    "        :param x: np array, state\n",
    "        :return: tensor, softmax probability of action\n",
    "        \"\"\"\n",
    "        # TODO: take sigma as input\n",
    "        # build neural network\n",
    "        network = nn.Sequential(\n",
    "            self.l1,\n",
    "            nn.Tanh(),\n",
    "            self.l2,\n",
    "            nn.Tanh(),\n",
    "            self.l3,\n",
    "            nn.Tanh())\n",
    "\n",
    "        return network(torch.FloatTensor(x).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(policy_network, state):\n",
    "    \"\"\"\n",
    "    Choose action according to policy on given state\n",
    "\n",
    "    :param policy_network: object, policy network\n",
    "    :param state: np array, state\n",
    "    :returns: list (len=2), action; tensor with grad fn, log probability\n",
    "    \"\"\"\n",
    "    probs = policy_network.forward(state)   # mean from policy network output\n",
    "\n",
    "    cov = torch.abs(policy_network.sigma) + 1e-3    # positive definite\n",
    "\n",
    "    m = MultivariateNormal(probs, cov)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.tolist(), log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(env, policy_network, batch_size=500, num_episodes=200, lr=0.01, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Policy gradient training using reinforce method\n",
    "\n",
    "    :param env: object, gym environment\n",
    "    :param policy_network: object, policy network\n",
    "    :param batch_size: int, batch size\n",
    "    :param num_episodes: int, number of episodes\n",
    "    :param lr: float, learning rate\n",
    "    :param gamma: float (0~1), discount factor\n",
    "    :return: list of average reward on each episode\n",
    "    \"\"\"\n",
    "    # setup place holders\n",
    "    average_reward_list = []  # store step over episode\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(policy_network.parameters(), \n",
    "                           lr=lr)\n",
    "\n",
    "    # train\n",
    "    for i in range(num_episodes):\n",
    "        # setup placeholders for each batch\n",
    "        batch_loss_sum = 0\n",
    "        batch_traj_counter = 0\n",
    "        batch_rewards = []\n",
    "\n",
    "        # setup placeholders for each trajectory\n",
    "        traj_rewards = []\n",
    "        traj_log_prob_sum = 0\n",
    "\n",
    "        # reset environment\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        # batch\n",
    "        for step in range(batch_size):\n",
    "            # exploration\n",
    "            action, log_prob = choose_action(policy_network, state)\n",
    "            state_next, reward, done, _ = env.step(action)\n",
    "            # env.render()\n",
    "\n",
    "            # store data\n",
    "            traj_rewards.append(reward)\n",
    "            traj_log_prob_sum += log_prob\n",
    "\n",
    "            # move on\n",
    "            if done or (step == batch_size - 1):\n",
    "                # trajectory or batch finished, update trajectory\n",
    "                traj_discounted_return = torch.sum(torch.FloatTensor(traj_rewards).to(device) *\n",
    "                                                   torch.FloatTensor([gamma ** t for t in range(1, len(traj_rewards) + 1)]).to(device))  # G(t)\n",
    "                batch_loss_sum += traj_discounted_return * traj_log_prob_sum\n",
    "                \n",
    "                # reset state\n",
    "                batch_rewards.append(np.sum(traj_rewards))\n",
    "                batch_traj_counter += 1\n",
    "\n",
    "                traj_rewards = []\n",
    "                traj_log_prob_sum = 0\n",
    "\n",
    "                state = env.reset()\n",
    "            else:\n",
    "                state = state_next\n",
    "\n",
    "        # finish batch\n",
    "        average_batch_reward = np.mean(batch_rewards)\n",
    "        average_reward_list.append(average_batch_reward)\n",
    "        loss = - batch_loss_sum / batch_traj_counter\n",
    "        \n",
    "        print('Episode [{}/{}] loss: {:.2f}, average reward: {:.2f}, trajectory num: {}'.format(i + 1, num_episodes,\n",
    "                               loss.item(), average_batch_reward, batch_traj_counter))\n",
    "\n",
    "        # update policy\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return average_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_with_baseline(env, policy_network, batch_size=500, num_episodes=200, lr=0.01, gamma=0.99, enable_baseline=False):\n",
    "    \"\"\"\n",
    "    Policy gradient training using modified reinforce method with baseline\n",
    "\n",
    "    :param env: object, gym environment\n",
    "    :param policy_network: object, policy network\n",
    "    :param batch_size: int, batch size\n",
    "    :param num_episodes: int, number of episodes\n",
    "    :param lr: float, learning rate\n",
    "    :param gamma: float (0~1), discount factor\n",
    "    :param enable_baseline: bool, flag to enable baseline, defaults to False\n",
    "    :return: list of average reward on each episode\n",
    "    \"\"\"\n",
    "    # setup place holders\n",
    "    average_reward_list = []  # store step over episode\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(policy_network.parameters(), \n",
    "                           lr=lr)\n",
    "\n",
    "    # train\n",
    "    for i in range(num_episodes):\n",
    "        # setup placeholders for each batch\n",
    "        batch_loss_sum = 0\n",
    "        batch_traj_counter = 0\n",
    "        batch_rewards = []\n",
    "\n",
    "        # setup placeholders for each trajectory\n",
    "        traj_loss_sum = 0\n",
    "        traj_rewards = []\n",
    "        traj_log_prob_list = []\n",
    "\n",
    "        # reset environment\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        # batch\n",
    "        for step in range(batch_size):\n",
    "            # exploration\n",
    "            action, log_prob = choose_action(policy_network, state)\n",
    "            state_next, reward, done, _ = env.step(action)\n",
    "            # env.render()\n",
    "\n",
    "            # store data\n",
    "            traj_rewards.append(reward)\n",
    "            traj_log_prob_list.append(log_prob)\n",
    "\n",
    "            # move on\n",
    "            if done or (step == batch_size - 1):\n",
    "                # trajectory or batch finished, update trajectory\n",
    "                discounted_return_list = []\n",
    "                discounted_return_list = [sum([gamma ** (t_prime - t) * traj_rewards[t_prime] for t_prime in range(t, len(traj_rewards))]) \\\n",
    "                                          for t in range(len(traj_rewards))]    # TODO\n",
    "                if enable_baseline:\n",
    "                    # substract discounted return list by its mean\n",
    "                    discounted_return_list = np.array(discounted_return_list) - np.mean(discounted_return_list)\n",
    "#                 for t in range(len(traj_rewards)):\n",
    "#                     print(traj_rewards)\n",
    "#                     assert False\n",
    "#                     discounted_return_sum = sum([gamma ** (t_prime - t) * traj_rewards[t_prime] for t_prime in range(len(traj_rewards))])\n",
    "#                     discounted_return_list.append(discounted_return_sum)\n",
    "\n",
    "                # sum the traj loss by loop so we do not lose tensor gradient\n",
    "                traj_loss_sum = 0\n",
    "                for t in range(len(traj_log_prob_list)):\n",
    "                    traj_loss_sum += traj_log_prob_list[t] * discounted_return_list[t]\n",
    "                batch_loss_sum += traj_loss_sum\n",
    "                \n",
    "                # reset state\n",
    "                batch_rewards.append(np.sum(traj_rewards))\n",
    "                batch_traj_counter += 1\n",
    "\n",
    "                traj_loss_sum = 0\n",
    "                traj_rewards = []\n",
    "                traj_log_prob_list = []\n",
    "\n",
    "                state = env.reset()\n",
    "            else:\n",
    "                state = state_next\n",
    "\n",
    "        # finish batch\n",
    "        average_batch_reward = np.mean(batch_rewards)\n",
    "        average_reward_list.append(average_batch_reward)\n",
    "        loss = - batch_loss_sum / batch_traj_counter    # TODO\n",
    "        if enable_baseline:\n",
    "            loss = - loss\n",
    "        \n",
    "        print('TODO: sigma: ', policy_network.sigma)    # TODO\n",
    "        print('Episode [{}/{}] loss: {:.2f}, average reward: {:.2f}, trajectory num: {}'.format(i + 1, num_episodes,\n",
    "                               loss.item(), average_batch_reward, batch_traj_counter))\n",
    "\n",
    "        # update policy\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return average_reward_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/home/cvv5233/anaconda3/lib/python3.7/site-packages/pybullet_envs/bullet\n",
      "options= \n",
      "[ 0.3928371   0.3928371  -0.68091764  0.26561381  0.5         0.\n",
      "  0.08333333  0.        ]\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.]], device='cuda:0', requires_grad=True)\n",
      "Episode [1/500] loss: 25.59, average reward: -53.58, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0100, 0.0000],\n",
      "        [0.0000, 1.0100]], device='cuda:0', requires_grad=True)\n",
      "Episode [2/500] loss: 21.91, average reward: -69.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0199, 0.0000],\n",
      "        [0.0000, 1.0200]], device='cuda:0', requires_grad=True)\n",
      "Episode [3/500] loss: 20.27, average reward: -69.82, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0296, 0.0000],\n",
      "        [0.0000, 1.0300]], device='cuda:0', requires_grad=True)\n",
      "Episode [4/500] loss: 28.32, average reward: -81.38, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0390, 0.0000],\n",
      "        [0.0000, 1.0397]], device='cuda:0', requires_grad=True)\n",
      "Episode [5/500] loss: 34.98, average reward: -83.90, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0486, 0.0000],\n",
      "        [0.0000, 1.0495]], device='cuda:0', requires_grad=True)\n",
      "Episode [6/500] loss: 29.56, average reward: -78.92, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0583, 0.0000],\n",
      "        [0.0000, 1.0593]], device='cuda:0', requires_grad=True)\n",
      "Episode [7/500] loss: 31.52, average reward: -85.03, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0683, 0.0000],\n",
      "        [0.0000, 1.0690]], device='cuda:0', requires_grad=True)\n",
      "Episode [8/500] loss: 32.78, average reward: -87.48, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0783, 0.0000],\n",
      "        [0.0000, 1.0787]], device='cuda:0', requires_grad=True)\n",
      "Episode [9/500] loss: 35.27, average reward: -86.10, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0884, 0.0000],\n",
      "        [0.0000, 1.0884]], device='cuda:0', requires_grad=True)\n",
      "Episode [10/500] loss: 33.82, average reward: -80.23, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.0985, 0.0000],\n",
      "        [0.0000, 1.0983]], device='cuda:0', requires_grad=True)\n",
      "Episode [11/500] loss: 27.17, average reward: -87.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1085, 0.0000],\n",
      "        [0.0000, 1.1081]], device='cuda:0', requires_grad=True)\n",
      "Episode [12/500] loss: 28.19, average reward: -89.61, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1184, 0.0000],\n",
      "        [0.0000, 1.1179]], device='cuda:0', requires_grad=True)\n",
      "Episode [13/500] loss: 24.75, average reward: -83.61, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1282, 0.0000],\n",
      "        [0.0000, 1.1274]], device='cuda:0', requires_grad=True)\n",
      "Episode [14/500] loss: 14.78, average reward: -82.64, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1375, 0.0000],\n",
      "        [0.0000, 1.1368]], device='cuda:0', requires_grad=True)\n",
      "Episode [15/500] loss: 27.33, average reward: -90.82, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1468, 0.0000],\n",
      "        [0.0000, 1.1461]], device='cuda:0', requires_grad=True)\n",
      "Episode [16/500] loss: 25.89, average reward: -91.76, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1559, 0.0000],\n",
      "        [0.0000, 1.1556]], device='cuda:0', requires_grad=True)\n",
      "Episode [17/500] loss: 30.22, average reward: -86.69, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1651, 0.0000],\n",
      "        [0.0000, 1.1650]], device='cuda:0', requires_grad=True)\n",
      "Episode [18/500] loss: 27.38, average reward: -86.10, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1743, 0.0000],\n",
      "        [0.0000, 1.1745]], device='cuda:0', requires_grad=True)\n",
      "Episode [19/500] loss: 40.06, average reward: -93.60, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1839, 0.0000],\n",
      "        [0.0000, 1.1841]], device='cuda:0', requires_grad=True)\n",
      "Episode [20/500] loss: 31.43, average reward: -93.41, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1935, 0.0000],\n",
      "        [0.0000, 1.1937]], device='cuda:0', requires_grad=True)\n",
      "Episode [21/500] loss: 29.76, average reward: -91.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2030, 0.0000],\n",
      "        [0.0000, 1.2034]], device='cuda:0', requires_grad=True)\n",
      "Episode [22/500] loss: 28.80, average reward: -94.27, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2123, 0.0000],\n",
      "        [0.0000, 1.2132]], device='cuda:0', requires_grad=True)\n",
      "Episode [23/500] loss: 35.53, average reward: -86.32, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2217, 0.0000],\n",
      "        [0.0000, 1.2231]], device='cuda:0', requires_grad=True)\n",
      "Episode [24/500] loss: 30.23, average reward: -93.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2311, 0.0000],\n",
      "        [0.0000, 1.2330]], device='cuda:0', requires_grad=True)\n",
      "Episode [25/500] loss: 31.66, average reward: -94.10, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2405, 0.0000],\n",
      "        [0.0000, 1.2430]], device='cuda:0', requires_grad=True)\n",
      "Episode [26/500] loss: 27.36, average reward: -92.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2500, 0.0000],\n",
      "        [0.0000, 1.2525]], device='cuda:0', requires_grad=True)\n",
      "Episode [27/500] loss: 34.48, average reward: -94.73, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2594, 0.0000],\n",
      "        [0.0000, 1.2623]], device='cuda:0', requires_grad=True)\n",
      "Episode [28/500] loss: 27.17, average reward: -86.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2685, 0.0000],\n",
      "        [0.0000, 1.2721]], device='cuda:0', requires_grad=True)\n",
      "Episode [29/500] loss: 43.99, average reward: -94.90, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2780, 0.0000],\n",
      "        [0.0000, 1.2821]], device='cuda:0', requires_grad=True)\n",
      "Episode [30/500] loss: 33.02, average reward: -87.72, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2875, 0.0000],\n",
      "        [0.0000, 1.2921]], device='cuda:0', requires_grad=True)\n",
      "Episode [31/500] loss: 37.71, average reward: -94.99, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2971, 0.0000],\n",
      "        [0.0000, 1.3021]], device='cuda:0', requires_grad=True)\n",
      "Episode [32/500] loss: 41.10, average reward: -95.88, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3071, 0.0000],\n",
      "        [0.0000, 1.3120]], device='cuda:0', requires_grad=True)\n",
      "Episode [33/500] loss: 42.55, average reward: -90.87, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3172, 0.0000],\n",
      "        [0.0000, 1.3221]], device='cuda:0', requires_grad=True)\n",
      "Episode [34/500] loss: 35.27, average reward: -83.75, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3272, 0.0000],\n",
      "        [0.0000, 1.3323]], device='cuda:0', requires_grad=True)\n",
      "Episode [35/500] loss: 32.74, average reward: -89.17, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3372, 0.0000],\n",
      "        [0.0000, 1.3422]], device='cuda:0', requires_grad=True)\n",
      "Episode [36/500] loss: 34.22, average reward: -94.60, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3472, 0.0000],\n",
      "        [0.0000, 1.3521]], device='cuda:0', requires_grad=True)\n",
      "Episode [37/500] loss: 40.90, average reward: -97.33, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3572, 0.0000],\n",
      "        [0.0000, 1.3621]], device='cuda:0', requires_grad=True)\n",
      "Episode [38/500] loss: 44.15, average reward: -95.10, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3675, 0.0000],\n",
      "        [0.0000, 1.3722]], device='cuda:0', requires_grad=True)\n",
      "Episode [39/500] loss: 38.46, average reward: -97.68, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3776, 0.0000],\n",
      "        [0.0000, 1.3823]], device='cuda:0', requires_grad=True)\n",
      "Episode [40/500] loss: 30.01, average reward: -96.79, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3878, 0.0000],\n",
      "        [0.0000, 1.3921]], device='cuda:0', requires_grad=True)\n",
      "Episode [41/500] loss: 37.94, average reward: -98.61, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3979, 0.0000],\n",
      "        [0.0000, 1.4019]], device='cuda:0', requires_grad=True)\n",
      "Episode [42/500] loss: 36.98, average reward: -91.93, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4078, 0.0000],\n",
      "        [0.0000, 1.4118]], device='cuda:0', requires_grad=True)\n",
      "Episode [43/500] loss: 27.18, average reward: -98.06, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4174, 0.0000],\n",
      "        [0.0000, 1.4216]], device='cuda:0', requires_grad=True)\n",
      "Episode [44/500] loss: 43.84, average reward: -100.06, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4273, 0.0000],\n",
      "        [0.0000, 1.4313]], device='cuda:0', requires_grad=True)\n",
      "Episode [45/500] loss: 38.14, average reward: -93.05, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4374, 0.0000],\n",
      "        [0.0000, 1.4409]], device='cuda:0', requires_grad=True)\n",
      "Episode [46/500] loss: 35.69, average reward: -92.27, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4473, 0.0000],\n",
      "        [0.0000, 1.4505]], device='cuda:0', requires_grad=True)\n",
      "Episode [47/500] loss: 39.95, average reward: -100.24, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4571, 0.0000],\n",
      "        [0.0000, 1.4603]], device='cuda:0', requires_grad=True)\n",
      "Episode [48/500] loss: 42.71, average reward: -94.30, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4669, 0.0000],\n",
      "        [0.0000, 1.4702]], device='cuda:0', requires_grad=True)\n",
      "Episode [49/500] loss: 31.72, average reward: -98.06, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4768, 0.0000],\n",
      "        [0.0000, 1.4798]], device='cuda:0', requires_grad=True)\n",
      "Episode [50/500] loss: 47.58, average reward: -100.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4869, 0.0000],\n",
      "        [0.0000, 1.4894]], device='cuda:0', requires_grad=True)\n",
      "Episode [51/500] loss: 36.22, average reward: -101.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4970, 0.0000],\n",
      "        [0.0000, 1.4989]], device='cuda:0', requires_grad=True)\n",
      "Episode [52/500] loss: 45.21, average reward: -93.94, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5071, 0.0000],\n",
      "        [0.0000, 1.5086]], device='cuda:0', requires_grad=True)\n",
      "Episode [53/500] loss: 44.04, average reward: -95.02, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5171, 0.0000],\n",
      "        [0.0000, 1.5185]], device='cuda:0', requires_grad=True)\n",
      "Episode [54/500] loss: 30.69, average reward: -87.27, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5270, 0.0000],\n",
      "        [0.0000, 1.5282]], device='cuda:0', requires_grad=True)\n",
      "Episode [55/500] loss: 47.06, average reward: -98.12, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5369, 0.0000],\n",
      "        [0.0000, 1.5380]], device='cuda:0', requires_grad=True)\n",
      "Episode [56/500] loss: 38.23, average reward: -101.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5468, 0.0000],\n",
      "        [0.0000, 1.5477]], device='cuda:0', requires_grad=True)\n",
      "Episode [57/500] loss: 40.22, average reward: -95.77, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5567, 0.0000],\n",
      "        [0.0000, 1.5574]], device='cuda:0', requires_grad=True)\n",
      "Episode [58/500] loss: 39.70, average reward: -97.71, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5666, 0.0000],\n",
      "        [0.0000, 1.5670]], device='cuda:0', requires_grad=True)\n",
      "Episode [59/500] loss: 34.37, average reward: -103.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5764, 0.0000],\n",
      "        [0.0000, 1.5764]], device='cuda:0', requires_grad=True)\n",
      "Episode [60/500] loss: 37.04, average reward: -103.18, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5861, 0.0000],\n",
      "        [0.0000, 1.5859]], device='cuda:0', requires_grad=True)\n",
      "Episode [61/500] loss: 44.41, average reward: -94.92, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5958, 0.0000],\n",
      "        [0.0000, 1.5954]], device='cuda:0', requires_grad=True)\n",
      "Episode [62/500] loss: 49.98, average reward: -105.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6056, 0.0000],\n",
      "        [0.0000, 1.6051]], device='cuda:0', requires_grad=True)\n",
      "Episode [63/500] loss: 34.22, average reward: -96.98, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6153, 0.0000],\n",
      "        [0.0000, 1.6146]], device='cuda:0', requires_grad=True)\n",
      "Episode [64/500] loss: 46.36, average reward: -96.11, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6251, 0.0000],\n",
      "        [0.0000, 1.6242]], device='cuda:0', requires_grad=True)\n",
      "Episode [65/500] loss: 38.57, average reward: -97.74, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6347, 0.0000],\n",
      "        [0.0000, 1.6339]], device='cuda:0', requires_grad=True)\n",
      "Episode [66/500] loss: 49.42, average reward: -104.46, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6444, 0.0000],\n",
      "        [0.0000, 1.6437]], device='cuda:0', requires_grad=True)\n",
      "Episode [67/500] loss: 40.88, average reward: -104.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6540, 0.0000],\n",
      "        [0.0000, 1.6535]], device='cuda:0', requires_grad=True)\n",
      "Episode [68/500] loss: 51.40, average reward: -100.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6639, 0.0000],\n",
      "        [0.0000, 1.6633]], device='cuda:0', requires_grad=True)\n",
      "Episode [69/500] loss: 40.21, average reward: -100.04, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6737, 0.0000],\n",
      "        [0.0000, 1.6731]], device='cuda:0', requires_grad=True)\n",
      "Episode [70/500] loss: 40.92, average reward: -105.47, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6834, 0.0000],\n",
      "        [0.0000, 1.6828]], device='cuda:0', requires_grad=True)\n",
      "Episode [71/500] loss: 42.59, average reward: -104.29, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6931, 0.0000],\n",
      "        [0.0000, 1.6925]], device='cuda:0', requires_grad=True)\n",
      "Episode [72/500] loss: 35.95, average reward: -98.30, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7027, 0.0000],\n",
      "        [0.0000, 1.7019]], device='cuda:0', requires_grad=True)\n",
      "Episode [73/500] loss: 53.36, average reward: -103.07, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7123, 0.0000],\n",
      "        [0.0000, 1.7117]], device='cuda:0', requires_grad=True)\n",
      "Episode [74/500] loss: 36.61, average reward: -97.80, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7221, 0.0000],\n",
      "        [0.0000, 1.7210]], device='cuda:0', requires_grad=True)\n",
      "Episode [75/500] loss: 43.74, average reward: -105.60, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7317, 0.0000],\n",
      "        [0.0000, 1.7305]], device='cuda:0', requires_grad=True)\n",
      "Episode [76/500] loss: 46.44, average reward: -108.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7416, 0.0000],\n",
      "        [0.0000, 1.7397]], device='cuda:0', requires_grad=True)\n",
      "Episode [77/500] loss: 42.57, average reward: -109.98, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7516, 0.0000],\n",
      "        [0.0000, 1.7488]], device='cuda:0', requires_grad=True)\n",
      "Episode [78/500] loss: 47.12, average reward: -102.39, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7614, 0.0000],\n",
      "        [0.0000, 1.7582]], device='cuda:0', requires_grad=True)\n",
      "Episode [79/500] loss: 50.32, average reward: -100.84, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7711, 0.0000],\n",
      "        [0.0000, 1.7678]], device='cuda:0', requires_grad=True)\n",
      "Episode [80/500] loss: 54.51, average reward: -110.10, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7810, 0.0000],\n",
      "        [0.0000, 1.7775]], device='cuda:0', requires_grad=True)\n",
      "Episode [81/500] loss: 55.18, average reward: -103.75, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7911, 0.0000],\n",
      "        [0.0000, 1.7874]], device='cuda:0', requires_grad=True)\n",
      "Episode [82/500] loss: 45.81, average reward: -103.75, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8011, 0.0000],\n",
      "        [0.0000, 1.7972]], device='cuda:0', requires_grad=True)\n",
      "Episode [83/500] loss: 49.37, average reward: -103.25, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8111, 0.0000],\n",
      "        [0.0000, 1.8071]], device='cuda:0', requires_grad=True)\n",
      "Episode [84/500] loss: 50.30, average reward: -103.95, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8212, 0.0000],\n",
      "        [0.0000, 1.8169]], device='cuda:0', requires_grad=True)\n",
      "Episode [85/500] loss: 50.08, average reward: -102.41, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8312, 0.0000],\n",
      "        [0.0000, 1.8269]], device='cuda:0', requires_grad=True)\n",
      "Episode [86/500] loss: 47.72, average reward: -109.44, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8411, 0.0000],\n",
      "        [0.0000, 1.8369]], device='cuda:0', requires_grad=True)\n",
      "Episode [87/500] loss: 47.10, average reward: -108.64, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8511, 0.0000],\n",
      "        [0.0000, 1.8467]], device='cuda:0', requires_grad=True)\n",
      "Episode [88/500] loss: 41.07, average reward: -104.08, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8608, 0.0000],\n",
      "        [0.0000, 1.8565]], device='cuda:0', requires_grad=True)\n",
      "Episode [89/500] loss: 54.75, average reward: -110.17, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8708, 0.0000],\n",
      "        [0.0000, 1.8662]], device='cuda:0', requires_grad=True)\n",
      "Episode [90/500] loss: 51.96, average reward: -105.54, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8809, 0.0000],\n",
      "        [0.0000, 1.8759]], device='cuda:0', requires_grad=True)\n",
      "Episode [91/500] loss: 48.66, average reward: -112.00, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8910, 0.0000],\n",
      "        [0.0000, 1.8855]], device='cuda:0', requires_grad=True)\n",
      "Episode [92/500] loss: 43.36, average reward: -100.52, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9011, 0.0000],\n",
      "        [0.0000, 1.8949]], device='cuda:0', requires_grad=True)\n",
      "Episode [93/500] loss: 44.66, average reward: -101.70, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9111, 0.0000],\n",
      "        [0.0000, 1.9042]], device='cuda:0', requires_grad=True)\n",
      "Episode [94/500] loss: 52.91, average reward: -114.06, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9210, 0.0000],\n",
      "        [0.0000, 1.9137]], device='cuda:0', requires_grad=True)\n",
      "Episode [95/500] loss: 54.51, average reward: -116.77, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9310, 0.0000],\n",
      "        [0.0000, 1.9233]], device='cuda:0', requires_grad=True)\n",
      "Episode [96/500] loss: 44.03, average reward: -112.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9410, 0.0000],\n",
      "        [0.0000, 1.9327]], device='cuda:0', requires_grad=True)\n",
      "Episode [97/500] loss: 37.74, average reward: -92.51, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9506, 0.0000],\n",
      "        [0.0000, 1.9420]], device='cuda:0', requires_grad=True)\n",
      "Episode [98/500] loss: 52.33, average reward: -112.72, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9604, 0.0000],\n",
      "        [0.0000, 1.9512]], device='cuda:0', requires_grad=True)\n",
      "Episode [99/500] loss: 56.85, average reward: -111.97, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9705, 0.0000],\n",
      "        [0.0000, 1.9603]], device='cuda:0', requires_grad=True)\n",
      "Episode [100/500] loss: 44.45, average reward: -107.23, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9804, 0.0000],\n",
      "        [0.0000, 1.9694]], device='cuda:0', requires_grad=True)\n",
      "Episode [101/500] loss: 61.02, average reward: -113.31, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.9905, 0.0000],\n",
      "        [0.0000, 1.9787]], device='cuda:0', requires_grad=True)\n",
      "Episode [102/500] loss: 58.42, average reward: -117.45, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0007, 0.0000],\n",
      "        [0.0000, 1.9881]], device='cuda:0', requires_grad=True)\n",
      "Episode [103/500] loss: 53.45, average reward: -114.55, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0110, 0.0000],\n",
      "        [0.0000, 1.9974]], device='cuda:0', requires_grad=True)\n",
      "Episode [104/500] loss: 47.99, average reward: -109.81, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0212, 0.0000],\n",
      "        [0.0000, 2.0067]], device='cuda:0', requires_grad=True)\n",
      "Episode [105/500] loss: 55.29, average reward: -113.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0314, 0.0000],\n",
      "        [0.0000, 2.0160]], device='cuda:0', requires_grad=True)\n",
      "Episode [106/500] loss: 53.69, average reward: -116.15, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0418, 0.0000],\n",
      "        [0.0000, 2.0252]], device='cuda:0', requires_grad=True)\n",
      "Episode [107/500] loss: 53.37, average reward: -116.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0521, 0.0000],\n",
      "        [0.0000, 2.0345]], device='cuda:0', requires_grad=True)\n",
      "Episode [108/500] loss: 49.89, average reward: -118.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0622, 0.0000],\n",
      "        [0.0000, 2.0437]], device='cuda:0', requires_grad=True)\n",
      "Episode [109/500] loss: 55.50, average reward: -111.67, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0725, 0.0000],\n",
      "        [0.0000, 2.0530]], device='cuda:0', requires_grad=True)\n",
      "Episode [110/500] loss: 56.14, average reward: -118.35, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0826, 0.0000],\n",
      "        [0.0000, 2.0624]], device='cuda:0', requires_grad=True)\n",
      "Episode [111/500] loss: 42.55, average reward: -117.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.0925, 0.0000],\n",
      "        [0.0000, 2.0716]], device='cuda:0', requires_grad=True)\n",
      "Episode [112/500] loss: 57.35, average reward: -117.02, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1025, 0.0000],\n",
      "        [0.0000, 2.0809]], device='cuda:0', requires_grad=True)\n",
      "Episode [113/500] loss: 42.52, average reward: -117.34, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1123, 0.0000],\n",
      "        [0.0000, 2.0900]], device='cuda:0', requires_grad=True)\n",
      "Episode [114/500] loss: 67.05, average reward: -120.55, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1223, 0.0000],\n",
      "        [0.0000, 2.0994]], device='cuda:0', requires_grad=True)\n",
      "Episode [115/500] loss: 57.55, average reward: -119.14, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1321, 0.0000],\n",
      "        [0.0000, 2.1091]], device='cuda:0', requires_grad=True)\n",
      "Episode [116/500] loss: 55.79, average reward: -110.85, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1419, 0.0000],\n",
      "        [0.0000, 2.1188]], device='cuda:0', requires_grad=True)\n",
      "Episode [117/500] loss: 77.67, average reward: -121.97, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1520, 0.0000],\n",
      "        [0.0000, 2.1288]], device='cuda:0', requires_grad=True)\n",
      "Episode [118/500] loss: 62.37, average reward: -119.17, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1621, 0.0000],\n",
      "        [0.0000, 2.1390]], device='cuda:0', requires_grad=True)\n",
      "Episode [119/500] loss: 56.59, average reward: -123.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1720, 0.0000],\n",
      "        [0.0000, 2.1493]], device='cuda:0', requires_grad=True)\n",
      "Episode [120/500] loss: 65.38, average reward: -118.50, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1821, 0.0000],\n",
      "        [0.0000, 2.1596]], device='cuda:0', requires_grad=True)\n",
      "Episode [121/500] loss: 69.06, average reward: -123.33, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.1923, 0.0000],\n",
      "        [0.0000, 2.1701]], device='cuda:0', requires_grad=True)\n",
      "Episode [122/500] loss: 54.98, average reward: -121.50, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2022, 0.0000],\n",
      "        [0.0000, 2.1806]], device='cuda:0', requires_grad=True)\n",
      "Episode [123/500] loss: 71.48, average reward: -123.90, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2125, 0.0000],\n",
      "        [0.0000, 2.1912]], device='cuda:0', requires_grad=True)\n",
      "Episode [124/500] loss: 38.68, average reward: -110.70, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2224, 0.0000],\n",
      "        [0.0000, 2.2013]], device='cuda:0', requires_grad=True)\n",
      "Episode [125/500] loss: 60.22, average reward: -115.06, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2325, 0.0000],\n",
      "        [0.0000, 2.2113]], device='cuda:0', requires_grad=True)\n",
      "Episode [126/500] loss: 47.25, average reward: -118.76, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2424, 0.0000],\n",
      "        [0.0000, 2.2210]], device='cuda:0', requires_grad=True)\n",
      "Episode [127/500] loss: 52.68, average reward: -109.61, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2523, 0.0000],\n",
      "        [0.0000, 2.2306]], device='cuda:0', requires_grad=True)\n",
      "Episode [128/500] loss: 51.27, average reward: -111.81, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2618, 0.0000],\n",
      "        [0.0000, 2.2404]], device='cuda:0', requires_grad=True)\n",
      "Episode [129/500] loss: 56.37, average reward: -112.95, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2713, 0.0000],\n",
      "        [0.0000, 2.2501]], device='cuda:0', requires_grad=True)\n",
      "Episode [130/500] loss: 57.89, average reward: -114.42, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2808, 0.0000],\n",
      "        [0.0000, 2.2597]], device='cuda:0', requires_grad=True)\n",
      "Episode [131/500] loss: 60.84, average reward: -123.49, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.2904, 0.0000],\n",
      "        [0.0000, 2.2693]], device='cuda:0', requires_grad=True)\n",
      "Episode [132/500] loss: 77.12, average reward: -125.65, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3004, 0.0000],\n",
      "        [0.0000, 2.2791]], device='cuda:0', requires_grad=True)\n",
      "Episode [133/500] loss: 61.85, average reward: -114.43, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3105, 0.0000],\n",
      "        [0.0000, 2.2888]], device='cuda:0', requires_grad=True)\n",
      "Episode [134/500] loss: 55.71, average reward: -122.91, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3205, 0.0000],\n",
      "        [0.0000, 2.2985]], device='cuda:0', requires_grad=True)\n",
      "Episode [135/500] loss: 49.99, average reward: -121.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3301, 0.0000],\n",
      "        [0.0000, 2.3081]], device='cuda:0', requires_grad=True)\n",
      "Episode [136/500] loss: 58.28, average reward: -124.86, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3398, 0.0000],\n",
      "        [0.0000, 2.3177]], device='cuda:0', requires_grad=True)\n",
      "Episode [137/500] loss: 66.14, average reward: -118.04, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3495, 0.0000],\n",
      "        [0.0000, 2.3273]], device='cuda:0', requires_grad=True)\n",
      "Episode [138/500] loss: 65.74, average reward: -122.15, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3592, 0.0000],\n",
      "        [0.0000, 2.3372]], device='cuda:0', requires_grad=True)\n",
      "Episode [139/500] loss: 51.90, average reward: -118.55, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3688, 0.0000],\n",
      "        [0.0000, 2.3468]], device='cuda:0', requires_grad=True)\n",
      "Episode [140/500] loss: 60.10, average reward: -124.12, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3784, 0.0000],\n",
      "        [0.0000, 2.3565]], device='cuda:0', requires_grad=True)\n",
      "Episode [141/500] loss: 69.43, average reward: -126.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3880, 0.0000],\n",
      "        [0.0000, 2.3664]], device='cuda:0', requires_grad=True)\n",
      "Episode [142/500] loss: 82.42, average reward: -124.71, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.3976, 0.0000],\n",
      "        [0.0000, 2.3768]], device='cuda:0', requires_grad=True)\n",
      "Episode [143/500] loss: 53.35, average reward: -121.13, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4072, 0.0000],\n",
      "        [0.0000, 2.3870]], device='cuda:0', requires_grad=True)\n",
      "Episode [144/500] loss: 56.33, average reward: -123.92, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4167, 0.0000],\n",
      "        [0.0000, 2.3970]], device='cuda:0', requires_grad=True)\n",
      "Episode [145/500] loss: 67.13, average reward: -120.16, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4261, 0.0000],\n",
      "        [0.0000, 2.4072]], device='cuda:0', requires_grad=True)\n",
      "Episode [146/500] loss: 52.51, average reward: -117.84, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4354, 0.0000],\n",
      "        [0.0000, 2.4171]], device='cuda:0', requires_grad=True)\n",
      "Episode [147/500] loss: 54.92, average reward: -114.76, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4447, 0.0000],\n",
      "        [0.0000, 2.4269]], device='cuda:0', requires_grad=True)\n",
      "Episode [148/500] loss: 67.01, average reward: -126.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4540, 0.0000],\n",
      "        [0.0000, 2.4368]], device='cuda:0', requires_grad=True)\n",
      "Episode [149/500] loss: 66.33, average reward: -122.40, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4638, 0.0000],\n",
      "        [0.0000, 2.4463]], device='cuda:0', requires_grad=True)\n",
      "Episode [150/500] loss: 64.40, average reward: -129.63, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4737, 0.0000],\n",
      "        [0.0000, 2.4557]], device='cuda:0', requires_grad=True)\n",
      "Episode [151/500] loss: 55.34, average reward: -118.97, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4835, 0.0000],\n",
      "        [0.0000, 2.4649]], device='cuda:0', requires_grad=True)\n",
      "Episode [152/500] loss: 54.90, average reward: -125.58, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.4934, 0.0000],\n",
      "        [0.0000, 2.4739]], device='cuda:0', requires_grad=True)\n",
      "Episode [153/500] loss: 72.38, average reward: -129.63, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5034, 0.0000],\n",
      "        [0.0000, 2.4830]], device='cuda:0', requires_grad=True)\n",
      "Episode [154/500] loss: 62.01, average reward: -132.44, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5134, 0.0000],\n",
      "        [0.0000, 2.4920]], device='cuda:0', requires_grad=True)\n",
      "Episode [155/500] loss: 76.20, average reward: -130.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5236, 0.0000],\n",
      "        [0.0000, 2.5012]], device='cuda:0', requires_grad=True)\n",
      "Episode [156/500] loss: 73.18, average reward: -126.10, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5339, 0.0000],\n",
      "        [0.0000, 2.5105]], device='cuda:0', requires_grad=True)\n",
      "Episode [157/500] loss: 78.80, average reward: -133.28, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5444, 0.0000],\n",
      "        [0.0000, 2.5200]], device='cuda:0', requires_grad=True)\n",
      "Episode [158/500] loss: 58.33, average reward: -113.94, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5545, 0.0000],\n",
      "        [0.0000, 2.5295]], device='cuda:0', requires_grad=True)\n",
      "Episode [159/500] loss: 70.24, average reward: -130.32, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5649, 0.0000],\n",
      "        [0.0000, 2.5389]], device='cuda:0', requires_grad=True)\n",
      "Episode [160/500] loss: 72.27, average reward: -129.19, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5753, 0.0000],\n",
      "        [0.0000, 2.5483]], device='cuda:0', requires_grad=True)\n",
      "Episode [161/500] loss: 67.66, average reward: -132.03, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5857, 0.0000],\n",
      "        [0.0000, 2.5578]], device='cuda:0', requires_grad=True)\n",
      "Episode [162/500] loss: 82.35, average reward: -130.28, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.5960, 0.0000],\n",
      "        [0.0000, 2.5676]], device='cuda:0', requires_grad=True)\n",
      "Episode [163/500] loss: 82.29, average reward: -132.75, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6064, 0.0000],\n",
      "        [0.0000, 2.5778]], device='cuda:0', requires_grad=True)\n",
      "Episode [164/500] loss: 60.17, average reward: -132.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6168, 0.0000],\n",
      "        [0.0000, 2.5876]], device='cuda:0', requires_grad=True)\n",
      "Episode [165/500] loss: 68.83, average reward: -124.45, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6271, 0.0000],\n",
      "        [0.0000, 2.5974]], device='cuda:0', requires_grad=True)\n",
      "Episode [166/500] loss: 89.40, average reward: -138.44, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6378, 0.0000],\n",
      "        [0.0000, 2.6074]], device='cuda:0', requires_grad=True)\n",
      "Episode [167/500] loss: 64.39, average reward: -125.56, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6484, 0.0000],\n",
      "        [0.0000, 2.6171]], device='cuda:0', requires_grad=True)\n",
      "Episode [168/500] loss: 62.46, average reward: -114.76, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6589, 0.0000],\n",
      "        [0.0000, 2.6267]], device='cuda:0', requires_grad=True)\n",
      "Episode [169/500] loss: 69.98, average reward: -133.18, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6694, 0.0000],\n",
      "        [0.0000, 2.6363]], device='cuda:0', requires_grad=True)\n",
      "Episode [170/500] loss: 57.52, average reward: -133.91, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6795, 0.0000],\n",
      "        [0.0000, 2.6459]], device='cuda:0', requires_grad=True)\n",
      "Episode [171/500] loss: 65.71, average reward: -125.57, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6895, 0.0000],\n",
      "        [0.0000, 2.6555]], device='cuda:0', requires_grad=True)\n",
      "Episode [172/500] loss: 73.38, average reward: -132.21, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.6995, 0.0000],\n",
      "        [0.0000, 2.6651]], device='cuda:0', requires_grad=True)\n",
      "Episode [173/500] loss: 72.78, average reward: -126.32, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7097, 0.0000],\n",
      "        [0.0000, 2.6746]], device='cuda:0', requires_grad=True)\n",
      "Episode [174/500] loss: 59.16, average reward: -124.28, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7195, 0.0000],\n",
      "        [0.0000, 2.6841]], device='cuda:0', requires_grad=True)\n",
      "Episode [175/500] loss: 77.04, average reward: -128.80, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7296, 0.0000],\n",
      "        [0.0000, 2.6936]], device='cuda:0', requires_grad=True)\n",
      "Episode [176/500] loss: 54.76, average reward: -125.58, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7394, 0.0000],\n",
      "        [0.0000, 2.7029]], device='cuda:0', requires_grad=True)\n",
      "Episode [177/500] loss: 55.37, average reward: -124.17, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7489, 0.0000],\n",
      "        [0.0000, 2.7120]], device='cuda:0', requires_grad=True)\n",
      "Episode [178/500] loss: 74.84, average reward: -136.29, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7586, 0.0000],\n",
      "        [0.0000, 2.7213]], device='cuda:0', requires_grad=True)\n",
      "Episode [179/500] loss: 68.51, average reward: -126.59, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7682, 0.0000],\n",
      "        [0.0000, 2.7305]], device='cuda:0', requires_grad=True)\n",
      "Episode [180/500] loss: 64.78, average reward: -125.35, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7779, 0.0000],\n",
      "        [0.0000, 2.7396]], device='cuda:0', requires_grad=True)\n",
      "Episode [181/500] loss: 69.75, average reward: -133.64, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7875, 0.0000],\n",
      "        [0.0000, 2.7487]], device='cuda:0', requires_grad=True)\n",
      "Episode [182/500] loss: 80.64, average reward: -139.14, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.7973, 0.0000],\n",
      "        [0.0000, 2.7580]], device='cuda:0', requires_grad=True)\n",
      "Episode [183/500] loss: 82.41, average reward: -138.02, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8070, 0.0000],\n",
      "        [0.0000, 2.7676]], device='cuda:0', requires_grad=True)\n",
      "Episode [184/500] loss: 66.95, average reward: -128.14, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8168, 0.0000],\n",
      "        [0.0000, 2.7770]], device='cuda:0', requires_grad=True)\n",
      "Episode [185/500] loss: 63.97, average reward: -136.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8264, 0.0000],\n",
      "        [0.0000, 2.7864]], device='cuda:0', requires_grad=True)\n",
      "Episode [186/500] loss: 84.07, average reward: -131.24, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8361, 0.0000],\n",
      "        [0.0000, 2.7960]], device='cuda:0', requires_grad=True)\n",
      "Episode [187/500] loss: 64.56, average reward: -128.96, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8456, 0.0000],\n",
      "        [0.0000, 2.8057]], device='cuda:0', requires_grad=True)\n",
      "Episode [188/500] loss: 71.74, average reward: -132.23, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8550, 0.0000],\n",
      "        [0.0000, 2.8153]], device='cuda:0', requires_grad=True)\n",
      "Episode [189/500] loss: 60.35, average reward: -130.59, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8643, 0.0000],\n",
      "        [0.0000, 2.8249]], device='cuda:0', requires_grad=True)\n",
      "Episode [190/500] loss: 74.06, average reward: -129.46, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8734, 0.0000],\n",
      "        [0.0000, 2.8346]], device='cuda:0', requires_grad=True)\n",
      "Episode [191/500] loss: 70.33, average reward: -137.27, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8825, 0.0000],\n",
      "        [0.0000, 2.8442]], device='cuda:0', requires_grad=True)\n",
      "Episode [192/500] loss: 76.22, average reward: -128.38, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.8917, 0.0000],\n",
      "        [0.0000, 2.8540]], device='cuda:0', requires_grad=True)\n",
      "Episode [193/500] loss: 85.43, average reward: -143.15, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9010, 0.0000],\n",
      "        [0.0000, 2.8640]], device='cuda:0', requires_grad=True)\n",
      "Episode [194/500] loss: 85.18, average reward: -132.78, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9101, 0.0000],\n",
      "        [0.0000, 2.8743]], device='cuda:0', requires_grad=True)\n",
      "Episode [195/500] loss: 57.36, average reward: -122.08, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9192, 0.0000],\n",
      "        [0.0000, 2.8844]], device='cuda:0', requires_grad=True)\n",
      "Episode [196/500] loss: 78.38, average reward: -129.95, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9282, 0.0000],\n",
      "        [0.0000, 2.8945]], device='cuda:0', requires_grad=True)\n",
      "Episode [197/500] loss: 82.24, average reward: -143.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9373, 0.0000],\n",
      "        [0.0000, 2.9047]], device='cuda:0', requires_grad=True)\n",
      "Episode [198/500] loss: 71.39, average reward: -130.88, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9465, 0.0000],\n",
      "        [0.0000, 2.9148]], device='cuda:0', requires_grad=True)\n",
      "Episode [199/500] loss: 67.90, average reward: -129.99, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9554, 0.0000],\n",
      "        [0.0000, 2.9249]], device='cuda:0', requires_grad=True)\n",
      "Episode [200/500] loss: 79.32, average reward: -139.50, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9644, 0.0000],\n",
      "        [0.0000, 2.9351]], device='cuda:0', requires_grad=True)\n",
      "Episode [201/500] loss: 79.88, average reward: -134.28, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9735, 0.0000],\n",
      "        [0.0000, 2.9453]], device='cuda:0', requires_grad=True)\n",
      "Episode [202/500] loss: 74.86, average reward: -130.93, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9825, 0.0000],\n",
      "        [0.0000, 2.9555]], device='cuda:0', requires_grad=True)\n",
      "Episode [203/500] loss: 77.64, average reward: -140.99, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[2.9914, 0.0000],\n",
      "        [0.0000, 2.9659]], device='cuda:0', requires_grad=True)\n",
      "Episode [204/500] loss: 83.18, average reward: -134.00, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0004, 0.0000],\n",
      "        [0.0000, 2.9763]], device='cuda:0', requires_grad=True)\n",
      "Episode [205/500] loss: 74.45, average reward: -143.63, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0093, 0.0000],\n",
      "        [0.0000, 2.9867]], device='cuda:0', requires_grad=True)\n",
      "Episode [206/500] loss: 69.67, average reward: -133.08, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0183, 0.0000],\n",
      "        [0.0000, 2.9969]], device='cuda:0', requires_grad=True)\n",
      "Episode [207/500] loss: 80.99, average reward: -146.94, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0274, 0.0000],\n",
      "        [0.0000, 3.0070]], device='cuda:0', requires_grad=True)\n",
      "Episode [208/500] loss: 83.43, average reward: -147.38, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0367, 0.0000],\n",
      "        [0.0000, 3.0171]], device='cuda:0', requires_grad=True)\n",
      "Episode [209/500] loss: 79.92, average reward: -141.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0460, 0.0000],\n",
      "        [0.0000, 3.0272]], device='cuda:0', requires_grad=True)\n",
      "Episode [210/500] loss: 71.77, average reward: -135.58, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0553, 0.0000],\n",
      "        [0.0000, 3.0372]], device='cuda:0', requires_grad=True)\n",
      "Episode [211/500] loss: 66.55, average reward: -132.40, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0643, 0.0000],\n",
      "        [0.0000, 3.0473]], device='cuda:0', requires_grad=True)\n",
      "Episode [212/500] loss: 72.88, average reward: -132.54, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0732, 0.0000],\n",
      "        [0.0000, 3.0572]], device='cuda:0', requires_grad=True)\n",
      "Episode [213/500] loss: 76.79, average reward: -136.60, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0823, 0.0000],\n",
      "        [0.0000, 3.0670]], device='cuda:0', requires_grad=True)\n",
      "Episode [214/500] loss: 71.67, average reward: -137.07, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.0915, 0.0000],\n",
      "        [0.0000, 3.0765]], device='cuda:0', requires_grad=True)\n",
      "Episode [215/500] loss: 72.71, average reward: -143.77, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1006, 0.0000],\n",
      "        [0.0000, 3.0860]], device='cuda:0', requires_grad=True)\n",
      "Episode [216/500] loss: 81.12, average reward: -144.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1097, 0.0000],\n",
      "        [0.0000, 3.0956]], device='cuda:0', requires_grad=True)\n",
      "Episode [217/500] loss: 77.43, average reward: -129.04, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1189, 0.0000],\n",
      "        [0.0000, 3.1052]], device='cuda:0', requires_grad=True)\n",
      "Episode [218/500] loss: 60.29, average reward: -130.31, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1278, 0.0000],\n",
      "        [0.0000, 3.1146]], device='cuda:0', requires_grad=True)\n",
      "Episode [219/500] loss: 98.76, average reward: -140.91, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1371, 0.0000],\n",
      "        [0.0000, 3.1242]], device='cuda:0', requires_grad=True)\n",
      "Episode [220/500] loss: 81.35, average reward: -135.53, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1465, 0.0000],\n",
      "        [0.0000, 3.1338]], device='cuda:0', requires_grad=True)\n",
      "Episode [221/500] loss: 73.51, average reward: -136.19, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1556, 0.0000],\n",
      "        [0.0000, 3.1434]], device='cuda:0', requires_grad=True)\n",
      "Episode [222/500] loss: 85.20, average reward: -140.75, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1648, 0.0000],\n",
      "        [0.0000, 3.1532]], device='cuda:0', requires_grad=True)\n",
      "Episode [223/500] loss: 59.10, average reward: -129.39, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1738, 0.0000],\n",
      "        [0.0000, 3.1626]], device='cuda:0', requires_grad=True)\n",
      "Episode [224/500] loss: 69.88, average reward: -138.06, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1829, 0.0000],\n",
      "        [0.0000, 3.1719]], device='cuda:0', requires_grad=True)\n",
      "Episode [225/500] loss: 93.11, average reward: -149.27, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.1924, 0.0000],\n",
      "        [0.0000, 3.1810]], device='cuda:0', requires_grad=True)\n",
      "Episode [226/500] loss: 70.65, average reward: -150.23, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2019, 0.0000],\n",
      "        [0.0000, 3.1900]], device='cuda:0', requires_grad=True)\n",
      "Episode [227/500] loss: 82.28, average reward: -152.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2115, 0.0000],\n",
      "        [0.0000, 3.1989]], device='cuda:0', requires_grad=True)\n",
      "Episode [228/500] loss: 78.16, average reward: -151.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2211, 0.0000],\n",
      "        [0.0000, 3.2079]], device='cuda:0', requires_grad=True)\n",
      "Episode [229/500] loss: 76.65, average reward: -137.68, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2307, 0.0000],\n",
      "        [0.0000, 3.2168]], device='cuda:0', requires_grad=True)\n",
      "Episode [230/500] loss: 87.95, average reward: -148.45, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2404, 0.0000],\n",
      "        [0.0000, 3.2258]], device='cuda:0', requires_grad=True)\n",
      "Episode [231/500] loss: 84.02, average reward: -150.58, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2499, 0.0000],\n",
      "        [0.0000, 3.2350]], device='cuda:0', requires_grad=True)\n",
      "Episode [232/500] loss: 75.80, average reward: -144.88, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2595, 0.0000],\n",
      "        [0.0000, 3.2442]], device='cuda:0', requires_grad=True)\n",
      "Episode [233/500] loss: 80.92, average reward: -148.61, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2691, 0.0000],\n",
      "        [0.0000, 3.2533]], device='cuda:0', requires_grad=True)\n",
      "Episode [234/500] loss: 79.71, average reward: -141.91, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2786, 0.0000],\n",
      "        [0.0000, 3.2624]], device='cuda:0', requires_grad=True)\n",
      "Episode [235/500] loss: 89.73, average reward: -138.64, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2882, 0.0000],\n",
      "        [0.0000, 3.2716]], device='cuda:0', requires_grad=True)\n",
      "Episode [236/500] loss: 80.49, average reward: -140.26, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.2979, 0.0000],\n",
      "        [0.0000, 3.2808]], device='cuda:0', requires_grad=True)\n",
      "Episode [237/500] loss: 69.42, average reward: -141.59, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3075, 0.0000],\n",
      "        [0.0000, 3.2898]], device='cuda:0', requires_grad=True)\n",
      "Episode [238/500] loss: 96.43, average reward: -155.14, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3172, 0.0000],\n",
      "        [0.0000, 3.2989]], device='cuda:0', requires_grad=True)\n",
      "Episode [239/500] loss: 73.68, average reward: -133.65, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3268, 0.0000],\n",
      "        [0.0000, 3.3080]], device='cuda:0', requires_grad=True)\n",
      "Episode [240/500] loss: 93.34, average reward: -140.85, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3365, 0.0000],\n",
      "        [0.0000, 3.3172]], device='cuda:0', requires_grad=True)\n",
      "Episode [241/500] loss: 98.55, average reward: -151.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3464, 0.0000],\n",
      "        [0.0000, 3.3267]], device='cuda:0', requires_grad=True)\n",
      "Episode [242/500] loss: 84.32, average reward: -141.14, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3561, 0.0000],\n",
      "        [0.0000, 3.3362]], device='cuda:0', requires_grad=True)\n",
      "Episode [243/500] loss: 89.40, average reward: -155.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3657, 0.0000],\n",
      "        [0.0000, 3.3459]], device='cuda:0', requires_grad=True)\n",
      "Episode [244/500] loss: 67.24, average reward: -141.76, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3751, 0.0000],\n",
      "        [0.0000, 3.3555]], device='cuda:0', requires_grad=True)\n",
      "Episode [245/500] loss: 96.81, average reward: -157.31, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3845, 0.0000],\n",
      "        [0.0000, 3.3653]], device='cuda:0', requires_grad=True)\n",
      "Episode [246/500] loss: 83.23, average reward: -154.47, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.3938, 0.0000],\n",
      "        [0.0000, 3.3751]], device='cuda:0', requires_grad=True)\n",
      "Episode [247/500] loss: 85.35, average reward: -156.73, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4032, 0.0000],\n",
      "        [0.0000, 3.3848]], device='cuda:0', requires_grad=True)\n",
      "Episode [248/500] loss: 94.92, average reward: -151.23, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4127, 0.0000],\n",
      "        [0.0000, 3.3947]], device='cuda:0', requires_grad=True)\n",
      "Episode [249/500] loss: 95.14, average reward: -149.91, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4222, 0.0000],\n",
      "        [0.0000, 3.4047]], device='cuda:0', requires_grad=True)\n",
      "Episode [250/500] loss: 93.42, average reward: -154.77, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4320, 0.0000],\n",
      "        [0.0000, 3.4145]], device='cuda:0', requires_grad=True)\n",
      "Episode [251/500] loss: 91.51, average reward: -155.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4416, 0.0000],\n",
      "        [0.0000, 3.4245]], device='cuda:0', requires_grad=True)\n",
      "Episode [252/500] loss: 90.38, average reward: -150.51, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4513, 0.0000],\n",
      "        [0.0000, 3.4346]], device='cuda:0', requires_grad=True)\n",
      "Episode [253/500] loss: 77.50, average reward: -155.74, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4608, 0.0000],\n",
      "        [0.0000, 3.4445]], device='cuda:0', requires_grad=True)\n",
      "Episode [254/500] loss: 76.18, average reward: -143.18, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4704, 0.0000],\n",
      "        [0.0000, 3.4541]], device='cuda:0', requires_grad=True)\n",
      "Episode [255/500] loss: 100.07, average reward: -159.41, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4801, 0.0000],\n",
      "        [0.0000, 3.4637]], device='cuda:0', requires_grad=True)\n",
      "Episode [256/500] loss: 94.71, average reward: -160.53, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4899, 0.0000],\n",
      "        [0.0000, 3.4735]], device='cuda:0', requires_grad=True)\n",
      "Episode [257/500] loss: 95.56, average reward: -155.27, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.4997, 0.0000],\n",
      "        [0.0000, 3.4833]], device='cuda:0', requires_grad=True)\n",
      "Episode [258/500] loss: 99.47, average reward: -158.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5094, 0.0000],\n",
      "        [0.0000, 3.4934]], device='cuda:0', requires_grad=True)\n",
      "Episode [259/500] loss: 95.47, average reward: -148.32, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5193, 0.0000],\n",
      "        [0.0000, 3.5034]], device='cuda:0', requires_grad=True)\n",
      "Episode [260/500] loss: 96.91, average reward: -148.83, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5292, 0.0000],\n",
      "        [0.0000, 3.5135]], device='cuda:0', requires_grad=True)\n",
      "Episode [261/500] loss: 107.79, average reward: -159.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5392, 0.0000],\n",
      "        [0.0000, 3.5238]], device='cuda:0', requires_grad=True)\n",
      "Episode [262/500] loss: 91.29, average reward: -162.11, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5490, 0.0000],\n",
      "        [0.0000, 3.5342]], device='cuda:0', requires_grad=True)\n",
      "Episode [263/500] loss: 93.51, average reward: -160.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5588, 0.0000],\n",
      "        [0.0000, 3.5445]], device='cuda:0', requires_grad=True)\n",
      "Episode [264/500] loss: 92.22, average reward: -148.31, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5686, 0.0000],\n",
      "        [0.0000, 3.5548]], device='cuda:0', requires_grad=True)\n",
      "Episode [265/500] loss: 88.22, average reward: -148.10, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5784, 0.0000],\n",
      "        [0.0000, 3.5650]], device='cuda:0', requires_grad=True)\n",
      "Episode [266/500] loss: 77.03, average reward: -139.88, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5880, 0.0000],\n",
      "        [0.0000, 3.5750]], device='cuda:0', requires_grad=True)\n",
      "Episode [267/500] loss: 97.69, average reward: -158.68, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.5976, 0.0000],\n",
      "        [0.0000, 3.5851]], device='cuda:0', requires_grad=True)\n",
      "Episode [268/500] loss: 108.58, average reward: -164.57, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6074, 0.0000],\n",
      "        [0.0000, 3.5952]], device='cuda:0', requires_grad=True)\n",
      "Episode [269/500] loss: 83.67, average reward: -152.53, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6173, 0.0000],\n",
      "        [0.0000, 3.6051]], device='cuda:0', requires_grad=True)\n",
      "Episode [270/500] loss: 103.83, average reward: -152.12, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6275, 0.0000],\n",
      "        [0.0000, 3.6149]], device='cuda:0', requires_grad=True)\n",
      "Episode [271/500] loss: 80.85, average reward: -159.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6375, 0.0000],\n",
      "        [0.0000, 3.6245]], device='cuda:0', requires_grad=True)\n",
      "Episode [272/500] loss: 75.04, average reward: -150.45, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6473, 0.0000],\n",
      "        [0.0000, 3.6340]], device='cuda:0', requires_grad=True)\n",
      "Episode [273/500] loss: 102.00, average reward: -158.65, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6573, 0.0000],\n",
      "        [0.0000, 3.6434]], device='cuda:0', requires_grad=True)\n",
      "Episode [274/500] loss: 91.02, average reward: -158.92, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6672, 0.0000],\n",
      "        [0.0000, 3.6529]], device='cuda:0', requires_grad=True)\n",
      "Episode [275/500] loss: 83.23, average reward: -161.00, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6769, 0.0000],\n",
      "        [0.0000, 3.6623]], device='cuda:0', requires_grad=True)\n",
      "Episode [276/500] loss: 84.52, average reward: -157.11, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6867, 0.0000],\n",
      "        [0.0000, 3.6716]], device='cuda:0', requires_grad=True)\n",
      "Episode [277/500] loss: 92.30, average reward: -166.74, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.6962, 0.0000],\n",
      "        [0.0000, 3.6810]], device='cuda:0', requires_grad=True)\n",
      "Episode [278/500] loss: 114.68, average reward: -166.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7060, 0.0000],\n",
      "        [0.0000, 3.6907]], device='cuda:0', requires_grad=True)\n",
      "Episode [279/500] loss: 120.33, average reward: -168.15, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7160, 0.0000],\n",
      "        [0.0000, 3.7006]], device='cuda:0', requires_grad=True)\n",
      "Episode [280/500] loss: 83.21, average reward: -152.86, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7258, 0.0000],\n",
      "        [0.0000, 3.7104]], device='cuda:0', requires_grad=True)\n",
      "Episode [281/500] loss: 89.77, average reward: -163.96, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7354, 0.0000],\n",
      "        [0.0000, 3.7203]], device='cuda:0', requires_grad=True)\n",
      "Episode [282/500] loss: 106.34, average reward: -163.81, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7449, 0.0000],\n",
      "        [0.0000, 3.7305]], device='cuda:0', requires_grad=True)\n",
      "Episode [283/500] loss: 75.08, average reward: -147.50, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7542, 0.0000],\n",
      "        [0.0000, 3.7404]], device='cuda:0', requires_grad=True)\n",
      "Episode [284/500] loss: 117.06, average reward: -167.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7638, 0.0000],\n",
      "        [0.0000, 3.7505]], device='cuda:0', requires_grad=True)\n",
      "Episode [285/500] loss: 99.15, average reward: -163.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7734, 0.0000],\n",
      "        [0.0000, 3.7606]], device='cuda:0', requires_grad=True)\n",
      "Episode [286/500] loss: 82.91, average reward: -137.71, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7828, 0.0000],\n",
      "        [0.0000, 3.7706]], device='cuda:0', requires_grad=True)\n",
      "Episode [287/500] loss: 80.22, average reward: -156.40, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.7920, 0.0000],\n",
      "        [0.0000, 3.7805]], device='cuda:0', requires_grad=True)\n",
      "Episode [288/500] loss: 99.73, average reward: -165.79, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8013, 0.0000],\n",
      "        [0.0000, 3.7903]], device='cuda:0', requires_grad=True)\n",
      "Episode [289/500] loss: 100.68, average reward: -155.35, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8107, 0.0000],\n",
      "        [0.0000, 3.8002]], device='cuda:0', requires_grad=True)\n",
      "Episode [290/500] loss: 99.70, average reward: -154.76, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8201, 0.0000],\n",
      "        [0.0000, 3.8101]], device='cuda:0', requires_grad=True)\n",
      "Episode [291/500] loss: 86.60, average reward: -144.91, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8295, 0.0000],\n",
      "        [0.0000, 3.8197]], device='cuda:0', requires_grad=True)\n",
      "Episode [292/500] loss: 108.12, average reward: -167.79, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8392, 0.0000],\n",
      "        [0.0000, 3.8294]], device='cuda:0', requires_grad=True)\n",
      "Episode [293/500] loss: 117.31, average reward: -171.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8491, 0.0000],\n",
      "        [0.0000, 3.8392]], device='cuda:0', requires_grad=True)\n",
      "Episode [294/500] loss: 102.37, average reward: -167.53, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8591, 0.0000],\n",
      "        [0.0000, 3.8489]], device='cuda:0', requires_grad=True)\n",
      "Episode [295/500] loss: 84.62, average reward: -144.46, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8690, 0.0000],\n",
      "        [0.0000, 3.8585]], device='cuda:0', requires_grad=True)\n",
      "Episode [296/500] loss: 95.56, average reward: -159.45, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8789, 0.0000],\n",
      "        [0.0000, 3.8678]], device='cuda:0', requires_grad=True)\n",
      "Episode [297/500] loss: 97.55, average reward: -168.32, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8890, 0.0000],\n",
      "        [0.0000, 3.8771]], device='cuda:0', requires_grad=True)\n",
      "Episode [298/500] loss: 95.07, average reward: -168.84, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.8989, 0.0000],\n",
      "        [0.0000, 3.8864]], device='cuda:0', requires_grad=True)\n",
      "Episode [299/500] loss: 82.96, average reward: -156.06, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9086, 0.0000],\n",
      "        [0.0000, 3.8957]], device='cuda:0', requires_grad=True)\n",
      "Episode [300/500] loss: 113.39, average reward: -173.55, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9184, 0.0000],\n",
      "        [0.0000, 3.9051]], device='cuda:0', requires_grad=True)\n",
      "Episode [301/500] loss: 113.97, average reward: -174.67, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9284, 0.0000],\n",
      "        [0.0000, 3.9146]], device='cuda:0', requires_grad=True)\n",
      "Episode [302/500] loss: 126.63, average reward: -175.13, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9387, 0.0000],\n",
      "        [0.0000, 3.9243]], device='cuda:0', requires_grad=True)\n",
      "Episode [303/500] loss: 95.52, average reward: -168.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9489, 0.0000],\n",
      "        [0.0000, 3.9340]], device='cuda:0', requires_grad=True)\n",
      "Episode [304/500] loss: 92.77, average reward: -157.24, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9588, 0.0000],\n",
      "        [0.0000, 3.9437]], device='cuda:0', requires_grad=True)\n",
      "Episode [305/500] loss: 104.56, average reward: -158.59, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9687, 0.0000],\n",
      "        [0.0000, 3.9534]], device='cuda:0', requires_grad=True)\n",
      "Episode [306/500] loss: 118.25, average reward: -172.47, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9787, 0.0000],\n",
      "        [0.0000, 3.9633]], device='cuda:0', requires_grad=True)\n",
      "Episode [307/500] loss: 85.60, average reward: -156.18, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9886, 0.0000],\n",
      "        [0.0000, 3.9731]], device='cuda:0', requires_grad=True)\n",
      "Episode [308/500] loss: 106.95, average reward: -170.33, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[3.9985, 0.0000],\n",
      "        [0.0000, 3.9829]], device='cuda:0', requires_grad=True)\n",
      "Episode [309/500] loss: 92.24, average reward: -174.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0083, 0.0000],\n",
      "        [0.0000, 3.9924]], device='cuda:0', requires_grad=True)\n",
      "Episode [310/500] loss: 96.68, average reward: -170.39, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0182, 0.0000],\n",
      "        [0.0000, 4.0019]], device='cuda:0', requires_grad=True)\n",
      "Episode [311/500] loss: 100.69, average reward: -173.92, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0280, 0.0000],\n",
      "        [0.0000, 4.0114]], device='cuda:0', requires_grad=True)\n",
      "Episode [312/500] loss: 96.05, average reward: -171.10, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0378, 0.0000],\n",
      "        [0.0000, 4.0208]], device='cuda:0', requires_grad=True)\n",
      "Episode [313/500] loss: 91.17, average reward: -149.98, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0474, 0.0000],\n",
      "        [0.0000, 4.0302]], device='cuda:0', requires_grad=True)\n",
      "Episode [314/500] loss: 83.84, average reward: -156.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0568, 0.0000],\n",
      "        [0.0000, 4.0394]], device='cuda:0', requires_grad=True)\n",
      "Episode [315/500] loss: 73.63, average reward: -158.28, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0661, 0.0000],\n",
      "        [0.0000, 4.0484]], device='cuda:0', requires_grad=True)\n",
      "Episode [316/500] loss: 87.08, average reward: -176.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0753, 0.0000],\n",
      "        [0.0000, 4.0572]], device='cuda:0', requires_grad=True)\n",
      "Episode [317/500] loss: 94.18, average reward: -161.27, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0844, 0.0000],\n",
      "        [0.0000, 4.0660]], device='cuda:0', requires_grad=True)\n",
      "Episode [318/500] loss: 105.70, average reward: -163.17, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.0937, 0.0000],\n",
      "        [0.0000, 4.0750]], device='cuda:0', requires_grad=True)\n",
      "Episode [319/500] loss: 112.88, average reward: -169.12, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1030, 0.0000],\n",
      "        [0.0000, 4.0840]], device='cuda:0', requires_grad=True)\n",
      "Episode [320/500] loss: 108.55, average reward: -163.94, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1124, 0.0000],\n",
      "        [0.0000, 4.0933]], device='cuda:0', requires_grad=True)\n",
      "Episode [321/500] loss: 97.19, average reward: -157.94, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1217, 0.0000],\n",
      "        [0.0000, 4.1025]], device='cuda:0', requires_grad=True)\n",
      "Episode [322/500] loss: 116.58, average reward: -176.61, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1313, 0.0000],\n",
      "        [0.0000, 4.1118]], device='cuda:0', requires_grad=True)\n",
      "Episode [323/500] loss: 106.03, average reward: -154.52, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1409, 0.0000],\n",
      "        [0.0000, 4.1211]], device='cuda:0', requires_grad=True)\n",
      "Episode [324/500] loss: 82.93, average reward: -179.60, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1504, 0.0000],\n",
      "        [0.0000, 4.1301]], device='cuda:0', requires_grad=True)\n",
      "Episode [325/500] loss: 112.75, average reward: -180.20, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1598, 0.0000],\n",
      "        [0.0000, 4.1395]], device='cuda:0', requires_grad=True)\n",
      "Episode [326/500] loss: 97.12, average reward: -176.21, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1692, 0.0000],\n",
      "        [0.0000, 4.1488]], device='cuda:0', requires_grad=True)\n",
      "Episode [327/500] loss: 104.44, average reward: -175.70, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1786, 0.0000],\n",
      "        [0.0000, 4.1580]], device='cuda:0', requires_grad=True)\n",
      "Episode [328/500] loss: 106.61, average reward: -155.03, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1882, 0.0000],\n",
      "        [0.0000, 4.1673]], device='cuda:0', requires_grad=True)\n",
      "Episode [329/500] loss: 96.19, average reward: -170.80, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.1976, 0.0000],\n",
      "        [0.0000, 4.1765]], device='cuda:0', requires_grad=True)\n",
      "Episode [330/500] loss: 100.13, average reward: -174.56, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2070, 0.0000],\n",
      "        [0.0000, 4.1858]], device='cuda:0', requires_grad=True)\n",
      "Episode [331/500] loss: 107.76, average reward: -165.62, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2163, 0.0000],\n",
      "        [0.0000, 4.1952]], device='cuda:0', requires_grad=True)\n",
      "Episode [332/500] loss: 108.81, average reward: -171.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2257, 0.0000],\n",
      "        [0.0000, 4.2046]], device='cuda:0', requires_grad=True)\n",
      "Episode [333/500] loss: 103.90, average reward: -163.57, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2352, 0.0000],\n",
      "        [0.0000, 4.2139]], device='cuda:0', requires_grad=True)\n",
      "Episode [334/500] loss: 114.63, average reward: -165.29, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2447, 0.0000],\n",
      "        [0.0000, 4.2234]], device='cuda:0', requires_grad=True)\n",
      "Episode [335/500] loss: 101.72, average reward: -182.46, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2541, 0.0000],\n",
      "        [0.0000, 4.2329]], device='cuda:0', requires_grad=True)\n",
      "Episode [336/500] loss: 117.71, average reward: -170.00, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2638, 0.0000],\n",
      "        [0.0000, 4.2423]], device='cuda:0', requires_grad=True)\n",
      "Episode [337/500] loss: 143.30, average reward: -181.56, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2737, 0.0000],\n",
      "        [0.0000, 4.2522]], device='cuda:0', requires_grad=True)\n",
      "Episode [338/500] loss: 113.80, average reward: -173.13, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2836, 0.0000],\n",
      "        [0.0000, 4.2621]], device='cuda:0', requires_grad=True)\n",
      "Episode [339/500] loss: 96.41, average reward: -167.78, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.2934, 0.0000],\n",
      "        [0.0000, 4.2718]], device='cuda:0', requires_grad=True)\n",
      "Episode [340/500] loss: 105.15, average reward: -170.46, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3033, 0.0000],\n",
      "        [0.0000, 4.2815]], device='cuda:0', requires_grad=True)\n",
      "Episode [341/500] loss: 95.76, average reward: -148.79, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3127, 0.0000],\n",
      "        [0.0000, 4.2913]], device='cuda:0', requires_grad=True)\n",
      "Episode [342/500] loss: 105.19, average reward: -184.90, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3221, 0.0000],\n",
      "        [0.0000, 4.3011]], device='cuda:0', requires_grad=True)\n",
      "Episode [343/500] loss: 100.67, average reward: -180.21, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3315, 0.0000],\n",
      "        [0.0000, 4.3107]], device='cuda:0', requires_grad=True)\n",
      "Episode [344/500] loss: 124.48, average reward: -172.93, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3413, 0.0000],\n",
      "        [0.0000, 4.3202]], device='cuda:0', requires_grad=True)\n",
      "Episode [345/500] loss: 109.82, average reward: -171.58, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3510, 0.0000],\n",
      "        [0.0000, 4.3298]], device='cuda:0', requires_grad=True)\n",
      "Episode [346/500] loss: 112.44, average reward: -179.67, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3608, 0.0000],\n",
      "        [0.0000, 4.3394]], device='cuda:0', requires_grad=True)\n",
      "Episode [347/500] loss: 105.21, average reward: -174.01, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3704, 0.0000],\n",
      "        [0.0000, 4.3491]], device='cuda:0', requires_grad=True)\n",
      "Episode [348/500] loss: 121.75, average reward: -180.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3801, 0.0000],\n",
      "        [0.0000, 4.3588]], device='cuda:0', requires_grad=True)\n",
      "Episode [349/500] loss: 122.31, average reward: -185.12, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3901, 0.0000],\n",
      "        [0.0000, 4.3684]], device='cuda:0', requires_grad=True)\n",
      "Episode [350/500] loss: 111.37, average reward: -162.00, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.3999, 0.0000],\n",
      "        [0.0000, 4.3783]], device='cuda:0', requires_grad=True)\n",
      "Episode [351/500] loss: 95.91, average reward: -165.82, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4095, 0.0000],\n",
      "        [0.0000, 4.3879]], device='cuda:0', requires_grad=True)\n",
      "Episode [352/500] loss: 109.95, average reward: -171.54, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4190, 0.0000],\n",
      "        [0.0000, 4.3977]], device='cuda:0', requires_grad=True)\n",
      "Episode [353/500] loss: 101.86, average reward: -162.21, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4283, 0.0000],\n",
      "        [0.0000, 4.4075]], device='cuda:0', requires_grad=True)\n",
      "Episode [354/500] loss: 107.41, average reward: -161.31, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4376, 0.0000],\n",
      "        [0.0000, 4.4174]], device='cuda:0', requires_grad=True)\n",
      "Episode [355/500] loss: 100.56, average reward: -173.64, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4466, 0.0000],\n",
      "        [0.0000, 4.4272]], device='cuda:0', requires_grad=True)\n",
      "Episode [356/500] loss: 94.45, average reward: -168.99, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4555, 0.0000],\n",
      "        [0.0000, 4.4370]], device='cuda:0', requires_grad=True)\n",
      "Episode [357/500] loss: 140.66, average reward: -182.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4648, 0.0000],\n",
      "        [0.0000, 4.4468]], device='cuda:0', requires_grad=True)\n",
      "Episode [358/500] loss: 101.43, average reward: -180.31, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4742, 0.0000],\n",
      "        [0.0000, 4.4565]], device='cuda:0', requires_grad=True)\n",
      "Episode [359/500] loss: 113.50, average reward: -178.24, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4835, 0.0000],\n",
      "        [0.0000, 4.4662]], device='cuda:0', requires_grad=True)\n",
      "Episode [360/500] loss: 102.13, average reward: -183.58, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.4927, 0.0000],\n",
      "        [0.0000, 4.4759]], device='cuda:0', requires_grad=True)\n",
      "Episode [361/500] loss: 122.45, average reward: -173.40, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5020, 0.0000],\n",
      "        [0.0000, 4.4857]], device='cuda:0', requires_grad=True)\n",
      "Episode [362/500] loss: 113.04, average reward: -168.30, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5111, 0.0000],\n",
      "        [0.0000, 4.4956]], device='cuda:0', requires_grad=True)\n",
      "Episode [363/500] loss: 114.09, average reward: -187.26, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5205, 0.0000],\n",
      "        [0.0000, 4.5054]], device='cuda:0', requires_grad=True)\n",
      "Episode [364/500] loss: 113.96, average reward: -172.28, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5299, 0.0000],\n",
      "        [0.0000, 4.5151]], device='cuda:0', requires_grad=True)\n",
      "Episode [365/500] loss: 104.94, average reward: -189.98, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5392, 0.0000],\n",
      "        [0.0000, 4.5248]], device='cuda:0', requires_grad=True)\n",
      "Episode [366/500] loss: 113.34, average reward: -163.00, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5485, 0.0000],\n",
      "        [0.0000, 4.5345]], device='cuda:0', requires_grad=True)\n",
      "Episode [367/500] loss: 95.40, average reward: -164.30, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5576, 0.0000],\n",
      "        [0.0000, 4.5441]], device='cuda:0', requires_grad=True)\n",
      "Episode [368/500] loss: 115.99, average reward: -181.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5669, 0.0000],\n",
      "        [0.0000, 4.5535]], device='cuda:0', requires_grad=True)\n",
      "Episode [369/500] loss: 106.99, average reward: -161.09, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5762, 0.0000],\n",
      "        [0.0000, 4.5630]], device='cuda:0', requires_grad=True)\n",
      "Episode [370/500] loss: 99.21, average reward: -169.14, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5854, 0.0000],\n",
      "        [0.0000, 4.5723]], device='cuda:0', requires_grad=True)\n",
      "Episode [371/500] loss: 123.36, average reward: -184.18, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.5947, 0.0000],\n",
      "        [0.0000, 4.5817]], device='cuda:0', requires_grad=True)\n",
      "Episode [372/500] loss: 124.77, average reward: -187.51, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6042, 0.0000],\n",
      "        [0.0000, 4.5911]], device='cuda:0', requires_grad=True)\n",
      "Episode [373/500] loss: 111.46, average reward: -172.84, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6138, 0.0000],\n",
      "        [0.0000, 4.6004]], device='cuda:0', requires_grad=True)\n",
      "Episode [374/500] loss: 98.80, average reward: -151.24, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6233, 0.0000],\n",
      "        [0.0000, 4.6095]], device='cuda:0', requires_grad=True)\n",
      "Episode [375/500] loss: 115.11, average reward: -177.63, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6329, 0.0000],\n",
      "        [0.0000, 4.6186]], device='cuda:0', requires_grad=True)\n",
      "Episode [376/500] loss: 116.84, average reward: -168.68, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6425, 0.0000],\n",
      "        [0.0000, 4.6277]], device='cuda:0', requires_grad=True)\n",
      "Episode [377/500] loss: 113.26, average reward: -177.30, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6519, 0.0000],\n",
      "        [0.0000, 4.6371]], device='cuda:0', requires_grad=True)\n",
      "Episode [378/500] loss: 112.89, average reward: -179.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6614, 0.0000],\n",
      "        [0.0000, 4.6463]], device='cuda:0', requires_grad=True)\n",
      "Episode [379/500] loss: 109.36, average reward: -186.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6708, 0.0000],\n",
      "        [0.0000, 4.6556]], device='cuda:0', requires_grad=True)\n",
      "Episode [380/500] loss: 98.90, average reward: -188.18, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6800, 0.0000],\n",
      "        [0.0000, 4.6648]], device='cuda:0', requires_grad=True)\n",
      "Episode [381/500] loss: 116.05, average reward: -175.58, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6894, 0.0000],\n",
      "        [0.0000, 4.6739]], device='cuda:0', requires_grad=True)\n",
      "Episode [382/500] loss: 126.34, average reward: -177.36, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.6986, 0.0000],\n",
      "        [0.0000, 4.6834]], device='cuda:0', requires_grad=True)\n",
      "Episode [383/500] loss: 96.55, average reward: -176.98, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7077, 0.0000],\n",
      "        [0.0000, 4.6927]], device='cuda:0', requires_grad=True)\n",
      "Episode [384/500] loss: 105.88, average reward: -165.70, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7169, 0.0000],\n",
      "        [0.0000, 4.7018]], device='cuda:0', requires_grad=True)\n",
      "Episode [385/500] loss: 108.35, average reward: -189.70, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7262, 0.0000],\n",
      "        [0.0000, 4.7108]], device='cuda:0', requires_grad=True)\n",
      "Episode [386/500] loss: 126.08, average reward: -188.98, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7355, 0.0000],\n",
      "        [0.0000, 4.7199]], device='cuda:0', requires_grad=True)\n",
      "Episode [387/500] loss: 89.48, average reward: -166.77, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7446, 0.0000],\n",
      "        [0.0000, 4.7289]], device='cuda:0', requires_grad=True)\n",
      "Episode [388/500] loss: 154.22, average reward: -191.19, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7540, 0.0000],\n",
      "        [0.0000, 4.7382]], device='cuda:0', requires_grad=True)\n",
      "Episode [389/500] loss: 132.22, average reward: -191.38, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7638, 0.0000],\n",
      "        [0.0000, 4.7475]], device='cuda:0', requires_grad=True)\n",
      "Episode [390/500] loss: 101.69, average reward: -164.59, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7734, 0.0000],\n",
      "        [0.0000, 4.7567]], device='cuda:0', requires_grad=True)\n",
      "Episode [391/500] loss: 140.70, average reward: -183.94, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7832, 0.0000],\n",
      "        [0.0000, 4.7660]], device='cuda:0', requires_grad=True)\n",
      "Episode [392/500] loss: 102.98, average reward: -178.01, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.7928, 0.0000],\n",
      "        [0.0000, 4.7752]], device='cuda:0', requires_grad=True)\n",
      "Episode [393/500] loss: 131.84, average reward: -195.11, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8026, 0.0000],\n",
      "        [0.0000, 4.7846]], device='cuda:0', requires_grad=True)\n",
      "Episode [394/500] loss: 139.54, average reward: -199.74, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8123, 0.0000],\n",
      "        [0.0000, 4.7943]], device='cuda:0', requires_grad=True)\n",
      "Episode [395/500] loss: 109.91, average reward: -198.05, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8219, 0.0000],\n",
      "        [0.0000, 4.8039]], device='cuda:0', requires_grad=True)\n",
      "Episode [396/500] loss: 109.65, average reward: -181.02, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8315, 0.0000],\n",
      "        [0.0000, 4.8134]], device='cuda:0', requires_grad=True)\n",
      "Episode [397/500] loss: 124.90, average reward: -179.48, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8411, 0.0000],\n",
      "        [0.0000, 4.8229]], device='cuda:0', requires_grad=True)\n",
      "Episode [398/500] loss: 100.32, average reward: -195.81, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8507, 0.0000],\n",
      "        [0.0000, 4.8322]], device='cuda:0', requires_grad=True)\n",
      "Episode [399/500] loss: 161.56, average reward: -198.41, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8605, 0.0000],\n",
      "        [0.0000, 4.8418]], device='cuda:0', requires_grad=True)\n",
      "Episode [400/500] loss: 161.97, average reward: -203.03, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8704, 0.0000],\n",
      "        [0.0000, 4.8520]], device='cuda:0', requires_grad=True)\n",
      "Episode [401/500] loss: 156.29, average reward: -200.89, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8803, 0.0000],\n",
      "        [0.0000, 4.8627]], device='cuda:0', requires_grad=True)\n",
      "Episode [402/500] loss: 146.07, average reward: -201.66, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.8903, 0.0000],\n",
      "        [0.0000, 4.8733]], device='cuda:0', requires_grad=True)\n",
      "Episode [403/500] loss: 133.57, average reward: -195.66, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9004, 0.0000],\n",
      "        [0.0000, 4.8840]], device='cuda:0', requires_grad=True)\n",
      "Episode [404/500] loss: 136.39, average reward: -193.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9105, 0.0000],\n",
      "        [0.0000, 4.8947]], device='cuda:0', requires_grad=True)\n",
      "Episode [405/500] loss: 127.72, average reward: -191.87, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9203, 0.0000],\n",
      "        [0.0000, 4.9056]], device='cuda:0', requires_grad=True)\n",
      "Episode [406/500] loss: 114.44, average reward: -192.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9301, 0.0000],\n",
      "        [0.0000, 4.9163]], device='cuda:0', requires_grad=True)\n",
      "Episode [407/500] loss: 130.68, average reward: -196.96, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9401, 0.0000],\n",
      "        [0.0000, 4.9267]], device='cuda:0', requires_grad=True)\n",
      "Episode [408/500] loss: 124.29, average reward: -171.89, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9499, 0.0000],\n",
      "        [0.0000, 4.9371]], device='cuda:0', requires_grad=True)\n",
      "Episode [409/500] loss: 106.13, average reward: -167.86, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9595, 0.0000],\n",
      "        [0.0000, 4.9475]], device='cuda:0', requires_grad=True)\n",
      "Episode [410/500] loss: 131.36, average reward: -202.29, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9692, 0.0000],\n",
      "        [0.0000, 4.9577]], device='cuda:0', requires_grad=True)\n",
      "Episode [411/500] loss: 125.60, average reward: -182.49, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9790, 0.0000],\n",
      "        [0.0000, 4.9678]], device='cuda:0', requires_grad=True)\n",
      "Episode [412/500] loss: 113.85, average reward: -181.93, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9888, 0.0000],\n",
      "        [0.0000, 4.9777]], device='cuda:0', requires_grad=True)\n",
      "Episode [413/500] loss: 146.50, average reward: -204.20, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[4.9989, 0.0000],\n",
      "        [0.0000, 4.9876]], device='cuda:0', requires_grad=True)\n",
      "Episode [414/500] loss: 120.91, average reward: -187.55, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0089, 0.0000],\n",
      "        [0.0000, 4.9974]], device='cuda:0', requires_grad=True)\n",
      "Episode [415/500] loss: 162.69, average reward: -205.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0192, 0.0000],\n",
      "        [0.0000, 5.0073]], device='cuda:0', requires_grad=True)\n",
      "Episode [416/500] loss: 140.78, average reward: -206.97, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0298, 0.0000],\n",
      "        [0.0000, 5.0172]], device='cuda:0', requires_grad=True)\n",
      "Episode [417/500] loss: 135.45, average reward: -189.22, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0404, 0.0000],\n",
      "        [0.0000, 5.0270]], device='cuda:0', requires_grad=True)\n",
      "Episode [418/500] loss: 136.54, average reward: -205.29, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0507, 0.0000],\n",
      "        [0.0000, 5.0371]], device='cuda:0', requires_grad=True)\n",
      "Episode [419/500] loss: 119.19, average reward: -187.99, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0611, 0.0000],\n",
      "        [0.0000, 5.0470]], device='cuda:0', requires_grad=True)\n",
      "Episode [420/500] loss: 138.35, average reward: -193.31, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0714, 0.0000],\n",
      "        [0.0000, 5.0569]], device='cuda:0', requires_grad=True)\n",
      "Episode [421/500] loss: 107.63, average reward: -176.65, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0816, 0.0000],\n",
      "        [0.0000, 5.0666]], device='cuda:0', requires_grad=True)\n",
      "Episode [422/500] loss: 130.75, average reward: -191.18, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.0918, 0.0000],\n",
      "        [0.0000, 5.0762]], device='cuda:0', requires_grad=True)\n",
      "Episode [423/500] loss: 117.64, average reward: -187.59, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1018, 0.0000],\n",
      "        [0.0000, 5.0859]], device='cuda:0', requires_grad=True)\n",
      "Episode [424/500] loss: 147.59, average reward: -202.96, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1120, 0.0000],\n",
      "        [0.0000, 5.0956]], device='cuda:0', requires_grad=True)\n",
      "Episode [425/500] loss: 125.83, average reward: -176.62, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1218, 0.0000],\n",
      "        [0.0000, 5.1056]], device='cuda:0', requires_grad=True)\n",
      "Episode [426/500] loss: 143.03, average reward: -210.62, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1317, 0.0000],\n",
      "        [0.0000, 5.1157]], device='cuda:0', requires_grad=True)\n",
      "Episode [427/500] loss: 144.78, average reward: -179.63, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1416, 0.0000],\n",
      "        [0.0000, 5.1259]], device='cuda:0', requires_grad=True)\n",
      "Episode [428/500] loss: 137.81, average reward: -203.17, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1515, 0.0000],\n",
      "        [0.0000, 5.1361]], device='cuda:0', requires_grad=True)\n",
      "Episode [429/500] loss: 151.37, average reward: -213.71, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1615, 0.0000],\n",
      "        [0.0000, 5.1465]], device='cuda:0', requires_grad=True)\n",
      "Episode [430/500] loss: 131.35, average reward: -191.29, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1713, 0.0000],\n",
      "        [0.0000, 5.1569]], device='cuda:0', requires_grad=True)\n",
      "Episode [431/500] loss: 144.39, average reward: -191.75, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1813, 0.0000],\n",
      "        [0.0000, 5.1674]], device='cuda:0', requires_grad=True)\n",
      "Episode [432/500] loss: 129.16, average reward: -204.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.1911, 0.0000],\n",
      "        [0.0000, 5.1778]], device='cuda:0', requires_grad=True)\n",
      "Episode [433/500] loss: 124.31, average reward: -185.94, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2009, 0.0000],\n",
      "        [0.0000, 5.1881]], device='cuda:0', requires_grad=True)\n",
      "Episode [434/500] loss: 116.87, average reward: -177.61, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2106, 0.0000],\n",
      "        [0.0000, 5.1981]], device='cuda:0', requires_grad=True)\n",
      "Episode [435/500] loss: 170.61, average reward: -206.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2206, 0.0000],\n",
      "        [0.0000, 5.2084]], device='cuda:0', requires_grad=True)\n",
      "Episode [436/500] loss: 159.86, average reward: -208.62, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2308, 0.0000],\n",
      "        [0.0000, 5.2188]], device='cuda:0', requires_grad=True)\n",
      "Episode [437/500] loss: 130.36, average reward: -213.49, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2408, 0.0000],\n",
      "        [0.0000, 5.2292]], device='cuda:0', requires_grad=True)\n",
      "Episode [438/500] loss: 119.50, average reward: -189.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2506, 0.0000],\n",
      "        [0.0000, 5.2396]], device='cuda:0', requires_grad=True)\n",
      "Episode [439/500] loss: 114.58, average reward: -187.09, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2603, 0.0000],\n",
      "        [0.0000, 5.2498]], device='cuda:0', requires_grad=True)\n",
      "Episode [440/500] loss: 139.30, average reward: -194.01, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2698, 0.0000],\n",
      "        [0.0000, 5.2600]], device='cuda:0', requires_grad=True)\n",
      "Episode [441/500] loss: 128.18, average reward: -193.36, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2794, 0.0000],\n",
      "        [0.0000, 5.2702]], device='cuda:0', requires_grad=True)\n",
      "Episode [442/500] loss: 168.89, average reward: -198.19, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2894, 0.0000],\n",
      "        [0.0000, 5.2804]], device='cuda:0', requires_grad=True)\n",
      "Episode [443/500] loss: 155.69, average reward: -212.97, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.2996, 0.0000],\n",
      "        [0.0000, 5.2906]], device='cuda:0', requires_grad=True)\n",
      "Episode [444/500] loss: 161.34, average reward: -208.87, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3098, 0.0000],\n",
      "        [0.0000, 5.3011]], device='cuda:0', requires_grad=True)\n",
      "Episode [445/500] loss: 154.17, average reward: -209.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3200, 0.0000],\n",
      "        [0.0000, 5.3117]], device='cuda:0', requires_grad=True)\n",
      "Episode [446/500] loss: 135.89, average reward: -196.42, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3302, 0.0000],\n",
      "        [0.0000, 5.3222]], device='cuda:0', requires_grad=True)\n",
      "Episode [447/500] loss: 114.74, average reward: -180.94, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3402, 0.0000],\n",
      "        [0.0000, 5.3325]], device='cuda:0', requires_grad=True)\n",
      "Episode [448/500] loss: 127.52, average reward: -207.55, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3502, 0.0000],\n",
      "        [0.0000, 5.3426]], device='cuda:0', requires_grad=True)\n",
      "Episode [449/500] loss: 163.97, average reward: -198.29, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3604, 0.0000],\n",
      "        [0.0000, 5.3527]], device='cuda:0', requires_grad=True)\n",
      "Episode [450/500] loss: 156.10, average reward: -210.47, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3707, 0.0000],\n",
      "        [0.0000, 5.3630]], device='cuda:0', requires_grad=True)\n",
      "Episode [451/500] loss: 115.54, average reward: -198.65, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3809, 0.0000],\n",
      "        [0.0000, 5.3730]], device='cuda:0', requires_grad=True)\n",
      "Episode [452/500] loss: 155.55, average reward: -209.01, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.3909, 0.0000],\n",
      "        [0.0000, 5.3833]], device='cuda:0', requires_grad=True)\n",
      "Episode [453/500] loss: 139.27, average reward: -185.88, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4010, 0.0000],\n",
      "        [0.0000, 5.3935]], device='cuda:0', requires_grad=True)\n",
      "Episode [454/500] loss: 135.32, average reward: -209.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4112, 0.0000],\n",
      "        [0.0000, 5.4035]], device='cuda:0', requires_grad=True)\n",
      "Episode [455/500] loss: 133.67, average reward: -191.15, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4214, 0.0000],\n",
      "        [0.0000, 5.4133]], device='cuda:0', requires_grad=True)\n",
      "Episode [456/500] loss: 156.54, average reward: -208.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4317, 0.0000],\n",
      "        [0.0000, 5.4232]], device='cuda:0', requires_grad=True)\n",
      "Episode [457/500] loss: 121.59, average reward: -195.24, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4418, 0.0000],\n",
      "        [0.0000, 5.4330]], device='cuda:0', requires_grad=True)\n",
      "Episode [458/500] loss: 113.84, average reward: -171.33, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4517, 0.0000],\n",
      "        [0.0000, 5.4426]], device='cuda:0', requires_grad=True)\n",
      "Episode [459/500] loss: 150.10, average reward: -203.92, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4619, 0.0000],\n",
      "        [0.0000, 5.4522]], device='cuda:0', requires_grad=True)\n",
      "Episode [460/500] loss: 146.61, average reward: -220.15, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4720, 0.0000],\n",
      "        [0.0000, 5.4618]], device='cuda:0', requires_grad=True)\n",
      "Episode [461/500] loss: 153.30, average reward: -220.13, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4820, 0.0000],\n",
      "        [0.0000, 5.4717]], device='cuda:0', requires_grad=True)\n",
      "Episode [462/500] loss: 98.65, average reward: -179.30, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.4917, 0.0000],\n",
      "        [0.0000, 5.4813]], device='cuda:0', requires_grad=True)\n",
      "Episode [463/500] loss: 134.87, average reward: -219.26, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5015, 0.0000],\n",
      "        [0.0000, 5.4908]], device='cuda:0', requires_grad=True)\n",
      "Episode [464/500] loss: 130.08, average reward: -205.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5113, 0.0000],\n",
      "        [0.0000, 5.5001]], device='cuda:0', requires_grad=True)\n",
      "Episode [465/500] loss: 144.60, average reward: -187.37, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5212, 0.0000],\n",
      "        [0.0000, 5.5095]], device='cuda:0', requires_grad=True)\n",
      "Episode [466/500] loss: 140.70, average reward: -201.00, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5311, 0.0000],\n",
      "        [0.0000, 5.5189]], device='cuda:0', requires_grad=True)\n",
      "Episode [467/500] loss: 129.38, average reward: -194.40, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5409, 0.0000],\n",
      "        [0.0000, 5.5282]], device='cuda:0', requires_grad=True)\n",
      "Episode [468/500] loss: 151.98, average reward: -220.75, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5507, 0.0000],\n",
      "        [0.0000, 5.5377]], device='cuda:0', requires_grad=True)\n",
      "Episode [469/500] loss: 138.23, average reward: -208.82, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5605, 0.0000],\n",
      "        [0.0000, 5.5471]], device='cuda:0', requires_grad=True)\n",
      "Episode [470/500] loss: 124.06, average reward: -199.80, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5703, 0.0000],\n",
      "        [0.0000, 5.5564]], device='cuda:0', requires_grad=True)\n",
      "Episode [471/500] loss: 119.83, average reward: -191.12, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5799, 0.0000],\n",
      "        [0.0000, 5.5657]], device='cuda:0', requires_grad=True)\n",
      "Episode [472/500] loss: 139.25, average reward: -220.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5892, 0.0000],\n",
      "        [0.0000, 5.5752]], device='cuda:0', requires_grad=True)\n",
      "Episode [473/500] loss: 141.11, average reward: -212.67, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.5987, 0.0000],\n",
      "        [0.0000, 5.5846]], device='cuda:0', requires_grad=True)\n",
      "Episode [474/500] loss: 146.69, average reward: -217.28, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6082, 0.0000],\n",
      "        [0.0000, 5.5940]], device='cuda:0', requires_grad=True)\n",
      "Episode [475/500] loss: 161.33, average reward: -221.35, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6180, 0.0000],\n",
      "        [0.0000, 5.6036]], device='cuda:0', requires_grad=True)\n",
      "Episode [476/500] loss: 117.05, average reward: -199.12, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6277, 0.0000],\n",
      "        [0.0000, 5.6129]], device='cuda:0', requires_grad=True)\n",
      "Episode [477/500] loss: 142.27, average reward: -205.82, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6372, 0.0000],\n",
      "        [0.0000, 5.6224]], device='cuda:0', requires_grad=True)\n",
      "Episode [478/500] loss: 142.49, average reward: -209.22, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6467, 0.0000],\n",
      "        [0.0000, 5.6320]], device='cuda:0', requires_grad=True)\n",
      "Episode [479/500] loss: 134.48, average reward: -203.35, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6563, 0.0000],\n",
      "        [0.0000, 5.6413]], device='cuda:0', requires_grad=True)\n",
      "Episode [480/500] loss: 158.59, average reward: -226.12, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6662, 0.0000],\n",
      "        [0.0000, 5.6507]], device='cuda:0', requires_grad=True)\n",
      "Episode [481/500] loss: 174.47, average reward: -224.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6762, 0.0000],\n",
      "        [0.0000, 5.6603]], device='cuda:0', requires_grad=True)\n",
      "Episode [482/500] loss: 135.97, average reward: -205.97, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6860, 0.0000],\n",
      "        [0.0000, 5.6700]], device='cuda:0', requires_grad=True)\n",
      "Episode [483/500] loss: 150.33, average reward: -206.35, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.6960, 0.0000],\n",
      "        [0.0000, 5.6796]], device='cuda:0', requires_grad=True)\n",
      "Episode [484/500] loss: 152.35, average reward: -203.89, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7059, 0.0000],\n",
      "        [0.0000, 5.6893]], device='cuda:0', requires_grad=True)\n",
      "Episode [485/500] loss: 161.78, average reward: -222.26, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7160, 0.0000],\n",
      "        [0.0000, 5.6991]], device='cuda:0', requires_grad=True)\n",
      "Episode [486/500] loss: 154.45, average reward: -213.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7260, 0.0000],\n",
      "        [0.0000, 5.7090]], device='cuda:0', requires_grad=True)\n",
      "Episode [487/500] loss: 159.11, average reward: -208.95, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7361, 0.0000],\n",
      "        [0.0000, 5.7190]], device='cuda:0', requires_grad=True)\n",
      "Episode [488/500] loss: 136.93, average reward: -226.48, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7460, 0.0000],\n",
      "        [0.0000, 5.7290]], device='cuda:0', requires_grad=True)\n",
      "Episode [489/500] loss: 145.37, average reward: -220.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7558, 0.0000],\n",
      "        [0.0000, 5.7390]], device='cuda:0', requires_grad=True)\n",
      "Episode [490/500] loss: 145.23, average reward: -221.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7656, 0.0000],\n",
      "        [0.0000, 5.7491]], device='cuda:0', requires_grad=True)\n",
      "Episode [491/500] loss: 123.89, average reward: -206.98, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7753, 0.0000],\n",
      "        [0.0000, 5.7588]], device='cuda:0', requires_grad=True)\n",
      "Episode [492/500] loss: 171.37, average reward: -209.66, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7852, 0.0000],\n",
      "        [0.0000, 5.7688]], device='cuda:0', requires_grad=True)\n",
      "Episode [493/500] loss: 151.59, average reward: -224.74, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.7949, 0.0000],\n",
      "        [0.0000, 5.7788]], device='cuda:0', requires_grad=True)\n",
      "Episode [494/500] loss: 117.94, average reward: -196.61, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.8045, 0.0000],\n",
      "        [0.0000, 5.7886]], device='cuda:0', requires_grad=True)\n",
      "Episode [495/500] loss: 127.76, average reward: -208.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.8141, 0.0000],\n",
      "        [0.0000, 5.7982]], device='cuda:0', requires_grad=True)\n",
      "Episode [496/500] loss: 135.49, average reward: -207.02, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.8235, 0.0000],\n",
      "        [0.0000, 5.8078]], device='cuda:0', requires_grad=True)\n",
      "Episode [497/500] loss: 168.54, average reward: -221.49, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.8331, 0.0000],\n",
      "        [0.0000, 5.8176]], device='cuda:0', requires_grad=True)\n",
      "Episode [498/500] loss: 151.16, average reward: -227.14, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.8427, 0.0000],\n",
      "        [0.0000, 5.8274]], device='cuda:0', requires_grad=True)\n",
      "Episode [499/500] loss: 128.84, average reward: -194.96, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[5.8522, 0.0000],\n",
      "        [0.0000, 5.8370]], device='cuda:0', requires_grad=True)\n",
      "Episode [500/500] loss: 191.13, average reward: -224.77, trajectory num: 14\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('modified_gym_env:ReacherPyBulletEnv-v1', rand_init=False)\n",
    "# env.render()\n",
    "# TODO: test\n",
    "state = env.reset()\n",
    "print(state)\n",
    "\n",
    "# setup network\n",
    "policy_network = PolicyNetwork(env).to(device)\n",
    "average_reward_list = reinforce_with_baseline(env, policy_network,batch_size=2000, num_episodes=500,\n",
    "                                              lr=0.01, gamma=0.9, enable_baseline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(average_reward_list)\n",
    "plt.xlabel('episode')\n",
    "plt.ylabel('average reward')\n",
    "plt.title('Question 2 Average Rewards at Each Iteration')\n",
    "plt.savefig('Question_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p2_policy.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(policy_network, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options= \n",
      "Finished in 150 steps\n"
     ]
    }
   ],
   "source": [
    "# load policy\n",
    "# with open('p2_policy.pkl', 'rb') as pickle_file:\n",
    "#     policy_network = pickle.load(pickle_file)\n",
    "\n",
    "# test policy\n",
    "env = gym.make('modified_gym_env:ReacherPyBulletEnv-v1', rand_init=False)\n",
    "# env.render()\n",
    "state = env.reset()\n",
    "done = False\n",
    "steps = 0\n",
    "\n",
    "while not done:\n",
    "    # TODO: do not sample here\n",
    "    action, log_prob = choose_action(policy_network, state)\n",
    "    state_next, reward, done, _ = env.step(action)\n",
    "    steps += 1\n",
    "\n",
    "print('Finished in {} steps'.format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
