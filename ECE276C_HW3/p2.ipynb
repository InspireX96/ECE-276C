{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 276C HW3 P2\n",
    "Mingwei Xu A53270271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gym\n",
    "import pybulletgym.envs\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cuda\n",
      "GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "# setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device :', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Policy Network using MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        :param env: object, gym environment\n",
    "        \"\"\"\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        # get state space and action space dimension\n",
    "        self.state_space_n = env.observation_space.shape[0] - 1   # should be 8 (TODO: bug in env showing wrong observation space?)\n",
    "        self.action_space_n = env.action_space.shape[0]   # should be 2\n",
    "\n",
    "        # define layers\n",
    "        self.l1 = nn.Linear(self.state_space_n, 128)\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.l3 = nn.Linear(64, self.action_space_n)\n",
    "\n",
    "        self.sigma = nn.Parameter(torch.eye(2))     # initalize cov matrix with grad fn\n",
    "#         self.sigma = nn.Parameter(torch.diag(torch.rand(2)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Feed forward\n",
    "        \n",
    "        :param x: np array, state\n",
    "        :return: tensor, softmax probability of action\n",
    "        \"\"\"\n",
    "        # TODO: take sigma as input\n",
    "        # build neural network\n",
    "        network = nn.Sequential(\n",
    "            self.l1,\n",
    "            nn.Tanh(),\n",
    "            self.l2,\n",
    "            nn.Tanh(),\n",
    "            self.l3,\n",
    "            nn.Tanh())\n",
    "\n",
    "        return network(torch.FloatTensor(x).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(policy_network, state):\n",
    "    \"\"\"\n",
    "    Choose action according to policy on given state\n",
    "\n",
    "    :param policy_network: object, policy network\n",
    "    :param state: np array, state\n",
    "    :returns: list (len=2), action; tensor with grad fn, log probability\n",
    "    \"\"\"\n",
    "    probs = policy_network.forward(state)   # mean from policy network output\n",
    "\n",
    "    cov = torch.abs(policy_network.sigma) + 1e-3    # positive definite\n",
    "\n",
    "    m = MultivariateNormal(probs, cov)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.tolist(), log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(env, policy_network, batch_size=500, num_episodes=200, lr=0.01, gamma=0.99):\n",
    "    \"\"\"\n",
    "    Policy gradient training using reinforce method\n",
    "\n",
    "    :param env: object, gym environment\n",
    "    :param policy_network: object, policy network\n",
    "    :param batch_size: int, batch size\n",
    "    :param num_episodes: int, number of episodes\n",
    "    :param lr: float, learning rate\n",
    "    :param gamma: float (0~1), discount factor\n",
    "    :return: list of average reward on each episode\n",
    "    \"\"\"\n",
    "    # setup place holders\n",
    "    average_reward_list = []  # store step over episode\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(policy_network.parameters(), \n",
    "                           lr=lr)\n",
    "\n",
    "    # train\n",
    "    for i in range(num_episodes):\n",
    "        # setup placeholders for each batch\n",
    "        batch_loss_sum = 0\n",
    "        batch_traj_counter = 0\n",
    "        batch_rewards = []\n",
    "\n",
    "        # setup placeholders for each trajectory\n",
    "        traj_rewards = []\n",
    "        traj_log_prob_sum = 0\n",
    "\n",
    "        # reset environment\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        # batch\n",
    "        for step in range(batch_size):\n",
    "            # exploration\n",
    "            action, log_prob = choose_action(policy_network, state)\n",
    "            state_next, reward, done, _ = env.step(action)\n",
    "            # env.render()\n",
    "\n",
    "            # store data\n",
    "            traj_rewards.append(reward)\n",
    "            traj_log_prob_sum += log_prob\n",
    "\n",
    "            # move on\n",
    "            if done or (step == batch_size - 1):\n",
    "                # trajectory or batch finished, update trajectory\n",
    "                traj_discounted_return = torch.sum(torch.FloatTensor(traj_rewards).to(device) *\n",
    "                                                   torch.FloatTensor([gamma ** t for t in range(1, len(traj_rewards) + 1)]).to(device))  # G(t)\n",
    "                batch_loss_sum += traj_discounted_return * traj_log_prob_sum\n",
    "                \n",
    "                # reset state\n",
    "                batch_rewards.append(np.sum(traj_rewards))\n",
    "                batch_traj_counter += 1\n",
    "\n",
    "                traj_rewards = []\n",
    "                traj_log_prob_sum = 0\n",
    "\n",
    "                state = env.reset()\n",
    "            else:\n",
    "                state = state_next\n",
    "\n",
    "        # finish batch\n",
    "        average_batch_reward = np.mean(batch_rewards)\n",
    "        average_reward_list.append(average_batch_reward)\n",
    "        loss = - batch_loss_sum / batch_traj_counter\n",
    "        \n",
    "        print('Episode [{}/{}] loss: {:.2f}, average reward: {:.2f}, trajectory num: {}'.format(i + 1, num_episodes,\n",
    "                               loss.item(), average_batch_reward, batch_traj_counter))\n",
    "\n",
    "        # update policy\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return average_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_with_baseline(env, policy_network, batch_size=500, num_episodes=200, lr=0.01, gamma=0.99, enable_baseline=False):\n",
    "    \"\"\"\n",
    "    Policy gradient training using modified reinforce method with baseline\n",
    "\n",
    "    :param env: object, gym environment\n",
    "    :param policy_network: object, policy network\n",
    "    :param batch_size: int, batch size\n",
    "    :param num_episodes: int, number of episodes\n",
    "    :param lr: float, learning rate\n",
    "    :param gamma: float (0~1), discount factor\n",
    "    :param enable_baseline: bool, flag to enable baseline, defaults to False\n",
    "    :return: list of average reward on each episode\n",
    "    \"\"\"\n",
    "    # setup place holders\n",
    "    average_reward_list = []  # store step over episode\n",
    "    average_step_list = []\n",
    "\n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(policy_network.parameters(), \n",
    "                           lr=lr)\n",
    "\n",
    "    # train\n",
    "    for i in range(num_episodes):\n",
    "        # setup placeholders for each batch\n",
    "        batch_loss_sum = 0\n",
    "        batch_traj_counter = 0\n",
    "        batch_rewards = []\n",
    "        batch_traj_steps = []\n",
    "\n",
    "        # setup placeholders for each trajectory\n",
    "        traj_loss_sum = 0\n",
    "        traj_rewards = []\n",
    "        traj_log_prob_list = []\n",
    "        traj_step_counter = 0\n",
    "\n",
    "        # reset environment\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        # batch\n",
    "        for step in range(batch_size):\n",
    "            # exploration\n",
    "            action, log_prob = choose_action(policy_network, state)\n",
    "            state_next, reward, done, _ = env.step(action)\n",
    "            traj_step_counter += 1\n",
    "            # env.render()\n",
    "\n",
    "            # store data\n",
    "            traj_rewards.append(reward)\n",
    "            traj_log_prob_list.append(log_prob)\n",
    "\n",
    "            # move on\n",
    "            if done or (step == batch_size - 1):\n",
    "                # trajectory or batch finished, update trajectory\n",
    "                discounted_return_list = []\n",
    "                discounted_return_list = [sum([gamma ** (t_prime - t) * traj_rewards[t_prime] for t_prime in range(t, len(traj_rewards))]) \\\n",
    "                                          for t in range(len(traj_rewards))]    # TODO\n",
    "                if enable_baseline:\n",
    "                    # substract discounted return list by its mean\n",
    "                    discounted_return_list = np.array(discounted_return_list) - np.mean(discounted_return_list)\n",
    "\n",
    "                # sum the traj loss by loop so we do not lose tensor gradient\n",
    "                traj_loss_sum = 0\n",
    "                for t in range(len(traj_log_prob_list)):\n",
    "                    traj_loss_sum += traj_log_prob_list[t] * discounted_return_list[t]\n",
    "                batch_loss_sum += traj_loss_sum\n",
    "                \n",
    "                # reset state\n",
    "                batch_rewards.append(np.sum(traj_rewards))\n",
    "                batch_traj_counter += 1\n",
    "                batch_traj_steps.append(traj_step_counter)\n",
    "\n",
    "                traj_step_counter = 0\n",
    "                traj_loss_sum = 0\n",
    "                traj_rewards = []\n",
    "                traj_log_prob_list = []\n",
    "\n",
    "                state = env.reset()\n",
    "            else:\n",
    "                state = state_next\n",
    "\n",
    "        # finish batch\n",
    "        average_batch_reward = np.mean(batch_rewards)\n",
    "        average_reward_list.append(average_batch_reward)\n",
    "        average_step_list.append(np.mean(batch_traj_steps))\n",
    "        loss = - batch_loss_sum / batch_traj_counter    # TODO\n",
    "        \n",
    "        print('TODO: sigma: ', policy_network.sigma)    # TODO\n",
    "        print('Episode [{}/{}] loss: {:.2f}, average reward: {:.2f}, trajectory num: {}'.format(i + 1, num_episodes,\n",
    "                               loss.item(), average_batch_reward, batch_traj_counter))\n",
    "\n",
    "        # update policy\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return average_reward_list, average_step_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/home/cvv5233/anaconda3/lib/python3.7/site-packages/pybullet_envs/bullet\n",
      "options= \n",
      "[ 0.3928371   0.3928371  -0.68091764  0.26561381  0.5         0.\n",
      "  0.08333333  0.        ]\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.]], device='cuda:0', requires_grad=True)\n",
      "Episode [1/500] loss: -26.79, average reward: -51.07, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9900, 0.0000],\n",
      "        [0.0000, 0.9900]], device='cuda:0', requires_grad=True)\n",
      "Episode [2/500] loss: -24.32, average reward: -52.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9801, 0.0000],\n",
      "        [0.0000, 0.9800]], device='cuda:0', requires_grad=True)\n",
      "Episode [3/500] loss: -25.98, average reward: -57.94, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9702, 0.0000],\n",
      "        [0.0000, 0.9700]], device='cuda:0', requires_grad=True)\n",
      "Episode [4/500] loss: -23.49, average reward: -59.72, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9602, 0.0000],\n",
      "        [0.0000, 0.9601]], device='cuda:0', requires_grad=True)\n",
      "Episode [5/500] loss: -24.82, average reward: -51.24, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9502, 0.0000],\n",
      "        [0.0000, 0.9503]], device='cuda:0', requires_grad=True)\n",
      "Episode [6/500] loss: -20.37, average reward: -48.13, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9403, 0.0000],\n",
      "        [0.0000, 0.9404]], device='cuda:0', requires_grad=True)\n",
      "Episode [7/500] loss: -25.62, average reward: -57.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9304, 0.0000],\n",
      "        [0.0000, 0.9305]], device='cuda:0', requires_grad=True)\n",
      "Episode [8/500] loss: -23.61, average reward: -52.71, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9205, 0.0000],\n",
      "        [0.0000, 0.9206]], device='cuda:0', requires_grad=True)\n",
      "Episode [9/500] loss: -28.24, average reward: -51.56, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9106, 0.0000],\n",
      "        [0.0000, 0.9105]], device='cuda:0', requires_grad=True)\n",
      "Episode [10/500] loss: -21.18, average reward: -48.66, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.9008, 0.0000],\n",
      "        [0.0000, 0.9005]], device='cuda:0', requires_grad=True)\n",
      "Episode [11/500] loss: -22.46, average reward: -48.98, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8907, 0.0000],\n",
      "        [0.0000, 0.8907]], device='cuda:0', requires_grad=True)\n",
      "Episode [12/500] loss: -22.45, average reward: -51.34, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8808, 0.0000],\n",
      "        [0.0000, 0.8809]], device='cuda:0', requires_grad=True)\n",
      "Episode [13/500] loss: -19.75, average reward: -47.39, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8709, 0.0000],\n",
      "        [0.0000, 0.8712]], device='cuda:0', requires_grad=True)\n",
      "Episode [14/500] loss: -28.15, average reward: -50.62, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8607, 0.0000],\n",
      "        [0.0000, 0.8615]], device='cuda:0', requires_grad=True)\n",
      "Episode [15/500] loss: -26.09, average reward: -49.49, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8505, 0.0000],\n",
      "        [0.0000, 0.8517]], device='cuda:0', requires_grad=True)\n",
      "Episode [16/500] loss: -22.80, average reward: -45.51, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8403, 0.0000],\n",
      "        [0.0000, 0.8418]], device='cuda:0', requires_grad=True)\n",
      "Episode [17/500] loss: -21.59, average reward: -48.29, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8303, 0.0000],\n",
      "        [0.0000, 0.8318]], device='cuda:0', requires_grad=True)\n",
      "Episode [18/500] loss: -18.12, average reward: -45.11, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8204, 0.0000],\n",
      "        [0.0000, 0.8220]], device='cuda:0', requires_grad=True)\n",
      "Episode [19/500] loss: -20.42, average reward: -47.21, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8105, 0.0000],\n",
      "        [0.0000, 0.8122]], device='cuda:0', requires_grad=True)\n",
      "Episode [20/500] loss: -21.45, average reward: -46.20, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.8007, 0.0000],\n",
      "        [0.0000, 0.8022]], device='cuda:0', requires_grad=True)\n",
      "Episode [21/500] loss: -18.87, average reward: -47.50, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7908, 0.0000],\n",
      "        [0.0000, 0.7925]], device='cuda:0', requires_grad=True)\n",
      "Episode [22/500] loss: -22.20, average reward: -44.76, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7811, 0.0000],\n",
      "        [0.0000, 0.7825]], device='cuda:0', requires_grad=True)\n",
      "Episode [23/500] loss: -17.37, average reward: -42.01, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7715, 0.0000],\n",
      "        [0.0000, 0.7726]], device='cuda:0', requires_grad=True)\n",
      "Episode [24/500] loss: -19.04, average reward: -43.76, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7618, 0.0000],\n",
      "        [0.0000, 0.7627]], device='cuda:0', requires_grad=True)\n",
      "Episode [25/500] loss: -16.78, average reward: -41.99, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7522, 0.0000],\n",
      "        [0.0000, 0.7530]], device='cuda:0', requires_grad=True)\n",
      "Episode [26/500] loss: -19.55, average reward: -43.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7426, 0.0000],\n",
      "        [0.0000, 0.7431]], device='cuda:0', requires_grad=True)\n",
      "Episode [27/500] loss: -16.59, average reward: -44.27, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7330, 0.0000],\n",
      "        [0.0000, 0.7335]], device='cuda:0', requires_grad=True)\n",
      "Episode [28/500] loss: -18.38, average reward: -38.88, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7233, 0.0000],\n",
      "        [0.0000, 0.7239]], device='cuda:0', requires_grad=True)\n",
      "Episode [29/500] loss: -18.52, average reward: -42.03, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7135, 0.0000],\n",
      "        [0.0000, 0.7143]], device='cuda:0', requires_grad=True)\n",
      "Episode [30/500] loss: -18.28, average reward: -45.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.7036, 0.0000],\n",
      "        [0.0000, 0.7047]], device='cuda:0', requires_grad=True)\n",
      "Episode [31/500] loss: -18.31, average reward: -42.72, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6937, 0.0000],\n",
      "        [0.0000, 0.6951]], device='cuda:0', requires_grad=True)\n",
      "Episode [32/500] loss: -16.15, average reward: -40.06, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6840, 0.0000],\n",
      "        [0.0000, 0.6854]], device='cuda:0', requires_grad=True)\n",
      "Episode [33/500] loss: -18.79, average reward: -40.51, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6744, 0.0000],\n",
      "        [0.0000, 0.6755]], device='cuda:0', requires_grad=True)\n",
      "Episode [34/500] loss: -22.78, average reward: -44.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6646, 0.0000],\n",
      "        [0.0000, 0.6652]], device='cuda:0', requires_grad=True)\n",
      "Episode [35/500] loss: -12.53, average reward: -36.40, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6550, 0.0000],\n",
      "        [0.0000, 0.6553]], device='cuda:0', requires_grad=True)\n",
      "Episode [36/500] loss: -16.19, average reward: -42.33, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6454, 0.0000],\n",
      "        [0.0000, 0.6453]], device='cuda:0', requires_grad=True)\n",
      "Episode [37/500] loss: -18.25, average reward: -42.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6357, 0.0000],\n",
      "        [0.0000, 0.6353]], device='cuda:0', requires_grad=True)\n",
      "Episode [38/500] loss: -16.67, average reward: -41.58, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6259, 0.0000],\n",
      "        [0.0000, 0.6253]], device='cuda:0', requires_grad=True)\n",
      "Episode [39/500] loss: -18.71, average reward: -38.40, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6160, 0.0000],\n",
      "        [0.0000, 0.6152]], device='cuda:0', requires_grad=True)\n",
      "Episode [40/500] loss: -17.72, average reward: -43.86, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6058, 0.0000],\n",
      "        [0.0000, 0.6052]], device='cuda:0', requires_grad=True)\n",
      "Episode [41/500] loss: -16.25, average reward: -38.26, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5958, 0.0000],\n",
      "        [0.0000, 0.5950]], device='cuda:0', requires_grad=True)\n",
      "Episode [42/500] loss: -12.11, average reward: -37.85, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5858, 0.0000],\n",
      "        [0.0000, 0.5852]], device='cuda:0', requires_grad=True)\n",
      "Episode [43/500] loss: -15.19, average reward: -40.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5758, 0.0000],\n",
      "        [0.0000, 0.5755]], device='cuda:0', requires_grad=True)\n",
      "Episode [44/500] loss: -15.26, average reward: -38.84, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5657, 0.0000],\n",
      "        [0.0000, 0.5656]], device='cuda:0', requires_grad=True)\n",
      "Episode [45/500] loss: -15.24, average reward: -34.56, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5557, 0.0000],\n",
      "        [0.0000, 0.5558]], device='cuda:0', requires_grad=True)\n",
      "Episode [46/500] loss: -14.58, average reward: -37.12, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5457, 0.0000],\n",
      "        [0.0000, 0.5458]], device='cuda:0', requires_grad=True)\n",
      "Episode [47/500] loss: -11.73, average reward: -34.19, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5359, 0.0000],\n",
      "        [0.0000, 0.5359]], device='cuda:0', requires_grad=True)\n",
      "Episode [48/500] loss: -11.53, average reward: -33.33, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5260, 0.0000],\n",
      "        [0.0000, 0.5264]], device='cuda:0', requires_grad=True)\n",
      "Episode [49/500] loss: -13.16, average reward: -35.70, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5161, 0.0000],\n",
      "        [0.0000, 0.5170]], device='cuda:0', requires_grad=True)\n",
      "Episode [50/500] loss: -19.23, average reward: -37.50, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5059, 0.0000],\n",
      "        [0.0000, 0.5070]], device='cuda:0', requires_grad=True)\n",
      "Episode [51/500] loss: -9.95, average reward: -24.59, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4960, 0.0000],\n",
      "        [0.0000, 0.4972]], device='cuda:0', requires_grad=True)\n",
      "Episode [52/500] loss: -12.06, average reward: -37.73, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4864, 0.0000],\n",
      "        [0.0000, 0.4873]], device='cuda:0', requires_grad=True)\n",
      "Episode [53/500] loss: -10.57, average reward: -29.26, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4769, 0.0000],\n",
      "        [0.0000, 0.4774]], device='cuda:0', requires_grad=True)\n",
      "Episode [54/500] loss: -14.38, average reward: -33.96, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4674, 0.0000],\n",
      "        [0.0000, 0.4673]], device='cuda:0', requires_grad=True)\n",
      "Episode [55/500] loss: -10.50, average reward: -27.74, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4580, 0.0000],\n",
      "        [0.0000, 0.4572]], device='cuda:0', requires_grad=True)\n",
      "Episode [56/500] loss: -15.35, average reward: -35.16, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4483, 0.0000],\n",
      "        [0.0000, 0.4470]], device='cuda:0', requires_grad=True)\n",
      "Episode [57/500] loss: -12.62, average reward: -35.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4383, 0.0000],\n",
      "        [0.0000, 0.4368]], device='cuda:0', requires_grad=True)\n",
      "Episode [58/500] loss: -11.46, average reward: -30.21, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4285, 0.0000],\n",
      "        [0.0000, 0.4266]], device='cuda:0', requires_grad=True)\n",
      "Episode [59/500] loss: -14.51, average reward: -29.39, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4180, 0.0000],\n",
      "        [0.0000, 0.4165]], device='cuda:0', requires_grad=True)\n",
      "Episode [60/500] loss: -11.78, average reward: -33.66, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4077, 0.0000],\n",
      "        [0.0000, 0.4063]], device='cuda:0', requires_grad=True)\n",
      "Episode [61/500] loss: -12.28, average reward: -32.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3972, 0.0000],\n",
      "        [0.0000, 0.3961]], device='cuda:0', requires_grad=True)\n",
      "Episode [62/500] loss: -8.95, average reward: -30.46, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3865, 0.0000],\n",
      "        [0.0000, 0.3863]], device='cuda:0', requires_grad=True)\n",
      "Episode [63/500] loss: -8.35, average reward: -26.81, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3760, 0.0000],\n",
      "        [0.0000, 0.3767]], device='cuda:0', requires_grad=True)\n",
      "Episode [64/500] loss: -8.30, average reward: -26.29, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3658, 0.0000],\n",
      "        [0.0000, 0.3672]], device='cuda:0', requires_grad=True)\n",
      "Episode [65/500] loss: -7.46, average reward: -29.90, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3558, 0.0000],\n",
      "        [0.0000, 0.3578]], device='cuda:0', requires_grad=True)\n",
      "Episode [66/500] loss: -10.13, average reward: -31.32, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3455, 0.0000],\n",
      "        [0.0000, 0.3485]], device='cuda:0', requires_grad=True)\n",
      "Episode [67/500] loss: -7.25, average reward: -29.78, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3353, 0.0000],\n",
      "        [0.0000, 0.3394]], device='cuda:0', requires_grad=True)\n",
      "Episode [68/500] loss: -8.74, average reward: -27.49, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3257, 0.0000],\n",
      "        [0.0000, 0.3298]], device='cuda:0', requires_grad=True)\n",
      "Episode [69/500] loss: -8.83, average reward: -27.46, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3161, 0.0000],\n",
      "        [0.0000, 0.3200]], device='cuda:0', requires_grad=True)\n",
      "Episode [70/500] loss: -9.08, average reward: -29.96, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3062, 0.0000],\n",
      "        [0.0000, 0.3103]], device='cuda:0', requires_grad=True)\n",
      "Episode [71/500] loss: -7.31, average reward: -28.49, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2966, 0.0000],\n",
      "        [0.0000, 0.3005]], device='cuda:0', requires_grad=True)\n",
      "Episode [72/500] loss: -7.38, average reward: -28.48, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2871, 0.0000],\n",
      "        [0.0000, 0.2907]], device='cuda:0', requires_grad=True)\n",
      "Episode [73/500] loss: -12.64, average reward: -31.70, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2771, 0.0000],\n",
      "        [0.0000, 0.2801]], device='cuda:0', requires_grad=True)\n",
      "Episode [74/500] loss: -7.94, average reward: -23.92, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2671, 0.0000],\n",
      "        [0.0000, 0.2696]], device='cuda:0', requires_grad=True)\n",
      "Episode [75/500] loss: -6.88, average reward: -27.63, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2574, 0.0000],\n",
      "        [0.0000, 0.2589]], device='cuda:0', requires_grad=True)\n",
      "Episode [76/500] loss: -6.22, average reward: -21.94, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2476, 0.0000],\n",
      "        [0.0000, 0.2485]], device='cuda:0', requires_grad=True)\n",
      "Episode [77/500] loss: -5.98, average reward: -26.41, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2381, 0.0000],\n",
      "        [0.0000, 0.2379]], device='cuda:0', requires_grad=True)\n",
      "Episode [78/500] loss: -6.31, average reward: -28.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2288, 0.0000],\n",
      "        [0.0000, 0.2273]], device='cuda:0', requires_grad=True)\n",
      "Episode [79/500] loss: -5.62, average reward: -25.41, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2194, 0.0000],\n",
      "        [0.0000, 0.2168]], device='cuda:0', requires_grad=True)\n",
      "Episode [80/500] loss: -5.40, average reward: -19.23, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2099, 0.0000],\n",
      "        [0.0000, 0.2065]], device='cuda:0', requires_grad=True)\n",
      "Episode [81/500] loss: -7.03, average reward: -23.62, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2002, 0.0000],\n",
      "        [0.0000, 0.1961]], device='cuda:0', requires_grad=True)\n",
      "Episode [82/500] loss: -8.39, average reward: -25.42, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1899, 0.0000],\n",
      "        [0.0000, 0.1852]], device='cuda:0', requires_grad=True)\n",
      "Episode [83/500] loss: -5.61, average reward: -29.15, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1794, 0.0000],\n",
      "        [0.0000, 0.1744]], device='cuda:0', requires_grad=True)\n",
      "Episode [84/500] loss: -7.20, average reward: -27.06, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1686, 0.0000],\n",
      "        [0.0000, 0.1633]], device='cuda:0', requires_grad=True)\n",
      "Episode [85/500] loss: -1.74, average reward: -25.87, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1586, 0.0000],\n",
      "        [0.0000, 0.1527]], device='cuda:0', requires_grad=True)\n",
      "Episode [86/500] loss: -2.32, average reward: -28.89, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1488, 0.0000],\n",
      "        [0.0000, 0.1428]], device='cuda:0', requires_grad=True)\n",
      "Episode [87/500] loss: -4.94, average reward: -23.05, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1388, 0.0000],\n",
      "        [0.0000, 0.1325]], device='cuda:0', requires_grad=True)\n",
      "Episode [88/500] loss: -5.75, average reward: -23.17, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1287, 0.0000],\n",
      "        [0.0000, 0.1216]], device='cuda:0', requires_grad=True)\n",
      "Episode [89/500] loss: -0.30, average reward: -25.36, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1197, 0.0000],\n",
      "        [0.0000, 0.1113]], device='cuda:0', requires_grad=True)\n",
      "Episode [90/500] loss: -3.50, average reward: -23.88, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1105, 0.0000],\n",
      "        [0.0000, 0.1009]], device='cuda:0', requires_grad=True)\n",
      "Episode [91/500] loss: -0.75, average reward: -23.51, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1016, 0.0000],\n",
      "        [0.0000, 0.0916]], device='cuda:0', requires_grad=True)\n",
      "Episode [92/500] loss: -3.45, average reward: -25.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0928, 0.0000],\n",
      "        [0.0000, 0.0815]], device='cuda:0', requires_grad=True)\n",
      "Episode [93/500] loss: -3.89, average reward: -24.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0836, 0.0000],\n",
      "        [0.0000, 0.0706]], device='cuda:0', requires_grad=True)\n",
      "Episode [94/500] loss: -3.28, average reward: -24.27, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0738, 0.0000],\n",
      "        [0.0000, 0.0594]], device='cuda:0', requires_grad=True)\n",
      "Episode [95/500] loss: -2.56, average reward: -24.65, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0637, 0.0000],\n",
      "        [0.0000, 0.0480]], device='cuda:0', requires_grad=True)\n",
      "Episode [96/500] loss: -1.77, average reward: -20.54, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0538, 0.0000],\n",
      "        [0.0000, 0.0362]], device='cuda:0', requires_grad=True)\n",
      "Episode [97/500] loss: -0.96, average reward: -23.30, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0441, 0.0000],\n",
      "        [0.0000, 0.0248]], device='cuda:0', requires_grad=True)\n",
      "Episode [98/500] loss: 1.98, average reward: -24.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0382, 0.0000],\n",
      "        [0.0000, 0.0156]], device='cuda:0', requires_grad=True)\n",
      "Episode [99/500] loss: -2.93, average reward: -28.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0290, 0.0000],\n",
      "        [0.0000, 0.0060]], device='cuda:0', requires_grad=True)\n",
      "Episode [100/500] loss: -0.19, average reward: -28.78, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0229,  0.0000],\n",
      "        [ 0.0000, -0.0071]], device='cuda:0', requires_grad=True)\n",
      "Episode [101/500] loss: 0.72, average reward: -25.14, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0176,  0.0000],\n",
      "        [ 0.0000, -0.0218]], device='cuda:0', requires_grad=True)\n",
      "Episode [102/500] loss: -1.97, average reward: -24.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0100,  0.0000],\n",
      "        [ 0.0000, -0.0330]], device='cuda:0', requires_grad=True)\n",
      "Episode [103/500] loss: 1.26, average reward: -19.62, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0079,  0.0000],\n",
      "        [ 0.0000, -0.0437]], device='cuda:0', requires_grad=True)\n",
      "Episode [104/500] loss: -0.18, average reward: -21.47, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0137,  0.0000],\n",
      "        [ 0.0000, -0.0515]], device='cuda:0', requires_grad=True)\n",
      "Episode [105/500] loss: -2.02, average reward: -21.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0195,  0.0000],\n",
      "        [ 0.0000, -0.0568]], device='cuda:0', requires_grad=True)\n",
      "Episode [106/500] loss: -1.44, average reward: -26.79, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0237,  0.0000],\n",
      "        [ 0.0000, -0.0609]], device='cuda:0', requires_grad=True)\n",
      "Episode [107/500] loss: -0.65, average reward: -29.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0284,  0.0000],\n",
      "        [ 0.0000, -0.0638]], device='cuda:0', requires_grad=True)\n",
      "Episode [108/500] loss: -0.01, average reward: -31.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0297,  0.0000],\n",
      "        [ 0.0000, -0.0677]], device='cuda:0', requires_grad=True)\n",
      "Episode [109/500] loss: -2.14, average reward: -27.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0314,  0.0000],\n",
      "        [ 0.0000, -0.0697]], device='cuda:0', requires_grad=True)\n",
      "Episode [110/500] loss: -1.59, average reward: -25.79, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0320,  0.0000],\n",
      "        [ 0.0000, -0.0711]], device='cuda:0', requires_grad=True)\n",
      "Episode [111/500] loss: -4.66, average reward: -29.50, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0306,  0.0000],\n",
      "        [ 0.0000, -0.0707]], device='cuda:0', requires_grad=True)\n",
      "Episode [112/500] loss: -1.22, average reward: -33.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0323,  0.0000],\n",
      "        [ 0.0000, -0.0684]], device='cuda:0', requires_grad=True)\n",
      "Episode [113/500] loss: -1.14, average reward: -38.81, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0346,  0.0000],\n",
      "        [ 0.0000, -0.0652]], device='cuda:0', requires_grad=True)\n",
      "Episode [114/500] loss: -5.00, average reward: -38.45, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0335,  0.0000],\n",
      "        [ 0.0000, -0.0613]], device='cuda:0', requires_grad=True)\n",
      "Episode [115/500] loss: -1.75, average reward: -36.80, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0326,  0.0000],\n",
      "        [ 0.0000, -0.0565]], device='cuda:0', requires_grad=True)\n",
      "Episode [116/500] loss: 0.39, average reward: -25.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0316,  0.0000],\n",
      "        [ 0.0000, -0.0526]], device='cuda:0', requires_grad=True)\n",
      "Episode [117/500] loss: -0.84, average reward: -24.86, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0296,  0.0000],\n",
      "        [ 0.0000, -0.0492]], device='cuda:0', requires_grad=True)\n",
      "Episode [118/500] loss: -1.36, average reward: -25.12, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0262,  0.0000],\n",
      "        [ 0.0000, -0.0461]], device='cuda:0', requires_grad=True)\n",
      "Episode [119/500] loss: -0.25, average reward: -23.39, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0232,  0.0000],\n",
      "        [ 0.0000, -0.0430]], device='cuda:0', requires_grad=True)\n",
      "Episode [120/500] loss: -0.16, average reward: -21.53, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0212,  0.0000],\n",
      "        [ 0.0000, -0.0397]], device='cuda:0', requires_grad=True)\n",
      "Episode [121/500] loss: -1.05, average reward: -18.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0197,  0.0000],\n",
      "        [ 0.0000, -0.0355]], device='cuda:0', requires_grad=True)\n",
      "Episode [122/500] loss: 0.02, average reward: -10.61, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0190,  0.0000],\n",
      "        [ 0.0000, -0.0313]], device='cuda:0', requires_grad=True)\n",
      "Episode [123/500] loss: -1.62, average reward: -20.91, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0174,  0.0000],\n",
      "        [ 0.0000, -0.0262]], device='cuda:0', requires_grad=True)\n",
      "Episode [124/500] loss: -0.13, average reward: -24.43, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0152,  0.0000],\n",
      "        [ 0.0000, -0.0219]], device='cuda:0', requires_grad=True)\n",
      "Episode [125/500] loss: -1.76, average reward: -26.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0119,  0.0000],\n",
      "        [ 0.0000, -0.0160]], device='cuda:0', requires_grad=True)\n",
      "Episode [126/500] loss: -0.28, average reward: -25.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0089,  0.0000],\n",
      "        [ 0.0000, -0.0101]], device='cuda:0', requires_grad=True)\n",
      "Episode [127/500] loss: 0.69, average reward: -24.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0086,  0.0000],\n",
      "        [ 0.0000, -0.0047]], device='cuda:0', requires_grad=True)\n",
      "Episode [128/500] loss: -0.38, average reward: -22.94, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0066,  0.0000],\n",
      "        [ 0.0000, -0.0001]], device='cuda:0', requires_grad=True)\n",
      "Episode [129/500] loss: 1.09, average reward: -10.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0085,  0.0000],\n",
      "        [ 0.0000, -0.0087]], device='cuda:0', requires_grad=True)\n",
      "Episode [130/500] loss: -2.10, average reward: -8.17, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0084,  0.0000],\n",
      "        [ 0.0000, -0.0138]], device='cuda:0', requires_grad=True)\n",
      "Episode [131/500] loss: -0.20, average reward: -3.04, trajectory num: 69\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0068,  0.0000],\n",
      "        [ 0.0000, -0.0186]], device='cuda:0', requires_grad=True)\n",
      "Episode [132/500] loss: 0.10, average reward: -2.79, trajectory num: 88\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0065,  0.0000],\n",
      "        [ 0.0000, -0.0228]], device='cuda:0', requires_grad=True)\n",
      "Episode [133/500] loss: -0.29, average reward: -3.13, trajectory num: 74\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0059,  0.0000],\n",
      "        [ 0.0000, -0.0265]], device='cuda:0', requires_grad=True)\n",
      "Episode [134/500] loss: -0.35, average reward: -3.52, trajectory num: 72\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0043,  0.0000],\n",
      "        [ 0.0000, -0.0298]], device='cuda:0', requires_grad=True)\n",
      "Episode [135/500] loss: 0.31, average reward: -4.00, trajectory num: 67\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0041,  0.0000],\n",
      "        [ 0.0000, -0.0328]], device='cuda:0', requires_grad=True)\n",
      "Episode [136/500] loss: -0.13, average reward: -6.06, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0057,  0.0000],\n",
      "        [ 0.0000, -0.0353]], device='cuda:0', requires_grad=True)\n",
      "Episode [137/500] loss: -0.27, average reward: -4.37, trajectory num: 71\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0076,  0.0000],\n",
      "        [ 0.0000, -0.0375]], device='cuda:0', requires_grad=True)\n",
      "Episode [138/500] loss: -0.52, average reward: -4.37, trajectory num: 75\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0086,  0.0000],\n",
      "        [ 0.0000, -0.0393]], device='cuda:0', requires_grad=True)\n",
      "Episode [139/500] loss: -1.33, average reward: -5.32, trajectory num: 42\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0072,  0.0000],\n",
      "        [ 0.0000, -0.0407]], device='cuda:0', requires_grad=True)\n",
      "Episode [140/500] loss: -0.28, average reward: -5.40, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0083,  0.0000],\n",
      "        [ 0.0000, -0.0417]], device='cuda:0', requires_grad=True)\n",
      "Episode [141/500] loss: 0.17, average reward: -5.42, trajectory num: 42\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0095,  0.0000],\n",
      "        [ 0.0000, -0.0426]], device='cuda:0', requires_grad=True)\n",
      "Episode [142/500] loss: -0.46, average reward: -6.89, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0134,  0.0000],\n",
      "        [ 0.0000, -0.0429]], device='cuda:0', requires_grad=True)\n",
      "Episode [143/500] loss: 0.05, average reward: -6.03, trajectory num: 58\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0173,  0.0000],\n",
      "        [ 0.0000, -0.0431]], device='cuda:0', requires_grad=True)\n",
      "Episode [144/500] loss: 0.07, average reward: -6.92, trajectory num: 35\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0203,  0.0000],\n",
      "        [ 0.0000, -0.0434]], device='cuda:0', requires_grad=True)\n",
      "Episode [145/500] loss: 0.63, average reward: -10.40, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0244,  0.0000],\n",
      "        [ 0.0000, -0.0436]], device='cuda:0', requires_grad=True)\n",
      "Episode [146/500] loss: -0.15, average reward: -11.67, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0284,  0.0000],\n",
      "        [ 0.0000, -0.0437]], device='cuda:0', requires_grad=True)\n",
      "Episode [147/500] loss: -0.39, average reward: -11.28, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0316,  0.0000],\n",
      "        [ 0.0000, -0.0437]], device='cuda:0', requires_grad=True)\n",
      "Episode [148/500] loss: -1.81, average reward: -10.30, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0345,  0.0000],\n",
      "        [ 0.0000, -0.0431]], device='cuda:0', requires_grad=True)\n",
      "Episode [149/500] loss: -2.21, average reward: -8.80, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0361,  0.0000],\n",
      "        [ 0.0000, -0.0422]], device='cuda:0', requires_grad=True)\n",
      "Episode [150/500] loss: -0.55, average reward: -4.18, trajectory num: 50\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0377,  0.0000],\n",
      "        [ 0.0000, -0.0411]], device='cuda:0', requires_grad=True)\n",
      "Episode [151/500] loss: -0.25, average reward: -4.40, trajectory num: 49\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0390,  0.0000],\n",
      "        [ 0.0000, -0.0401]], device='cuda:0', requires_grad=True)\n",
      "Episode [152/500] loss: -0.63, average reward: -4.81, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0395,  0.0000],\n",
      "        [ 0.0000, -0.0392]], device='cuda:0', requires_grad=True)\n",
      "Episode [153/500] loss: -0.43, average reward: -3.81, trajectory num: 76\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0398,  0.0000],\n",
      "        [ 0.0000, -0.0384]], device='cuda:0', requires_grad=True)\n",
      "Episode [154/500] loss: -0.07, average reward: -4.29, trajectory num: 67\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0402,  0.0000],\n",
      "        [ 0.0000, -0.0376]], device='cuda:0', requires_grad=True)\n",
      "Episode [155/500] loss: -1.43, average reward: -7.16, trajectory num: 38\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0400,  0.0000],\n",
      "        [ 0.0000, -0.0365]], device='cuda:0', requires_grad=True)\n",
      "Episode [156/500] loss: 0.11, average reward: -8.81, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0401,  0.0000],\n",
      "        [ 0.0000, -0.0355]], device='cuda:0', requires_grad=True)\n",
      "Episode [157/500] loss: 0.07, average reward: -6.27, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0398,  0.0000],\n",
      "        [ 0.0000, -0.0347]], device='cuda:0', requires_grad=True)\n",
      "Episode [158/500] loss: -0.67, average reward: -3.73, trajectory num: 85\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0393,  0.0000],\n",
      "        [ 0.0000, -0.0339]], device='cuda:0', requires_grad=True)\n",
      "Episode [159/500] loss: -0.60, average reward: -6.20, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0389,  0.0000],\n",
      "        [ 0.0000, -0.0329]], device='cuda:0', requires_grad=True)\n",
      "Episode [160/500] loss: -1.87, average reward: -10.68, trajectory num: 24\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0378,  0.0000],\n",
      "        [ 0.0000, -0.0315]], device='cuda:0', requires_grad=True)\n",
      "Episode [161/500] loss: -1.51, average reward: -10.41, trajectory num: 25\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0361,  0.0000],\n",
      "        [ 0.0000, -0.0299]], device='cuda:0', requires_grad=True)\n",
      "Episode [162/500] loss: 0.08, average reward: -12.95, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0343,  0.0000],\n",
      "        [ 0.0000, -0.0287]], device='cuda:0', requires_grad=True)\n",
      "Episode [163/500] loss: -1.33, average reward: -13.52, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0324,  0.0000],\n",
      "        [ 0.0000, -0.0269]], device='cuda:0', requires_grad=True)\n",
      "Episode [164/500] loss: -0.31, average reward: -9.47, trajectory num: 24\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0306,  0.0000],\n",
      "        [ 0.0000, -0.0253]], device='cuda:0', requires_grad=True)\n",
      "Episode [165/500] loss: -0.49, average reward: -8.25, trajectory num: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0282,  0.0000],\n",
      "        [ 0.0000, -0.0239]], device='cuda:0', requires_grad=True)\n",
      "Episode [166/500] loss: -0.99, average reward: -9.93, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0257,  0.0000],\n",
      "        [ 0.0000, -0.0223]], device='cuda:0', requires_grad=True)\n",
      "Episode [167/500] loss: -2.06, average reward: -15.20, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0223,  0.0000],\n",
      "        [ 0.0000, -0.0199]], device='cuda:0', requires_grad=True)\n",
      "Episode [168/500] loss: -1.39, average reward: -15.74, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0189,  0.0000],\n",
      "        [ 0.0000, -0.0170]], device='cuda:0', requires_grad=True)\n",
      "Episode [169/500] loss: -1.24, average reward: -14.94, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0144,  0.0000],\n",
      "        [ 0.0000, -0.0140]], device='cuda:0', requires_grad=True)\n",
      "Episode [170/500] loss: -0.22, average reward: -9.04, trajectory num: 23\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0093,  0.0000],\n",
      "        [ 0.0000, -0.0115]], device='cuda:0', requires_grad=True)\n",
      "Episode [171/500] loss: -0.01, average reward: -3.12, trajectory num: 90\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0048,  0.0000],\n",
      "        [ 0.0000, -0.0092]], device='cuda:0', requires_grad=True)\n",
      "Episode [172/500] loss: -1.11, average reward: -7.08, trajectory num: 23\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0044,  0.0000],\n",
      "        [ 0.0000, -0.0071]], device='cuda:0', requires_grad=True)\n",
      "Episode [173/500] loss: 0.50, average reward: -11.32, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0089,  0.0000],\n",
      "        [ 0.0000, -0.0077]], device='cuda:0', requires_grad=True)\n",
      "Episode [174/500] loss: -0.89, average reward: -10.79, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0123,  0.0000],\n",
      "        [ 0.0000, -0.0067]], device='cuda:0', requires_grad=True)\n",
      "Episode [175/500] loss: 2.74, average reward: -16.10, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0182,  0.0000],\n",
      "        [ 0.0000, -0.0089]], device='cuda:0', requires_grad=True)\n",
      "Episode [176/500] loss: -2.98, average reward: -24.68, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0221,  0.0000],\n",
      "        [ 0.0000, -0.0076]], device='cuda:0', requires_grad=True)\n",
      "Episode [177/500] loss: -0.43, average reward: -29.27, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0243,  0.0000],\n",
      "        [ 0.0000, -0.0078]], device='cuda:0', requires_grad=True)\n",
      "Episode [178/500] loss: -4.71, average reward: -32.31, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0229,  0.0000],\n",
      "        [ 0.0000, -0.0051]], device='cuda:0', requires_grad=True)\n",
      "Episode [179/500] loss: -3.25, average reward: -27.26, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0186,  0.0000],\n",
      "        [ 0.0000, -0.0013]], device='cuda:0', requires_grad=True)\n",
      "Episode [180/500] loss: -0.53, average reward: -29.49, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0153,  0.0000],\n",
      "        [ 0.0000,  0.0079]], device='cuda:0', requires_grad=True)\n",
      "Episode [181/500] loss: 0.03, average reward: -28.28, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0133,  0.0000],\n",
      "        [ 0.0000,  0.0154]], device='cuda:0', requires_grad=True)\n",
      "Episode [182/500] loss: -1.19, average reward: -28.76, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0099,  0.0000],\n",
      "        [ 0.0000,  0.0219]], device='cuda:0', requires_grad=True)\n",
      "Episode [183/500] loss: 0.40, average reward: -36.52, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0085,  0.0000],\n",
      "        [ 0.0000,  0.0274]], device='cuda:0', requires_grad=True)\n",
      "Episode [184/500] loss: -0.81, average reward: -37.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0060,  0.0000],\n",
      "        [ 0.0000,  0.0323]], device='cuda:0', requires_grad=True)\n",
      "Episode [185/500] loss: 0.88, average reward: -32.69, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0074,  0.0000],\n",
      "        [ 0.0000,  0.0367]], device='cuda:0', requires_grad=True)\n",
      "Episode [186/500] loss: -3.02, average reward: -43.06, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0038,  0.0000],\n",
      "        [ 0.0000,  0.0402]], device='cuda:0', requires_grad=True)\n",
      "Episode [187/500] loss: -1.05, average reward: -44.49, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0053,  0.0000],\n",
      "        [ 0.0000,  0.0427]], device='cuda:0', requires_grad=True)\n",
      "Episode [188/500] loss: -2.61, average reward: -45.94, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0033,  0.0000],\n",
      "        [ 0.0000,  0.0444]], device='cuda:0', requires_grad=True)\n",
      "Episode [189/500] loss: 0.97, average reward: -44.46, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0073,  0.0000],\n",
      "        [ 0.0000,  0.0459]], device='cuda:0', requires_grad=True)\n",
      "Episode [190/500] loss: -0.42, average reward: -42.70, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0092,  0.0000],\n",
      "        [ 0.0000,  0.0474]], device='cuda:0', requires_grad=True)\n",
      "Episode [191/500] loss: 1.94, average reward: -42.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0131,  0.0000],\n",
      "        [ 0.0000,  0.0489]], device='cuda:0', requires_grad=True)\n",
      "Episode [192/500] loss: -3.15, average reward: -43.05, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0150,  0.0000],\n",
      "        [ 0.0000,  0.0499]], device='cuda:0', requires_grad=True)\n",
      "Episode [193/500] loss: -2.20, average reward: -37.69, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0163,  0.0000],\n",
      "        [ 0.0000,  0.0502]], device='cuda:0', requires_grad=True)\n",
      "Episode [194/500] loss: 0.60, average reward: -37.82, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0171,  0.0000],\n",
      "        [ 0.0000,  0.0507]], device='cuda:0', requires_grad=True)\n",
      "Episode [195/500] loss: -0.20, average reward: -38.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0173,  0.0000],\n",
      "        [ 0.0000,  0.0512]], device='cuda:0', requires_grad=True)\n",
      "Episode [196/500] loss: -1.57, average reward: -38.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0178,  0.0000],\n",
      "        [ 0.0000,  0.0512]], device='cuda:0', requires_grad=True)\n",
      "Episode [197/500] loss: -0.08, average reward: -38.80, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0174,  0.0000],\n",
      "        [ 0.0000,  0.0514]], device='cuda:0', requires_grad=True)\n",
      "Episode [198/500] loss: -1.58, average reward: -44.65, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0148,  0.0000],\n",
      "        [ 0.0000,  0.0517]], device='cuda:0', requires_grad=True)\n",
      "Episode [199/500] loss: 2.80, average reward: -46.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0138,  0.0000],\n",
      "        [ 0.0000,  0.0525]], device='cuda:0', requires_grad=True)\n",
      "Episode [200/500] loss: 0.10, average reward: -46.46, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0121,  0.0000],\n",
      "        [ 0.0000,  0.0533]], device='cuda:0', requires_grad=True)\n",
      "Episode [201/500] loss: -0.90, average reward: -45.58, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0108,  0.0000],\n",
      "        [ 0.0000,  0.0538]], device='cuda:0', requires_grad=True)\n",
      "Episode [202/500] loss: -0.45, average reward: -43.64, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0092,  0.0000],\n",
      "        [ 0.0000,  0.0542]], device='cuda:0', requires_grad=True)\n",
      "Episode [203/500] loss: 1.64, average reward: -38.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0113,  0.0000],\n",
      "        [ 0.0000,  0.0545]], device='cuda:0', requires_grad=True)\n",
      "Episode [204/500] loss: -1.71, average reward: -33.68, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0106,  0.0000],\n",
      "        [ 0.0000,  0.0548]], device='cuda:0', requires_grad=True)\n",
      "Episode [205/500] loss: -3.60, average reward: -29.79, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0072,  0.0000],\n",
      "        [ 0.0000,  0.0546]], device='cuda:0', requires_grad=True)\n",
      "Episode [206/500] loss: -1.65, average reward: -33.92, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0042,  0.0000],\n",
      "        [ 0.0000,  0.0540]], device='cuda:0', requires_grad=True)\n",
      "Episode [207/500] loss: -0.82, average reward: -25.66, trajectory num: 23\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0051,  0.0000],\n",
      "        [ 0.0000,  0.0529]], device='cuda:0', requires_grad=True)\n",
      "Episode [208/500] loss: -0.27, average reward: -44.27, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0073,  0.0000],\n",
      "        [ 0.0000,  0.0517]], device='cuda:0', requires_grad=True)\n",
      "Episode [209/500] loss: -2.62, average reward: -47.19, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0086,  0.0000],\n",
      "        [ 0.0000,  0.0500]], device='cuda:0', requires_grad=True)\n",
      "Episode [210/500] loss: -2.21, average reward: -44.61, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0051,  0.0000],\n",
      "        [ 0.0000,  0.0486]], device='cuda:0', requires_grad=True)\n",
      "Episode [211/500] loss: 2.59, average reward: -37.51, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0062,  0.0000],\n",
      "        [ 0.0000,  0.0477]], device='cuda:0', requires_grad=True)\n",
      "Episode [212/500] loss: 1.39, average reward: -30.69, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0100,  0.0000],\n",
      "        [ 0.0000,  0.0469]], device='cuda:0', requires_grad=True)\n",
      "Episode [213/500] loss: -0.53, average reward: -31.31, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0147,  0.0000],\n",
      "        [ 0.0000,  0.0457]], device='cuda:0', requires_grad=True)\n",
      "Episode [214/500] loss: -0.12, average reward: -35.09, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0192,  0.0000],\n",
      "        [ 0.0000,  0.0445]], device='cuda:0', requires_grad=True)\n",
      "Episode [215/500] loss: -1.48, average reward: -37.75, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0235,  0.0000],\n",
      "        [ 0.0000,  0.0428]], device='cuda:0', requires_grad=True)\n",
      "Episode [216/500] loss: -0.75, average reward: -37.29, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0269,  0.0000],\n",
      "        [ 0.0000,  0.0413]], device='cuda:0', requires_grad=True)\n",
      "Episode [217/500] loss: -0.43, average reward: -32.20, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0295,  0.0000],\n",
      "        [ 0.0000,  0.0401]], device='cuda:0', requires_grad=True)\n",
      "Episode [218/500] loss: -0.47, average reward: -23.05, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0316,  0.0000],\n",
      "        [ 0.0000,  0.0391]], device='cuda:0', requires_grad=True)\n",
      "Episode [219/500] loss: -0.80, average reward: -30.27, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0335,  0.0000],\n",
      "        [ 0.0000,  0.0378]], device='cuda:0', requires_grad=True)\n",
      "Episode [220/500] loss: -0.88, average reward: -29.69, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0351,  0.0000],\n",
      "        [ 0.0000,  0.0365]], device='cuda:0', requires_grad=True)\n",
      "Episode [221/500] loss: -1.12, average reward: -33.77, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0365,  0.0000],\n",
      "        [ 0.0000,  0.0349]], device='cuda:0', requires_grad=True)\n",
      "Episode [222/500] loss: -1.72, average reward: -28.21, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0369,  0.0000],\n",
      "        [ 0.0000,  0.0334]], device='cuda:0', requires_grad=True)\n",
      "Episode [223/500] loss: 0.23, average reward: -40.13, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0378,  0.0000],\n",
      "        [ 0.0000,  0.0319]], device='cuda:0', requires_grad=True)\n",
      "Episode [224/500] loss: -2.09, average reward: -43.87, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0385,  0.0000],\n",
      "        [ 0.0000,  0.0296]], device='cuda:0', requires_grad=True)\n",
      "Episode [225/500] loss: 3.30, average reward: -37.25, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0398,  0.0000],\n",
      "        [ 0.0000,  0.0282]], device='cuda:0', requires_grad=True)\n",
      "Episode [226/500] loss: -1.27, average reward: -46.21, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0412,  0.0000],\n",
      "        [ 0.0000,  0.0262]], device='cuda:0', requires_grad=True)\n",
      "Episode [227/500] loss: 1.03, average reward: -46.39, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0427,  0.0000],\n",
      "        [ 0.0000,  0.0246]], device='cuda:0', requires_grad=True)\n",
      "Episode [228/500] loss: -2.04, average reward: -45.38, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0435,  0.0000],\n",
      "        [ 0.0000,  0.0227]], device='cuda:0', requires_grad=True)\n",
      "Episode [229/500] loss: -2.34, average reward: -43.00, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0438,  0.0000],\n",
      "        [ 0.0000,  0.0204]], device='cuda:0', requires_grad=True)\n",
      "Episode [230/500] loss: -0.19, average reward: -42.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0443,  0.0000],\n",
      "        [ 0.0000,  0.0176]], device='cuda:0', requires_grad=True)\n",
      "Episode [231/500] loss: -2.67, average reward: -39.78, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0444,  0.0000],\n",
      "        [ 0.0000,  0.0139]], device='cuda:0', requires_grad=True)\n",
      "Episode [232/500] loss: -2.16, average reward: -39.08, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0438,  0.0000],\n",
      "        [ 0.0000,  0.0104]], device='cuda:0', requires_grad=True)\n",
      "Episode [233/500] loss: 0.36, average reward: -38.63, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0433,  0.0000],\n",
      "        [ 0.0000,  0.0076]], device='cuda:0', requires_grad=True)\n",
      "Episode [234/500] loss: 2.71, average reward: -38.34, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0437,  0.0000],\n",
      "        [ 0.0000,  0.0054]], device='cuda:0', requires_grad=True)\n",
      "Episode [235/500] loss: -2.08, average reward: -38.51, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0436,  0.0000],\n",
      "        [ 0.0000,  0.0024]], device='cuda:0', requires_grad=True)\n",
      "Episode [236/500] loss: -0.85, average reward: -38.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0433,  0.0000],\n",
      "        [ 0.0000, -0.0024]], device='cuda:0', requires_grad=True)\n",
      "Episode [237/500] loss: -0.68, average reward: -38.28, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0433,  0.0000],\n",
      "        [ 0.0000, -0.0013]], device='cuda:0', requires_grad=True)\n",
      "Episode [238/500] loss: 1.42, average reward: -38.02, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0438,  0.0000],\n",
      "        [ 0.0000,  0.0003]], device='cuda:0', requires_grad=True)\n",
      "Episode [239/500] loss: -0.65, average reward: -37.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0444,  0.0000],\n",
      "        [ 0.0000, -0.0073]], device='cuda:0', requires_grad=True)\n",
      "Episode [240/500] loss: 1.51, average reward: -37.66, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0455,  0.0000],\n",
      "        [ 0.0000, -0.0135]], device='cuda:0', requires_grad=True)\n",
      "Episode [241/500] loss: 0.61, average reward: -37.84, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0467,  0.0000],\n",
      "        [ 0.0000, -0.0193]], device='cuda:0', requires_grad=True)\n",
      "Episode [242/500] loss: -2.08, average reward: -38.24, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0473,  0.0000],\n",
      "        [ 0.0000, -0.0241]], device='cuda:0', requires_grad=True)\n",
      "Episode [243/500] loss: -0.49, average reward: -37.68, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0479,  0.0000],\n",
      "        [ 0.0000, -0.0283]], device='cuda:0', requires_grad=True)\n",
      "Episode [244/500] loss: -1.86, average reward: -37.68, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0480,  0.0000],\n",
      "        [ 0.0000, -0.0317]], device='cuda:0', requires_grad=True)\n",
      "Episode [245/500] loss: -3.74, average reward: -37.87, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0474,  0.0000],\n",
      "        [ 0.0000, -0.0341]], device='cuda:0', requires_grad=True)\n",
      "Episode [246/500] loss: 0.24, average reward: -37.55, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0467,  0.0000],\n",
      "        [ 0.0000, -0.0366]], device='cuda:0', requires_grad=True)\n",
      "Episode [247/500] loss: -2.17, average reward: -37.49, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0455,  0.0000],\n",
      "        [ 0.0000, -0.0388]], device='cuda:0', requires_grad=True)\n",
      "Episode [248/500] loss: -1.45, average reward: -37.53, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0439,  0.0000],\n",
      "        [ 0.0000, -0.0406]], device='cuda:0', requires_grad=True)\n",
      "Episode [249/500] loss: -0.48, average reward: -37.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0419,  0.0000],\n",
      "        [ 0.0000, -0.0426]], device='cuda:0', requires_grad=True)\n",
      "Episode [250/500] loss: -1.02, average reward: -37.59, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0400,  0.0000],\n",
      "        [ 0.0000, -0.0442]], device='cuda:0', requires_grad=True)\n",
      "Episode [251/500] loss: -1.94, average reward: -38.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0378,  0.0000],\n",
      "        [ 0.0000, -0.0454]], device='cuda:0', requires_grad=True)\n",
      "Episode [252/500] loss: -0.36, average reward: -37.39, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0358,  0.0000],\n",
      "        [ 0.0000, -0.0464]], device='cuda:0', requires_grad=True)\n",
      "Episode [253/500] loss: -6.12, average reward: -38.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0326,  0.0000],\n",
      "        [ 0.0000, -0.0466]], device='cuda:0', requires_grad=True)\n",
      "Episode [254/500] loss: -3.94, average reward: -38.12, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0289,  0.0000],\n",
      "        [ 0.0000, -0.0463]], device='cuda:0', requires_grad=True)\n",
      "Episode [255/500] loss: -2.34, average reward: -37.82, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0253,  0.0000],\n",
      "        [ 0.0000, -0.0455]], device='cuda:0', requires_grad=True)\n",
      "Episode [256/500] loss: -1.99, average reward: -37.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0214,  0.0000],\n",
      "        [ 0.0000, -0.0445]], device='cuda:0', requires_grad=True)\n",
      "Episode [257/500] loss: -0.93, average reward: -37.82, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0170,  0.0000],\n",
      "        [ 0.0000, -0.0438]], device='cuda:0', requires_grad=True)\n",
      "Episode [258/500] loss: -0.76, average reward: -37.64, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0133,  0.0000],\n",
      "        [ 0.0000, -0.0428]], device='cuda:0', requires_grad=True)\n",
      "Episode [259/500] loss: -0.38, average reward: -37.46, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0107,  0.0000],\n",
      "        [ 0.0000, -0.0417]], device='cuda:0', requires_grad=True)\n",
      "Episode [260/500] loss: 0.31, average reward: -37.18, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0100,  0.0000],\n",
      "        [ 0.0000, -0.0405]], device='cuda:0', requires_grad=True)\n",
      "Episode [261/500] loss: -0.72, average reward: -36.84, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0087,  0.0000],\n",
      "        [ 0.0000, -0.0393]], device='cuda:0', requires_grad=True)\n",
      "Episode [262/500] loss: -2.29, average reward: -36.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0065,  0.0000],\n",
      "        [ 0.0000, -0.0377]], device='cuda:0', requires_grad=True)\n",
      "Episode [263/500] loss: -0.11, average reward: -36.63, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0051,  0.0000],\n",
      "        [ 0.0000, -0.0362]], device='cuda:0', requires_grad=True)\n",
      "Episode [264/500] loss: -0.78, average reward: -36.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0058,  0.0000],\n",
      "        [ 0.0000, -0.0343]], device='cuda:0', requires_grad=True)\n",
      "Episode [265/500] loss: 2.47, average reward: -37.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0069,  0.0000],\n",
      "        [ 0.0000, -0.0334]], device='cuda:0', requires_grad=True)\n",
      "Episode [266/500] loss: 1.08, average reward: -37.30, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0097,  0.0000],\n",
      "        [ 0.0000, -0.0326]], device='cuda:0', requires_grad=True)\n",
      "Episode [267/500] loss: -2.08, average reward: -38.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0111,  0.0000],\n",
      "        [ 0.0000, -0.0314]], device='cuda:0', requires_grad=True)\n",
      "Episode [268/500] loss: -1.67, average reward: -37.45, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0100,  0.0000],\n",
      "        [ 0.0000, -0.0303]], device='cuda:0', requires_grad=True)\n",
      "Episode [269/500] loss: -0.40, average reward: -35.62, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0099,  0.0000],\n",
      "        [ 0.0000, -0.0290]], device='cuda:0', requires_grad=True)\n",
      "Episode [270/500] loss: -0.85, average reward: -36.71, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0108,  0.0000],\n",
      "        [ 0.0000, -0.0272]], device='cuda:0', requires_grad=True)\n",
      "Episode [271/500] loss: -1.33, average reward: -36.97, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0088,  0.0000],\n",
      "        [ 0.0000, -0.0258]], device='cuda:0', requires_grad=True)\n",
      "Episode [272/500] loss: -0.90, average reward: -36.86, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0055,  0.0000],\n",
      "        [ 0.0000, -0.0245]], device='cuda:0', requires_grad=True)\n",
      "Episode [273/500] loss: -1.23, average reward: -36.96, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0002,  0.0000],\n",
      "        [ 0.0000, -0.0233]], device='cuda:0', requires_grad=True)\n",
      "Episode [274/500] loss: 1.04, average reward: -36.99, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0141,  0.0000],\n",
      "        [ 0.0000, -0.0221]], device='cuda:0', requires_grad=True)\n",
      "Episode [275/500] loss: 0.33, average reward: -38.12, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0276,  0.0000],\n",
      "        [ 0.0000, -0.0207]], device='cuda:0', requires_grad=True)\n",
      "Episode [276/500] loss: -1.05, average reward: -36.35, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0397,  0.0000],\n",
      "        [ 0.0000, -0.0188]], device='cuda:0', requires_grad=True)\n",
      "Episode [277/500] loss: -0.77, average reward: -36.25, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0501,  0.0000],\n",
      "        [ 0.0000, -0.0177]], device='cuda:0', requires_grad=True)\n",
      "Episode [278/500] loss: -2.76, average reward: -34.94, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0589,  0.0000],\n",
      "        [ 0.0000, -0.0163]], device='cuda:0', requires_grad=True)\n",
      "Episode [279/500] loss: -2.24, average reward: -33.85, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0666,  0.0000],\n",
      "        [ 0.0000, -0.0146]], device='cuda:0', requires_grad=True)\n",
      "Episode [280/500] loss: -2.26, average reward: -24.51, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0731,  0.0000],\n",
      "        [ 0.0000, -0.0128]], device='cuda:0', requires_grad=True)\n",
      "Episode [281/500] loss: 0.27, average reward: -32.87, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0791,  0.0000],\n",
      "        [ 0.0000, -0.0114]], device='cuda:0', requires_grad=True)\n",
      "Episode [282/500] loss: -1.82, average reward: -30.24, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0842,  0.0000],\n",
      "        [ 0.0000, -0.0096]], device='cuda:0', requires_grad=True)\n",
      "Episode [283/500] loss: -2.49, average reward: -28.18, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0886,  0.0000],\n",
      "        [ 0.0000, -0.0074]], device='cuda:0', requires_grad=True)\n",
      "Episode [284/500] loss: 3.38, average reward: -33.67, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0925,  0.0000],\n",
      "        [ 0.0000, -0.0100]], device='cuda:0', requires_grad=True)\n",
      "Episode [285/500] loss: -1.80, average reward: -40.20, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0957,  0.0000],\n",
      "        [ 0.0000, -0.0132]], device='cuda:0', requires_grad=True)\n",
      "Episode [286/500] loss: -0.52, average reward: -31.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0985,  0.0000],\n",
      "        [ 0.0000, -0.0163]], device='cuda:0', requires_grad=True)\n",
      "Episode [287/500] loss: -2.58, average reward: -34.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1008,  0.0000],\n",
      "        [ 0.0000, -0.0184]], device='cuda:0', requires_grad=True)\n",
      "Episode [288/500] loss: -1.19, average reward: -36.81, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1028,  0.0000],\n",
      "        [ 0.0000, -0.0201]], device='cuda:0', requires_grad=True)\n",
      "Episode [289/500] loss: -0.66, average reward: -37.92, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1047,  0.0000],\n",
      "        [ 0.0000, -0.0211]], device='cuda:0', requires_grad=True)\n",
      "Episode [290/500] loss: -2.61, average reward: -37.88, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1060,  0.0000],\n",
      "        [ 0.0000, -0.0219]], device='cuda:0', requires_grad=True)\n",
      "Episode [291/500] loss: -2.18, average reward: -38.69, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1070,  0.0000],\n",
      "        [ 0.0000, -0.0229]], device='cuda:0', requires_grad=True)\n",
      "Episode [292/500] loss: 1.76, average reward: -38.61, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1076,  0.0000],\n",
      "        [ 0.0000, -0.0253]], device='cuda:0', requires_grad=True)\n",
      "Episode [293/500] loss: -1.06, average reward: -38.16, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1081,  0.0000],\n",
      "        [ 0.0000, -0.0275]], device='cuda:0', requires_grad=True)\n",
      "Episode [294/500] loss: -0.64, average reward: -37.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1085,  0.0000],\n",
      "        [ 0.0000, -0.0292]], device='cuda:0', requires_grad=True)\n",
      "Episode [295/500] loss: -1.32, average reward: -37.27, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1087,  0.0000],\n",
      "        [ 0.0000, -0.0310]], device='cuda:0', requires_grad=True)\n",
      "Episode [296/500] loss: -3.45, average reward: -36.20, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1085,  0.0000],\n",
      "        [ 0.0000, -0.0324]], device='cuda:0', requires_grad=True)\n",
      "Episode [297/500] loss: -3.31, average reward: -31.70, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1080,  0.0000],\n",
      "        [ 0.0000, -0.0334]], device='cuda:0', requires_grad=True)\n",
      "Episode [298/500] loss: -2.54, average reward: -35.48, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1074,  0.0000],\n",
      "        [ 0.0000, -0.0341]], device='cuda:0', requires_grad=True)\n",
      "Episode [299/500] loss: -3.25, average reward: -36.45, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1067,  0.0000],\n",
      "        [ 0.0000, -0.0340]], device='cuda:0', requires_grad=True)\n",
      "Episode [300/500] loss: -0.90, average reward: -34.35, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1060,  0.0000],\n",
      "        [ 0.0000, -0.0339]], device='cuda:0', requires_grad=True)\n",
      "Episode [301/500] loss: -2.41, average reward: -36.10, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1049,  0.0000],\n",
      "        [ 0.0000, -0.0341]], device='cuda:0', requires_grad=True)\n",
      "Episode [302/500] loss: -2.09, average reward: -31.84, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1038,  0.0000],\n",
      "        [ 0.0000, -0.0340]], device='cuda:0', requires_grad=True)\n",
      "Episode [303/500] loss: -2.96, average reward: -35.82, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1025,  0.0000],\n",
      "        [ 0.0000, -0.0338]], device='cuda:0', requires_grad=True)\n",
      "Episode [304/500] loss: -3.36, average reward: -37.72, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1010,  0.0000],\n",
      "        [ 0.0000, -0.0332]], device='cuda:0', requires_grad=True)\n",
      "Episode [305/500] loss: -2.66, average reward: -31.98, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0993,  0.0000],\n",
      "        [ 0.0000, -0.0329]], device='cuda:0', requires_grad=True)\n",
      "Episode [306/500] loss: -2.52, average reward: -31.72, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0975,  0.0000],\n",
      "        [ 0.0000, -0.0322]], device='cuda:0', requires_grad=True)\n",
      "Episode [307/500] loss: -0.37, average reward: -36.04, trajectory num: 16\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('modified_gym_env:ReacherPyBulletEnv-v1', rand_init=False)\n",
    "# env.render()\n",
    "# TODO: test\n",
    "state = env.reset()\n",
    "print(state)\n",
    "\n",
    "# setup network\n",
    "policy_network = PolicyNetwork(env).to(device)\n",
    "average_reward_list, average_step_list = reinforce_with_baseline(env, policy_network,batch_size=2000, num_episodes=500,\n",
    "                                              lr=0.01, gamma=0.9, enable_baseline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(average_reward_list)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('average reward')\n",
    "plt.title('Question 2 Average Rewards at Each Iteration')\n",
    "plt.savefig('Question_2.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(average_step_list)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('average step')\n",
    "plt.title('Question 2 Average Steps at Each Iteration')\n",
    "plt.savefig('Question_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p2_policy.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(policy_network, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load policy\n",
    "# with open('p2_policy.pkl', 'rb') as pickle_file:\n",
    "#     policy_network = pickle.load(pickle_file)\n",
    "\n",
    "# test policy\n",
    "env = gym.make('modified_gym_env:ReacherPyBulletEnv-v1', rand_init=False)\n",
    "# env.render()\n",
    "state = env.reset()\n",
    "done = False\n",
    "steps = 0\n",
    "\n",
    "while not done:\n",
    "    # TODO: do not sample here\n",
    "    action, log_prob = choose_action(policy_network, state)\n",
    "    state_next, reward, done, _ = env.step(action)\n",
    "    steps += 1\n",
    "\n",
    "print('Finished in {} steps'.format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
