{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 276C HW3 P2\n",
    "Mingwei Xu A53270271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import gym\n",
    "import pybulletgym.envs\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cpu\n"
     ]
    }
   ],
   "source": [
    "# setup device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')    # CPU seems faster in this question\n",
    "print('Using device :', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Policy Network using MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        \"\"\"\n",
    "        :param env: object, gym environment\n",
    "        \"\"\"\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        # get state space and action space dimension\n",
    "        self.state_space_n = env.observation_space.shape[0] - 1   # should be 8 (TODO: bug in env showing wrong observation space?)\n",
    "        self.action_space_n = env.action_space.shape[0]   # should be 2\n",
    "\n",
    "        # define layers\n",
    "        self.l1 = nn.Linear(self.state_space_n, 128)\n",
    "        self.l2 = nn.Linear(128, 64)\n",
    "        self.l3 = nn.Linear(64, self.action_space_n)\n",
    "\n",
    "#         self.sigma = nn.Parameter(torch.eye(2))     # initalize cov matrix with grad fn\n",
    "        self.sigma = nn.Parameter(torch.diag(torch.FloatTensor([0.2, 0.2])))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Feed forward\n",
    "        \n",
    "        :param x: np array, state\n",
    "        :return: tensor, softmax probability of action\n",
    "        \"\"\"\n",
    "        # TODO: take sigma as input\n",
    "        # build neural network\n",
    "        network = nn.Sequential(\n",
    "            self.l1,\n",
    "            nn.Tanh(),\n",
    "            self.l2,\n",
    "            nn.Tanh(),\n",
    "            self.l3,\n",
    "            nn.Tanh())\n",
    "\n",
    "        return network(torch.FloatTensor(x).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(policy_network, state, eval_policy=False):\n",
    "    \"\"\"\n",
    "    Choose action according to policy on given state\n",
    "\n",
    "    :param policy_network: object, policy network\n",
    "    :param state: np array, state\n",
    "    :param eval_policy: bool, flag to turn on when evaluating policy.\n",
    "                        It will disable sample and return action directly from policy network output.\n",
    "    :returns: list (len=2), action; tensor with grad fn, log probability\n",
    "    \"\"\"\n",
    "    probs = policy_network.forward(state)   # mean from policy network output\n",
    "\n",
    "    cov = torch.abs(policy_network.sigma) + 1e-3    # positive definite\n",
    "\n",
    "    m = MultivariateNormal(probs, cov)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    \n",
    "    if eval_policy:\n",
    "        print('action: ', probs)\n",
    "        return probs.tolist(), log_prob\n",
    "\n",
    "    return action.tolist(), log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_with_baseline(env, policy_network, batch_size=500, num_episodes=200, lr=0.01, gamma=0.99, enable_baseline=False):\n",
    "    \"\"\"\n",
    "    Policy gradient training using modified reinforce method with baseline\n",
    "\n",
    "    :param env: object, gym environment\n",
    "    :param policy_network: object, policy network\n",
    "    :param batch_size: int, batch size\n",
    "    :param num_episodes: int, number of episodes\n",
    "    :param lr: float, learning rate\n",
    "    :param gamma: float (0~1), discount factor\n",
    "    :param enable_baseline: bool, flag to enable baseline, defaults to False\n",
    "    :return: list of average reward on each episode\n",
    "    \"\"\"\n",
    "    # setup place holders\n",
    "    average_reward_list = []  # store step over episode\n",
    "    average_step_list = []\n",
    "\n",
    "    # define optimizer\n",
    "#     optimizer = optim.Adam(policy_network.parameters(), \n",
    "#                            lr=lr)\n",
    "    optimizer = optim.SGD(policy_network.parameters(), \n",
    "                           lr=lr)\n",
    "\n",
    "    # train\n",
    "    for i in range(num_episodes):\n",
    "        # setup placeholders for each batch\n",
    "        batch_loss_sum = 0\n",
    "        batch_traj_counter = 0\n",
    "        batch_rewards = []\n",
    "        batch_log_prob_list = []\n",
    "        batch_discounted_return_list = []\n",
    "        batch_traj_steps = []\n",
    "\n",
    "        # setup placeholders for each trajectory\n",
    "        traj_rewards = []\n",
    "        traj_log_prob_list = []\n",
    "        traj_step_counter = 0\n",
    "\n",
    "        # reset environment\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        # batch\n",
    "        for step in range(batch_size):\n",
    "            # exploration\n",
    "            action, log_prob = choose_action(policy_network, state)\n",
    "            state_next, reward, done, _ = env.step(action)\n",
    "            # env.render()\n",
    "\n",
    "            # store data\n",
    "            traj_rewards.append(reward)\n",
    "            traj_log_prob_list.append(log_prob)\n",
    "\n",
    "            # move on\n",
    "            if done or (step == batch_size - 1):\n",
    "                # trajectory or batch finished, update trajectory\n",
    "                discounted_return_list = [sum([gamma ** (t_prime - t) * traj_rewards[t_prime] for t_prime in range(t, len(traj_rewards))]) \\\n",
    "                                          for t in range(1, len(traj_rewards) + 1)]\n",
    "\n",
    "                # collect batch info\n",
    "                batch_log_prob_list.extend(traj_log_prob_list)\n",
    "                batch_discounted_return_list.extend(discounted_return_list)\n",
    "                \n",
    "                # reset state\n",
    "                batch_rewards.append(np.sum(traj_rewards))\n",
    "                batch_traj_counter += 1\n",
    "                batch_traj_steps.append(traj_step_counter)\n",
    "\n",
    "                traj_step_counter = 0\n",
    "                traj_rewards = []\n",
    "                traj_log_prob_list = []\n",
    "\n",
    "                state = env.reset()\n",
    "            else:\n",
    "                state = state_next\n",
    "\n",
    "        # finish batch\n",
    "        # subtract average returns if baseline is enabled\n",
    "        if enable_baseline:\n",
    "            batch_discounted_return_list -= np.mean(batch_discounted_return_list)\n",
    "        \n",
    "        # sum the traj loss by loop so we do not lose tensor gradient\n",
    "        for step in range(len(batch_log_prob_list)):\n",
    "            batch_loss_sum += batch_log_prob_list[step] * batch_discounted_return_list[step]\n",
    "        \n",
    "        average_batch_reward = np.mean(batch_rewards)\n",
    "        average_reward_list.append(average_batch_reward)\n",
    "        average_step_list.append(np.mean(batch_traj_steps))\n",
    "        loss = - batch_loss_sum / batch_traj_counter    # TODO\n",
    "        \n",
    "        print('TODO: sigma: ', policy_network.sigma)    # TODO\n",
    "        print('Episode [{}/{}] loss: {:.2f}, average reward: {:.2f}, trajectory num: {}'.format(i + 1, num_episodes,\n",
    "                               loss.item(), average_batch_reward, batch_traj_counter))\n",
    "\n",
    "        # update policy\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return average_reward_list, average_step_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "options= \n",
      "[ 0.3928371   0.3928371  -0.68091764  0.26561381  0.5         0.\n",
      "  0.08333333  0.        ]\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2000, 0.0000],\n",
      "        [0.0000, 0.2000]], requires_grad=True)\n",
      "Episode [1/500] loss: 0.37, average reward: -25.19, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2162, 0.0000],\n",
      "        [0.0000, 0.2025]], requires_grad=True)\n",
      "Episode [2/500] loss: -0.62, average reward: -33.90, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1984, 0.0000],\n",
      "        [0.0000, 0.1911]], requires_grad=True)\n",
      "Episode [3/500] loss: 0.14, average reward: -28.64, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2159, 0.0000],\n",
      "        [0.0000, 0.1811]], requires_grad=True)\n",
      "Episode [4/500] loss: -1.60, average reward: -33.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1734, 0.0000],\n",
      "        [0.0000, 0.1429]], requires_grad=True)\n",
      "Episode [5/500] loss: -1.77, average reward: -31.55, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.2307,  0.0000],\n",
      "        [ 0.0000, -0.0501]], requires_grad=True)\n",
      "Episode [6/500] loss: -0.72, average reward: -27.53, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2539, 0.0000],\n",
      "        [0.0000, 0.1989]], requires_grad=True)\n",
      "Episode [7/500] loss: -1.07, average reward: -34.10, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2857, 0.0000],\n",
      "        [0.0000, 0.1041]], requires_grad=True)\n",
      "Episode [8/500] loss: 0.22, average reward: -35.10, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2986, 0.0000],\n",
      "        [0.0000, 0.0890]], requires_grad=True)\n",
      "Episode [9/500] loss: 2.95, average reward: -31.61, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3344, 0.0000],\n",
      "        [0.0000, 0.2981]], requires_grad=True)\n",
      "Episode [10/500] loss: -1.51, average reward: -30.30, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2841, 0.0000],\n",
      "        [0.0000, 0.3040]], requires_grad=True)\n",
      "Episode [11/500] loss: -0.59, average reward: -38.83, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2720, 0.0000],\n",
      "        [0.0000, 0.2958]], requires_grad=True)\n",
      "Episode [12/500] loss: 1.65, average reward: -33.98, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2453, 0.0000],\n",
      "        [0.0000, 0.3758]], requires_grad=True)\n",
      "Episode [13/500] loss: 2.11, average reward: -32.39, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2948, 0.0000],\n",
      "        [0.0000, 0.3998]], requires_grad=True)\n",
      "Episode [14/500] loss: -3.79, average reward: -37.60, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2613, 0.0000],\n",
      "        [0.0000, 0.3299]], requires_grad=True)\n",
      "Episode [15/500] loss: -0.56, average reward: -24.15, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2395, 0.0000],\n",
      "        [0.0000, 0.3302]], requires_grad=True)\n",
      "Episode [16/500] loss: -1.02, average reward: -23.37, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1853, 0.0000],\n",
      "        [0.0000, 0.3390]], requires_grad=True)\n",
      "Episode [17/500] loss: -0.37, average reward: -32.76, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1175, 0.0000],\n",
      "        [0.0000, 0.3650]], requires_grad=True)\n",
      "Episode [18/500] loss: -0.53, average reward: -19.82, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1533, 0.0000],\n",
      "        [0.0000, 0.3390]], requires_grad=True)\n",
      "Episode [19/500] loss: -0.19, average reward: -20.14, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1872, 0.0000],\n",
      "        [0.0000, 0.3182]], requires_grad=True)\n",
      "Episode [20/500] loss: 0.92, average reward: -30.54, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1368, 0.0000],\n",
      "        [0.0000, 0.3769]], requires_grad=True)\n",
      "Episode [21/500] loss: -0.02, average reward: -21.64, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0754, 0.0000],\n",
      "        [0.0000, 0.3986]], requires_grad=True)\n",
      "Episode [22/500] loss: -1.46, average reward: -27.19, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0740,  0.0000],\n",
      "        [ 0.0000,  0.3906]], requires_grad=True)\n",
      "Episode [23/500] loss: -2.29, average reward: -22.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1380, 0.0000],\n",
      "        [0.0000, 0.3726]], requires_grad=True)\n",
      "Episode [24/500] loss: 0.06, average reward: -22.72, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1500, 0.0000],\n",
      "        [0.0000, 0.3699]], requires_grad=True)\n",
      "Episode [25/500] loss: 2.40, average reward: -26.54, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2972, 0.0000],\n",
      "        [0.0000, 0.3748]], requires_grad=True)\n",
      "Episode [26/500] loss: -0.13, average reward: -26.83, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3018, 0.0000],\n",
      "        [0.0000, 0.3677]], requires_grad=True)\n",
      "Episode [27/500] loss: 0.47, average reward: -18.71, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3203, 0.0000],\n",
      "        [0.0000, 0.3651]], requires_grad=True)\n",
      "Episode [28/500] loss: 0.71, average reward: -16.54, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3217, 0.0000],\n",
      "        [0.0000, 0.3835]], requires_grad=True)\n",
      "Episode [29/500] loss: -1.60, average reward: -20.00, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3206, 0.0000],\n",
      "        [0.0000, 0.3424]], requires_grad=True)\n",
      "Episode [30/500] loss: -1.04, average reward: -22.57, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3200, 0.0000],\n",
      "        [0.0000, 0.3128]], requires_grad=True)\n",
      "Episode [31/500] loss: 0.31, average reward: -22.58, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3529, 0.0000],\n",
      "        [0.0000, 0.2891]], requires_grad=True)\n",
      "Episode [32/500] loss: 2.37, average reward: -26.62, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3842, 0.0000],\n",
      "        [0.0000, 0.3325]], requires_grad=True)\n",
      "Episode [33/500] loss: -2.99, average reward: -28.49, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3504, 0.0000],\n",
      "        [0.0000, 0.2819]], requires_grad=True)\n",
      "Episode [34/500] loss: -3.83, average reward: -24.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2651, 0.0000],\n",
      "        [0.0000, 0.2524]], requires_grad=True)\n",
      "Episode [35/500] loss: 0.11, average reward: -20.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2777, 0.0000],\n",
      "        [0.0000, 0.2434]], requires_grad=True)\n",
      "Episode [36/500] loss: -3.02, average reward: -19.82, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2078, 0.0000],\n",
      "        [0.0000, 0.1990]], requires_grad=True)\n",
      "Episode [37/500] loss: -0.87, average reward: -24.45, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1842, 0.0000],\n",
      "        [0.0000, 0.1799]], requires_grad=True)\n",
      "Episode [38/500] loss: 0.71, average reward: -19.70, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1842, 0.0000],\n",
      "        [0.0000, 0.2191]], requires_grad=True)\n",
      "Episode [39/500] loss: -0.49, average reward: -17.84, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1972, 0.0000],\n",
      "        [0.0000, 0.1863]], requires_grad=True)\n",
      "Episode [40/500] loss: -1.80, average reward: -20.00, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1992, 0.0000],\n",
      "        [0.0000, 0.0884]], requires_grad=True)\n",
      "Episode [41/500] loss: -0.84, average reward: -18.52, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1875, 0.0000],\n",
      "        [0.0000, 0.0211]], requires_grad=True)\n",
      "Episode [42/500] loss: -2.53, average reward: -16.98, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1034,  0.0000],\n",
      "        [ 0.0000, -0.3939]], requires_grad=True)\n",
      "Episode [43/500] loss: -3.36, average reward: -19.52, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0711,  0.0000],\n",
      "        [ 0.0000, -0.3548]], requires_grad=True)\n",
      "Episode [44/500] loss: -2.90, average reward: -16.79, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0898,  0.0000],\n",
      "        [ 0.0000, -0.3050]], requires_grad=True)\n",
      "Episode [45/500] loss: -1.29, average reward: -19.08, trajectory num: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0068,  0.0000],\n",
      "        [ 0.0000, -0.2875]], requires_grad=True)\n",
      "Episode [46/500] loss: 0.55, average reward: -10.66, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.9379,  0.0000],\n",
      "        [ 0.0000, -0.2548]], requires_grad=True)\n",
      "Episode [47/500] loss: 1.66, average reward: -43.37, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.9423,  0.0000],\n",
      "        [ 0.0000, -0.2862]], requires_grad=True)\n",
      "Episode [48/500] loss: -4.79, average reward: -67.57, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.9350,  0.0000],\n",
      "        [ 0.0000, -0.1684]], requires_grad=True)\n",
      "Episode [49/500] loss: -4.39, average reward: -56.31, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.9048,  0.0000],\n",
      "        [ 0.0000, -0.2550]], requires_grad=True)\n",
      "Episode [50/500] loss: -4.68, average reward: -71.50, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.8895,  0.0000],\n",
      "        [ 0.0000, -0.1857]], requires_grad=True)\n",
      "Episode [51/500] loss: -3.85, average reward: -69.23, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.8805,  0.0000],\n",
      "        [ 0.0000, -0.0712]], requires_grad=True)\n",
      "Episode [52/500] loss: -4.68, average reward: -66.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8625, 0.0000],\n",
      "        [0.0000, 0.1088]], requires_grad=True)\n",
      "Episode [53/500] loss: -3.24, average reward: -66.17, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8291, 0.0000],\n",
      "        [0.0000, 0.3783]], requires_grad=True)\n",
      "Episode [54/500] loss: -6.32, average reward: -71.14, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8228, 0.0000],\n",
      "        [0.0000, 0.2421]], requires_grad=True)\n",
      "Episode [55/500] loss: 4.34, average reward: -66.92, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8319, 0.0000],\n",
      "        [0.0000, 0.3524]], requires_grad=True)\n",
      "Episode [56/500] loss: -3.95, average reward: -57.19, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8094, 0.0000],\n",
      "        [0.0000, 0.3573]], requires_grad=True)\n",
      "Episode [57/500] loss: -4.48, average reward: -53.23, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.8000, 0.0000],\n",
      "        [0.0000, 0.2799]], requires_grad=True)\n",
      "Episode [58/500] loss: -1.35, average reward: -57.81, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7997, 0.0000],\n",
      "        [0.0000, 0.2335]], requires_grad=True)\n",
      "Episode [59/500] loss: -3.62, average reward: -47.27, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7799, 0.0000],\n",
      "        [0.0000, 0.2316]], requires_grad=True)\n",
      "Episode [60/500] loss: -10.47, average reward: -67.97, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7397, 0.0000],\n",
      "        [0.0000, 0.0894]], requires_grad=True)\n",
      "Episode [61/500] loss: -0.48, average reward: -64.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.7213, 0.0000],\n",
      "        [0.0000, 0.3916]], requires_grad=True)\n",
      "Episode [62/500] loss: -5.97, average reward: -67.04, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6976, 0.0000],\n",
      "        [0.0000, 0.3436]], requires_grad=True)\n",
      "Episode [63/500] loss: -6.77, average reward: -68.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6679, 0.0000],\n",
      "        [0.0000, 0.2937]], requires_grad=True)\n",
      "Episode [64/500] loss: -9.12, average reward: -65.11, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6255, 0.0000],\n",
      "        [0.0000, 0.2240]], requires_grad=True)\n",
      "Episode [65/500] loss: 0.01, average reward: -64.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6239, 0.0000],\n",
      "        [0.0000, 0.2360]], requires_grad=True)\n",
      "Episode [66/500] loss: -6.88, average reward: -64.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5934, 0.0000],\n",
      "        [0.0000, 0.1547]], requires_grad=True)\n",
      "Episode [67/500] loss: -0.11, average reward: -62.25, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5972, 0.0000],\n",
      "        [0.0000, 0.1085]], requires_grad=True)\n",
      "Episode [68/500] loss: 0.81, average reward: -56.45, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5887, 0.0000],\n",
      "        [0.0000, 0.3076]], requires_grad=True)\n",
      "Episode [69/500] loss: 0.63, average reward: -43.91, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5944, 0.0000],\n",
      "        [0.0000, 0.2985]], requires_grad=True)\n",
      "Episode [70/500] loss: -0.09, average reward: -55.53, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.6038, 0.0000],\n",
      "        [0.0000, 0.2455]], requires_grad=True)\n",
      "Episode [71/500] loss: -4.37, average reward: -59.99, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5978, 0.0000],\n",
      "        [0.0000, 0.1070]], requires_grad=True)\n",
      "Episode [72/500] loss: 1.92, average reward: -57.86, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5928, 0.0000],\n",
      "        [0.0000, 0.3582]], requires_grad=True)\n",
      "Episode [73/500] loss: -6.34, average reward: -60.15, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5693, 0.0000],\n",
      "        [0.0000, 0.2859]], requires_grad=True)\n",
      "Episode [74/500] loss: 0.88, average reward: -57.31, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5642, 0.0000],\n",
      "        [0.0000, 0.3442]], requires_grad=True)\n",
      "Episode [75/500] loss: -4.47, average reward: -62.36, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.5205, 0.0000],\n",
      "        [0.0000, 0.4130]], requires_grad=True)\n",
      "Episode [76/500] loss: -5.81, average reward: -55.44, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4895, 0.0000],\n",
      "        [0.0000, 0.3867]], requires_grad=True)\n",
      "Episode [77/500] loss: -6.85, average reward: -53.82, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4642, 0.0000],\n",
      "        [0.0000, 0.3068]], requires_grad=True)\n",
      "Episode [78/500] loss: -2.75, average reward: -52.17, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4434, 0.0000],\n",
      "        [0.0000, 0.3165]], requires_grad=True)\n",
      "Episode [79/500] loss: -3.75, average reward: -38.98, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.4201, 0.0000],\n",
      "        [0.0000, 0.3043]], requires_grad=True)\n",
      "Episode [80/500] loss: -2.49, average reward: -38.31, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3956, 0.0000],\n",
      "        [0.0000, 0.3370]], requires_grad=True)\n",
      "Episode [81/500] loss: -1.46, average reward: -44.64, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3745, 0.0000],\n",
      "        [0.0000, 0.3809]], requires_grad=True)\n",
      "Episode [82/500] loss: -1.82, average reward: -50.51, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3605, 0.0000],\n",
      "        [0.0000, 0.3838]], requires_grad=True)\n",
      "Episode [83/500] loss: 0.23, average reward: -37.41, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3537, 0.0000],\n",
      "        [0.0000, 0.4138]], requires_grad=True)\n",
      "Episode [84/500] loss: -3.92, average reward: -34.43, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3503, 0.0000],\n",
      "        [0.0000, 0.3303]], requires_grad=True)\n",
      "Episode [85/500] loss: -0.21, average reward: -34.31, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3474, 0.0000],\n",
      "        [0.0000, 0.3360]], requires_grad=True)\n",
      "Episode [86/500] loss: -0.65, average reward: -30.69, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.3407, 0.0000],\n",
      "        [0.0000, 0.3433]], requires_grad=True)\n",
      "Episode [87/500] loss: -8.59, average reward: -29.31, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2931, 0.0000],\n",
      "        [0.0000, 0.2791]], requires_grad=True)\n",
      "Episode [88/500] loss: 0.06, average reward: -17.17, trajectory num: 38\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2857, 0.0000],\n",
      "        [0.0000, 0.3153]], requires_grad=True)\n",
      "Episode [89/500] loss: -1.19, average reward: -24.51, trajectory num: 24\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2695, 0.0000],\n",
      "        [0.0000, 0.3434]], requires_grad=True)\n",
      "Episode [90/500] loss: -2.73, average reward: -28.73, trajectory num: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2486, 0.0000],\n",
      "        [0.0000, 0.3412]], requires_grad=True)\n",
      "Episode [91/500] loss: -0.34, average reward: -23.67, trajectory num: 24\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2528, 0.0000],\n",
      "        [0.0000, 0.3161]], requires_grad=True)\n",
      "Episode [92/500] loss: -1.20, average reward: -35.82, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2444, 0.0000],\n",
      "        [0.0000, 0.3118]], requires_grad=True)\n",
      "Episode [93/500] loss: -2.29, average reward: -27.39, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2301, 0.0000],\n",
      "        [0.0000, 0.2950]], requires_grad=True)\n",
      "Episode [94/500] loss: -0.25, average reward: -19.52, trajectory num: 29\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.2196, 0.0000],\n",
      "        [0.0000, 0.3303]], requires_grad=True)\n",
      "Episode [95/500] loss: -8.26, average reward: -27.02, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1857, 0.0000],\n",
      "        [0.0000, 0.2062]], requires_grad=True)\n",
      "Episode [96/500] loss: -1.48, average reward: -19.77, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1800, 0.0000],\n",
      "        [0.0000, 0.1673]], requires_grad=True)\n",
      "Episode [97/500] loss: 0.42, average reward: -24.62, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1648, 0.0000],\n",
      "        [0.0000, 0.2993]], requires_grad=True)\n",
      "Episode [98/500] loss: -0.66, average reward: -24.40, trajectory num: 24\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1592, 0.0000],\n",
      "        [0.0000, 0.2988]], requires_grad=True)\n",
      "Episode [99/500] loss: -2.20, average reward: -20.13, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1583, 0.0000],\n",
      "        [0.0000, 0.2289]], requires_grad=True)\n",
      "Episode [100/500] loss: -0.66, average reward: -23.65, trajectory num: 23\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1571, 0.0000],\n",
      "        [0.0000, 0.2061]], requires_grad=True)\n",
      "Episode [101/500] loss: -3.95, average reward: -23.27, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[1.1449, 0.0000],\n",
      "        [0.0000, 0.0839]], requires_grad=True)\n",
      "Episode [102/500] loss: -0.68, average reward: -23.19, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.1465,  0.0000],\n",
      "        [ 0.0000, -0.0176]], requires_grad=True)\n",
      "Episode [103/500] loss: -1.20, average reward: -31.81, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.1244,  0.0000],\n",
      "        [ 0.0000, -0.7229]], requires_grad=True)\n",
      "Episode [104/500] loss: -2.09, average reward: -43.33, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.1222,  0.0000],\n",
      "        [ 0.0000, -0.6975]], requires_grad=True)\n",
      "Episode [105/500] loss: -4.90, average reward: -25.27, trajectory num: 27\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.1001,  0.0000],\n",
      "        [ 0.0000, -0.6629]], requires_grad=True)\n",
      "Episode [106/500] loss: -6.31, average reward: -41.21, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.0734,  0.0000],\n",
      "        [ 0.0000, -0.6122]], requires_grad=True)\n",
      "Episode [107/500] loss: -3.85, average reward: -29.49, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.0316,  0.0000],\n",
      "        [ 0.0000, -0.6225]], requires_grad=True)\n",
      "Episode [108/500] loss: -2.61, average reward: -36.58, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 1.0310,  0.0000],\n",
      "        [ 0.0000, -0.5816]], requires_grad=True)\n",
      "Episode [109/500] loss: -3.61, average reward: -34.85, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9992,  0.0000],\n",
      "        [ 0.0000, -0.5760]], requires_grad=True)\n",
      "Episode [110/500] loss: -2.99, average reward: -33.88, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9900,  0.0000],\n",
      "        [ 0.0000, -0.5401]], requires_grad=True)\n",
      "Episode [111/500] loss: -2.84, average reward: -22.84, trajectory num: 24\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9645,  0.0000],\n",
      "        [ 0.0000, -0.5343]], requires_grad=True)\n",
      "Episode [112/500] loss: -1.53, average reward: -18.51, trajectory num: 32\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9593,  0.0000],\n",
      "        [ 0.0000, -0.5152]], requires_grad=True)\n",
      "Episode [113/500] loss: -2.91, average reward: -19.54, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9406,  0.0000],\n",
      "        [ 0.0000, -0.4937]], requires_grad=True)\n",
      "Episode [114/500] loss: -1.23, average reward: -14.69, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9333,  0.0000],\n",
      "        [ 0.0000, -0.4827]], requires_grad=True)\n",
      "Episode [115/500] loss: -0.10, average reward: -16.52, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9309,  0.0000],\n",
      "        [ 0.0000, -0.4852]], requires_grad=True)\n",
      "Episode [116/500] loss: 0.29, average reward: -16.23, trajectory num: 33\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9225,  0.0000],\n",
      "        [ 0.0000, -0.5071]], requires_grad=True)\n",
      "Episode [117/500] loss: -1.55, average reward: -14.80, trajectory num: 41\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9134,  0.0000],\n",
      "        [ 0.0000, -0.4932]], requires_grad=True)\n",
      "Episode [118/500] loss: -1.47, average reward: -16.94, trajectory num: 32\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.9013,  0.0000],\n",
      "        [ 0.0000, -0.4860]], requires_grad=True)\n",
      "Episode [119/500] loss: -1.49, average reward: -14.52, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8977,  0.0000],\n",
      "        [ 0.0000, -0.4622]], requires_grad=True)\n",
      "Episode [120/500] loss: -0.65, average reward: -13.03, trajectory num: 44\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8879,  0.0000],\n",
      "        [ 0.0000, -0.4672]], requires_grad=True)\n",
      "Episode [121/500] loss: -2.88, average reward: -16.29, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8691,  0.0000],\n",
      "        [ 0.0000, -0.4413]], requires_grad=True)\n",
      "Episode [122/500] loss: -0.32, average reward: -14.72, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8599,  0.0000],\n",
      "        [ 0.0000, -0.4524]], requires_grad=True)\n",
      "Episode [123/500] loss: -0.25, average reward: -12.51, trajectory num: 46\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8592,  0.0000],\n",
      "        [ 0.0000, -0.4483]], requires_grad=True)\n",
      "Episode [124/500] loss: -1.17, average reward: -15.14, trajectory num: 35\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8547,  0.0000],\n",
      "        [ 0.0000, -0.4308]], requires_grad=True)\n",
      "Episode [125/500] loss: -0.09, average reward: -11.58, trajectory num: 49\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8567,  0.0000],\n",
      "        [ 0.0000, -0.4247]], requires_grad=True)\n",
      "Episode [126/500] loss: -1.55, average reward: -11.75, trajectory num: 47\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8463,  0.0000],\n",
      "        [ 0.0000, -0.4094]], requires_grad=True)\n",
      "Episode [127/500] loss: -0.49, average reward: -13.45, trajectory num: 41\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8425,  0.0000],\n",
      "        [ 0.0000, -0.4052]], requires_grad=True)\n",
      "Episode [128/500] loss: 0.40, average reward: -14.41, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8414,  0.0000],\n",
      "        [ 0.0000, -0.4174]], requires_grad=True)\n",
      "Episode [129/500] loss: -2.79, average reward: -23.37, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8148,  0.0000],\n",
      "        [ 0.0000, -0.4042]], requires_grad=True)\n",
      "Episode [130/500] loss: -0.77, average reward: -21.30, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8127,  0.0000],\n",
      "        [ 0.0000, -0.3894]], requires_grad=True)\n",
      "Episode [131/500] loss: -1.02, average reward: -16.65, trajectory num: 29\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8061,  0.0000],\n",
      "        [ 0.0000, -0.3771]], requires_grad=True)\n",
      "Episode [132/500] loss: 0.37, average reward: -17.39, trajectory num: 27\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8017,  0.0000],\n",
      "        [ 0.0000, -0.3963]], requires_grad=True)\n",
      "Episode [133/500] loss: -3.57, average reward: -29.99, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7817,  0.0000],\n",
      "        [ 0.0000, -0.3468]], requires_grad=True)\n",
      "Episode [134/500] loss: -1.56, average reward: -32.34, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7624,  0.0000],\n",
      "        [ 0.0000, -0.3455]], requires_grad=True)\n",
      "Episode [135/500] loss: 0.60, average reward: -28.73, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7819,  0.0000],\n",
      "        [ 0.0000, -0.3196]], requires_grad=True)\n",
      "Episode [136/500] loss: -1.50, average reward: -16.08, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7767,  0.0000],\n",
      "        [ 0.0000, -0.2853]], requires_grad=True)\n",
      "Episode [137/500] loss: 0.00, average reward: -13.12, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7806,  0.0000],\n",
      "        [ 0.0000, -0.2750]], requires_grad=True)\n",
      "Episode [138/500] loss: -1.28, average reward: -15.17, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7754,  0.0000],\n",
      "        [ 0.0000, -0.2429]], requires_grad=True)\n",
      "Episode [139/500] loss: -1.77, average reward: -25.22, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7755,  0.0000],\n",
      "        [ 0.0000, -0.1697]], requires_grad=True)\n",
      "Episode [140/500] loss: -0.16, average reward: -24.65, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7679,  0.0000],\n",
      "        [ 0.0000, -0.1948]], requires_grad=True)\n",
      "Episode [141/500] loss: -5.81, average reward: -24.32, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7060,  0.0000],\n",
      "        [ 0.0000, -0.1416]], requires_grad=True)\n",
      "Episode [142/500] loss: -2.13, average reward: -15.95, trajectory num: 26\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.6878,  0.0000],\n",
      "        [ 0.0000, -0.0827]], requires_grad=True)\n",
      "Episode [143/500] loss: -3.48, average reward: -22.85, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6620, 0.0000],\n",
      "        [0.0000, 0.1212]], requires_grad=True)\n",
      "Episode [144/500] loss: -1.46, average reward: -11.46, trajectory num: 35\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6498, 0.0000],\n",
      "        [0.0000, 0.0684]], requires_grad=True)\n",
      "Episode [145/500] loss: -1.75, average reward: -9.10, trajectory num: 47\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.6402,  0.0000],\n",
      "        [ 0.0000, -0.0943]], requires_grad=True)\n",
      "Episode [146/500] loss: -1.05, average reward: -11.56, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.6442, 0.0000],\n",
      "        [0.0000, 0.0429]], requires_grad=True)\n",
      "Episode [147/500] loss: -3.11, average reward: -14.70, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.6129,  0.0000],\n",
      "        [ 0.0000, -0.2055]], requires_grad=True)\n",
      "Episode [148/500] loss: -3.35, average reward: -30.14, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.5762,  0.0000],\n",
      "        [ 0.0000, -0.1523]], requires_grad=True)\n",
      "Episode [149/500] loss: -5.90, average reward: -24.99, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.5040,  0.0000],\n",
      "        [ 0.0000, -0.0391]], requires_grad=True)\n",
      "Episode [150/500] loss: -5.21, average reward: -21.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.3969,  0.0000],\n",
      "        [ 0.0000, -0.0835]], requires_grad=True)\n",
      "Episode [151/500] loss: -3.23, average reward: -15.72, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3652, 0.0000],\n",
      "        [0.0000, 0.1494]], requires_grad=True)\n",
      "Episode [152/500] loss: -0.85, average reward: -14.16, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3715, 0.0000],\n",
      "        [0.0000, 0.0775]], requires_grad=True)\n",
      "Episode [153/500] loss: -1.68, average reward: -19.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.3481,  0.0000],\n",
      "        [ 0.0000, -0.0242]], requires_grad=True)\n",
      "Episode [154/500] loss: -0.63, average reward: -18.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.3269,  0.0000],\n",
      "        [ 0.0000, -0.0662]], requires_grad=True)\n",
      "Episode [155/500] loss: -0.79, average reward: -15.78, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3174, 0.0000],\n",
      "        [0.0000, 0.0066]], requires_grad=True)\n",
      "Episode [156/500] loss: 0.44, average reward: -6.52, trajectory num: 52\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3158, 0.0000],\n",
      "        [0.0000, 0.6472]], requires_grad=True)\n",
      "Episode [157/500] loss: -1.67, average reward: -32.80, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2703, 0.0000],\n",
      "        [0.0000, 0.6437]], requires_grad=True)\n",
      "Episode [158/500] loss: -0.54, average reward: -19.03, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2517, 0.0000],\n",
      "        [0.0000, 0.6432]], requires_grad=True)\n",
      "Episode [159/500] loss: -2.74, average reward: -11.50, trajectory num: 47\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2302, 0.0000],\n",
      "        [0.0000, 0.6092]], requires_grad=True)\n",
      "Episode [160/500] loss: -1.17, average reward: -11.47, trajectory num: 43\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2289, 0.0000],\n",
      "        [0.0000, 0.5905]], requires_grad=True)\n",
      "Episode [161/500] loss: -2.40, average reward: -10.96, trajectory num: 44\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1798, 0.0000],\n",
      "        [0.0000, 0.5690]], requires_grad=True)\n",
      "Episode [162/500] loss: -1.08, average reward: -9.78, trajectory num: 47\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1682, 0.0000],\n",
      "        [0.0000, 0.5537]], requires_grad=True)\n",
      "Episode [163/500] loss: -0.81, average reward: -11.63, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2265, 0.0000],\n",
      "        [0.0000, 0.5214]], requires_grad=True)\n",
      "Episode [164/500] loss: -0.40, average reward: -13.61, trajectory num: 29\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2016, 0.0000],\n",
      "        [0.0000, 0.5245]], requires_grad=True)\n",
      "Episode [165/500] loss: -1.12, average reward: -10.10, trajectory num: 44\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1742, 0.0000],\n",
      "        [0.0000, 0.5136]], requires_grad=True)\n",
      "Episode [166/500] loss: -0.02, average reward: -10.17, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1932, 0.0000],\n",
      "        [0.0000, 0.5067]], requires_grad=True)\n",
      "Episode [167/500] loss: -2.19, average reward: -9.01, trajectory num: 48\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1561, 0.0000],\n",
      "        [0.0000, 0.4779]], requires_grad=True)\n",
      "Episode [168/500] loss: -1.27, average reward: -8.78, trajectory num: 49\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1559, 0.0000],\n",
      "        [0.0000, 0.4513]], requires_grad=True)\n",
      "Episode [169/500] loss: -1.41, average reward: -10.10, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1219, 0.0000],\n",
      "        [0.0000, 0.4319]], requires_grad=True)\n",
      "Episode [170/500] loss: -0.29, average reward: -13.07, trajectory num: 24\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2157, 0.0000],\n",
      "        [0.0000, 0.3986]], requires_grad=True)\n",
      "Episode [171/500] loss: -1.18, average reward: -9.04, trajectory num: 43\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1914, 0.0000],\n",
      "        [0.0000, 0.3823]], requires_grad=True)\n",
      "Episode [172/500] loss: -0.74, average reward: -8.78, trajectory num: 46\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1632, 0.0000],\n",
      "        [0.0000, 0.3771]], requires_grad=True)\n",
      "Episode [173/500] loss: -1.05, average reward: -16.05, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1845, 0.0000],\n",
      "        [0.0000, 0.3399]], requires_grad=True)\n",
      "Episode [174/500] loss: -2.64, average reward: -16.00, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1560, 0.0000],\n",
      "        [0.0000, 0.2779]], requires_grad=True)\n",
      "Episode [175/500] loss: 1.00, average reward: -11.64, trajectory num: 26\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1957, 0.0000],\n",
      "        [0.0000, 0.2914]], requires_grad=True)\n",
      "Episode [176/500] loss: -0.79, average reward: -8.96, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.2047, 0.0000],\n",
      "        [0.0000, 0.2582]], requires_grad=True)\n",
      "Episode [177/500] loss: -0.11, average reward: -7.78, trajectory num: 48\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1953, 0.0000],\n",
      "        [0.0000, 0.2612]], requires_grad=True)\n",
      "Episode [178/500] loss: -0.29, average reward: -8.56, trajectory num: 41\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1727, 0.0000],\n",
      "        [0.0000, 0.2669]], requires_grad=True)\n",
      "Episode [179/500] loss: -2.55, average reward: -17.45, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1952, 0.0000],\n",
      "        [0.0000, 0.1573]], requires_grad=True)\n",
      "Episode [180/500] loss: -1.01, average reward: -9.61, trajectory num: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1747, 0.0000],\n",
      "        [0.0000, 0.1185]], requires_grad=True)\n",
      "Episode [181/500] loss: -3.60, average reward: -14.86, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0538,  0.0000],\n",
      "        [ 0.0000, -0.0052]], requires_grad=True)\n",
      "Episode [182/500] loss: -0.18, average reward: -5.44, trajectory num: 36\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0068,  0.0000],\n",
      "        [ 0.0000, -0.2489]], requires_grad=True)\n",
      "Episode [183/500] loss: -1.76, average reward: -9.71, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8214,  0.0000],\n",
      "        [ 0.0000, -0.2037]], requires_grad=True)\n",
      "Episode [184/500] loss: -1.37, average reward: -15.23, trajectory num: 29\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.8109,  0.0000],\n",
      "        [ 0.0000, -0.1793]], requires_grad=True)\n",
      "Episode [185/500] loss: -3.29, average reward: -31.34, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7765,  0.0000],\n",
      "        [ 0.0000, -0.1511]], requires_grad=True)\n",
      "Episode [186/500] loss: 2.35, average reward: -27.81, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7610,  0.0000],\n",
      "        [ 0.0000, -0.3850]], requires_grad=True)\n",
      "Episode [187/500] loss: -3.63, average reward: -36.48, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7360,  0.0000],\n",
      "        [ 0.0000, -0.3404]], requires_grad=True)\n",
      "Episode [188/500] loss: -3.93, average reward: -34.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.7151,  0.0000],\n",
      "        [ 0.0000, -0.2707]], requires_grad=True)\n",
      "Episode [189/500] loss: -3.98, average reward: -35.40, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.6570,  0.0000],\n",
      "        [ 0.0000, -0.2773]], requires_grad=True)\n",
      "Episode [190/500] loss: -1.07, average reward: -34.26, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.6657,  0.0000],\n",
      "        [ 0.0000, -0.2184]], requires_grad=True)\n",
      "Episode [191/500] loss: -6.76, average reward: -34.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.6208,  0.0000],\n",
      "        [ 0.0000, -0.0466]], requires_grad=True)\n",
      "Episode [192/500] loss: -2.04, average reward: -15.90, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5997, 0.0000],\n",
      "        [0.0000, 0.1018]], requires_grad=True)\n",
      "Episode [193/500] loss: -0.99, average reward: -14.00, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.5938, 0.0000],\n",
      "        [0.0000, 0.0391]], requires_grad=True)\n",
      "Episode [194/500] loss: -1.83, average reward: -23.38, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.5850,  0.0000],\n",
      "        [ 0.0000, -0.2854]], requires_grad=True)\n",
      "Episode [195/500] loss: -0.06, average reward: -22.32, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.5753,  0.0000],\n",
      "        [ 0.0000, -0.3031]], requires_grad=True)\n",
      "Episode [196/500] loss: -2.43, average reward: -15.08, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.5298,  0.0000],\n",
      "        [ 0.0000, -0.3094]], requires_grad=True)\n",
      "Episode [197/500] loss: -2.40, average reward: -21.57, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.5100,  0.0000],\n",
      "        [ 0.0000, -0.2659]], requires_grad=True)\n",
      "Episode [198/500] loss: -3.61, average reward: -18.12, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.4837,  0.0000],\n",
      "        [ 0.0000, -0.1809]], requires_grad=True)\n",
      "Episode [199/500] loss: -3.69, average reward: -23.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.4726,  0.0000],\n",
      "        [ 0.0000, -0.0078]], requires_grad=True)\n",
      "Episode [200/500] loss: -0.42, average reward: -10.87, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.4437,  0.0000],\n",
      "        [ 0.0000, -1.1148]], requires_grad=True)\n",
      "Episode [201/500] loss: -3.16, average reward: -57.74, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.4005,  0.0000],\n",
      "        [ 0.0000, -1.1036]], requires_grad=True)\n",
      "Episode [202/500] loss: -5.21, average reward: -56.78, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.2645,  0.0000],\n",
      "        [ 0.0000, -1.1060]], requires_grad=True)\n",
      "Episode [203/500] loss: -1.92, average reward: -57.80, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1732,  0.0000],\n",
      "        [ 0.0000, -1.1106]], requires_grad=True)\n",
      "Episode [204/500] loss: -4.30, average reward: -50.73, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0407,  0.0000],\n",
      "        [ 0.0000, -1.0927]], requires_grad=True)\n",
      "Episode [205/500] loss: -3.01, average reward: -46.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4604,  0.0000],\n",
      "        [ 0.0000, -1.0843]], requires_grad=True)\n",
      "Episode [206/500] loss: -1.18, average reward: -57.65, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4426,  0.0000],\n",
      "        [ 0.0000, -1.0811]], requires_grad=True)\n",
      "Episode [207/500] loss: -1.53, average reward: -53.11, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4051,  0.0000],\n",
      "        [ 0.0000, -1.0823]], requires_grad=True)\n",
      "Episode [208/500] loss: -2.77, average reward: -46.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3250,  0.0000],\n",
      "        [ 0.0000, -1.0868]], requires_grad=True)\n",
      "Episode [209/500] loss: -0.22, average reward: -47.16, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2946,  0.0000],\n",
      "        [ 0.0000, -1.0940]], requires_grad=True)\n",
      "Episode [210/500] loss: -0.76, average reward: -43.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3828,  0.0000],\n",
      "        [ 0.0000, -1.0633]], requires_grad=True)\n",
      "Episode [211/500] loss: -3.25, average reward: -42.24, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3736,  0.0000],\n",
      "        [ 0.0000, -1.0360]], requires_grad=True)\n",
      "Episode [212/500] loss: -5.24, average reward: -45.69, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4169,  0.0000],\n",
      "        [ 0.0000, -0.9699]], requires_grad=True)\n",
      "Episode [213/500] loss: -6.24, average reward: -29.86, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3082,  0.0000],\n",
      "        [ 0.0000, -0.9524]], requires_grad=True)\n",
      "Episode [214/500] loss: -4.01, average reward: -43.89, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3197,  0.0000],\n",
      "        [ 0.0000, -0.9067]], requires_grad=True)\n",
      "Episode [215/500] loss: -0.24, average reward: -34.86, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3591,  0.0000],\n",
      "        [ 0.0000, -0.8900]], requires_grad=True)\n",
      "Episode [216/500] loss: -1.48, average reward: -38.02, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3147,  0.0000],\n",
      "        [ 0.0000, -0.8913]], requires_grad=True)\n",
      "Episode [217/500] loss: -0.33, average reward: -29.23, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3253,  0.0000],\n",
      "        [ 0.0000, -0.8839]], requires_grad=True)\n",
      "Episode [218/500] loss: -6.30, average reward: -38.71, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2539,  0.0000],\n",
      "        [ 0.0000, -0.8391]], requires_grad=True)\n",
      "Episode [219/500] loss: -1.60, average reward: -14.65, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2356,  0.0000],\n",
      "        [ 0.0000, -0.8257]], requires_grad=True)\n",
      "Episode [220/500] loss: -1.04, average reward: -13.68, trajectory num: 41\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2316,  0.0000],\n",
      "        [ 0.0000, -0.8143]], requires_grad=True)\n",
      "Episode [221/500] loss: -0.48, average reward: -15.69, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2137,  0.0000],\n",
      "        [ 0.0000, -0.8135]], requires_grad=True)\n",
      "Episode [222/500] loss: -1.03, average reward: -13.26, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1966,  0.0000],\n",
      "        [ 0.0000, -0.8054]], requires_grad=True)\n",
      "Episode [223/500] loss: -2.19, average reward: -15.17, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1890,  0.0000],\n",
      "        [ 0.0000, -0.7801]], requires_grad=True)\n",
      "Episode [224/500] loss: -0.07, average reward: -15.77, trajectory num: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1815,  0.0000],\n",
      "        [ 0.0000, -0.7810]], requires_grad=True)\n",
      "Episode [225/500] loss: -1.28, average reward: -14.99, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1616,  0.0000],\n",
      "        [ 0.0000, -0.7692]], requires_grad=True)\n",
      "Episode [226/500] loss: -0.66, average reward: -13.82, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1415,  0.0000],\n",
      "        [ 0.0000, -0.7648]], requires_grad=True)\n",
      "Episode [227/500] loss: -2.74, average reward: -13.18, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1289,  0.0000],\n",
      "        [ 0.0000, -0.7314]], requires_grad=True)\n",
      "Episode [228/500] loss: -0.78, average reward: -11.38, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1559,  0.0000],\n",
      "        [ 0.0000, -0.7160]], requires_grad=True)\n",
      "Episode [229/500] loss: -0.47, average reward: -16.19, trajectory num: 31\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2378,  0.0000],\n",
      "        [ 0.0000, -0.6915]], requires_grad=True)\n",
      "Episode [230/500] loss: -2.90, average reward: -21.66, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2352,  0.0000],\n",
      "        [ 0.0000, -0.6505]], requires_grad=True)\n",
      "Episode [231/500] loss: -1.80, average reward: -12.80, trajectory num: 43\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2100,  0.0000],\n",
      "        [ 0.0000, -0.6321]], requires_grad=True)\n",
      "Episode [232/500] loss: -1.25, average reward: -13.52, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2021,  0.0000],\n",
      "        [ 0.0000, -0.6150]], requires_grad=True)\n",
      "Episode [233/500] loss: -2.34, average reward: -17.46, trajectory num: 26\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1461,  0.0000],\n",
      "        [ 0.0000, -0.5955]], requires_grad=True)\n",
      "Episode [234/500] loss: -1.57, average reward: -12.50, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0741,  0.0000],\n",
      "        [ 0.0000, -0.5869]], requires_grad=True)\n",
      "Episode [235/500] loss: -0.33, average reward: -12.24, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0817,  0.0000],\n",
      "        [ 0.0000, -0.5801]], requires_grad=True)\n",
      "Episode [236/500] loss: -0.89, average reward: -13.76, trajectory num: 31\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1111,  0.0000],\n",
      "        [ 0.0000, -0.5606]], requires_grad=True)\n",
      "Episode [237/500] loss: 0.04, average reward: -10.89, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0867,  0.0000],\n",
      "        [ 0.0000, -0.5663]], requires_grad=True)\n",
      "Episode [238/500] loss: -2.36, average reward: -10.67, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0156,  0.0000],\n",
      "        [ 0.0000, -0.5404]], requires_grad=True)\n",
      "Episode [239/500] loss: -0.88, average reward: -11.65, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0114,  0.0000],\n",
      "        [ 0.0000, -0.5243]], requires_grad=True)\n",
      "Episode [240/500] loss: -4.50, average reward: -27.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8305,  0.0000],\n",
      "        [ 0.0000, -0.4820]], requires_grad=True)\n",
      "Episode [241/500] loss: -2.54, average reward: -28.89, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8228,  0.0000],\n",
      "        [ 0.0000, -0.4586]], requires_grad=True)\n",
      "Episode [242/500] loss: -3.75, average reward: -26.95, trajectory num: 33\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8219,  0.0000],\n",
      "        [ 0.0000, -0.3806]], requires_grad=True)\n",
      "Episode [243/500] loss: 0.71, average reward: -25.37, trajectory num: 31\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8259,  0.0000],\n",
      "        [ 0.0000, -0.3797]], requires_grad=True)\n",
      "Episode [244/500] loss: -1.08, average reward: -53.94, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8120,  0.0000],\n",
      "        [ 0.0000, -0.4179]], requires_grad=True)\n",
      "Episode [245/500] loss: 2.18, average reward: -40.49, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8245,  0.0000],\n",
      "        [ 0.0000, -0.4158]], requires_grad=True)\n",
      "Episode [246/500] loss: -2.49, average reward: -21.24, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8166,  0.0000],\n",
      "        [ 0.0000, -0.3911]], requires_grad=True)\n",
      "Episode [247/500] loss: -5.62, average reward: -38.81, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8030,  0.0000],\n",
      "        [ 0.0000, -0.3107]], requires_grad=True)\n",
      "Episode [248/500] loss: -0.01, average reward: -20.88, trajectory num: 38\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7940,  0.0000],\n",
      "        [ 0.0000, -0.3624]], requires_grad=True)\n",
      "Episode [249/500] loss: 4.98, average reward: -48.00, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8231,  0.0000],\n",
      "        [ 0.0000, -0.3557]], requires_grad=True)\n",
      "Episode [250/500] loss: -0.47, average reward: -35.38, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8186,  0.0000],\n",
      "        [ 0.0000, -0.3659]], requires_grad=True)\n",
      "Episode [251/500] loss: -3.74, average reward: -22.81, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8127,  0.0000],\n",
      "        [ 0.0000, -0.2933]], requires_grad=True)\n",
      "Episode [252/500] loss: 0.61, average reward: -33.38, trajectory num: 23\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8027,  0.0000],\n",
      "        [ 0.0000, -0.3749]], requires_grad=True)\n",
      "Episode [253/500] loss: -0.79, average reward: -18.10, trajectory num: 44\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8056,  0.0000],\n",
      "        [ 0.0000, -0.3401]], requires_grad=True)\n",
      "Episode [254/500] loss: -0.07, average reward: -18.40, trajectory num: 44\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8112,  0.0000],\n",
      "        [ 0.0000, -0.3084]], requires_grad=True)\n",
      "Episode [255/500] loss: -1.83, average reward: -18.32, trajectory num: 44\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8033,  0.0000],\n",
      "        [ 0.0000, -0.2958]], requires_grad=True)\n",
      "Episode [256/500] loss: 1.66, average reward: -36.68, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8011,  0.0000],\n",
      "        [ 0.0000, -0.3649]], requires_grad=True)\n",
      "Episode [257/500] loss: -3.00, average reward: -47.39, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.8023,  0.0000],\n",
      "        [ 0.0000, -0.2771]], requires_grad=True)\n",
      "Episode [258/500] loss: -2.58, average reward: -22.30, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7885,  0.0000],\n",
      "        [ 0.0000, -0.2736]], requires_grad=True)\n",
      "Episode [259/500] loss: -4.57, average reward: -49.31, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7815,  0.0000],\n",
      "        [ 0.0000, -0.1535]], requires_grad=True)\n",
      "Episode [260/500] loss: -0.40, average reward: -24.61, trajectory num: 27\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7846,  0.0000],\n",
      "        [ 0.0000, -0.0903]], requires_grad=True)\n",
      "Episode [261/500] loss: -2.94, average reward: -17.20, trajectory num: 42\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7721,  0.0000],\n",
      "        [ 0.0000, -0.0144]], requires_grad=True)\n",
      "Episode [262/500] loss: -0.77, average reward: -42.77, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7722,  0.0000],\n",
      "        [ 0.0000,  0.4876]], requires_grad=True)\n",
      "Episode [263/500] loss: -9.09, average reward: -60.95, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7412,  0.0000],\n",
      "        [ 0.0000,  0.4140]], requires_grad=True)\n",
      "Episode [264/500] loss: -0.40, average reward: -57.53, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7470,  0.0000],\n",
      "        [ 0.0000,  0.3796]], requires_grad=True)\n",
      "Episode [265/500] loss: -1.05, average reward: -19.35, trajectory num: 41\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7404,  0.0000],\n",
      "        [ 0.0000,  0.3824]], requires_grad=True)\n",
      "Episode [266/500] loss: 0.77, average reward: -17.47, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7396,  0.0000],\n",
      "        [ 0.0000,  0.4062]], requires_grad=True)\n",
      "Episode [267/500] loss: -1.07, average reward: -19.99, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7413,  0.0000],\n",
      "        [ 0.0000,  0.3726]], requires_grad=True)\n",
      "Episode [268/500] loss: -3.66, average reward: -27.15, trajectory num: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7250,  0.0000],\n",
      "        [ 0.0000,  0.3506]], requires_grad=True)\n",
      "Episode [269/500] loss: 0.80, average reward: -23.43, trajectory num: 33\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7251,  0.0000],\n",
      "        [ 0.0000,  0.3731]], requires_grad=True)\n",
      "Episode [270/500] loss: -2.85, average reward: -17.37, trajectory num: 43\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7203,  0.0000],\n",
      "        [ 0.0000,  0.3191]], requires_grad=True)\n",
      "Episode [271/500] loss: -1.81, average reward: -16.99, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7187,  0.0000],\n",
      "        [ 0.0000,  0.2712]], requires_grad=True)\n",
      "Episode [272/500] loss: -3.19, average reward: -50.09, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7205,  0.0000],\n",
      "        [ 0.0000,  0.1423]], requires_grad=True)\n",
      "Episode [273/500] loss: -2.91, average reward: -38.81, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7023,  0.0000],\n",
      "        [ 0.0000,  0.1591]], requires_grad=True)\n",
      "Episode [274/500] loss: -0.75, average reward: -13.66, trajectory num: 56\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.7016,  0.0000],\n",
      "        [ 0.0000,  0.1194]], requires_grad=True)\n",
      "Episode [275/500] loss: -1.21, average reward: -22.20, trajectory num: 32\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6995,  0.0000],\n",
      "        [ 0.0000,  0.0496]], requires_grad=True)\n",
      "Episode [276/500] loss: -3.51, average reward: -17.62, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6860,  0.0000],\n",
      "        [ 0.0000, -0.1909]], requires_grad=True)\n",
      "Episode [277/500] loss: -4.04, average reward: -21.29, trajectory num: 32\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6777,  0.0000],\n",
      "        [ 0.0000, -0.0527]], requires_grad=True)\n",
      "Episode [278/500] loss: -5.47, average reward: -39.33, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6665,  0.0000],\n",
      "        [ 0.0000,  0.6109]], requires_grad=True)\n",
      "Episode [279/500] loss: -4.18, average reward: -47.99, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6550,  0.0000],\n",
      "        [ 0.0000,  0.5737]], requires_grad=True)\n",
      "Episode [280/500] loss: -4.35, average reward: -32.69, trajectory num: 25\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6538,  0.0000],\n",
      "        [ 0.0000,  0.5014]], requires_grad=True)\n",
      "Episode [281/500] loss: 0.06, average reward: -32.96, trajectory num: 25\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6600,  0.0000],\n",
      "        [ 0.0000,  0.4825]], requires_grad=True)\n",
      "Episode [282/500] loss: -4.27, average reward: -40.01, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6470,  0.0000],\n",
      "        [ 0.0000,  0.4389]], requires_grad=True)\n",
      "Episode [283/500] loss: -1.68, average reward: -20.10, trajectory num: 38\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6442,  0.0000],\n",
      "        [ 0.0000,  0.4112]], requires_grad=True)\n",
      "Episode [284/500] loss: 2.15, average reward: -25.71, trajectory num: 29\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6503,  0.0000],\n",
      "        [ 0.0000,  0.4389]], requires_grad=True)\n",
      "Episode [285/500] loss: -1.54, average reward: -20.28, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6387,  0.0000],\n",
      "        [ 0.0000,  0.4475]], requires_grad=True)\n",
      "Episode [286/500] loss: -1.55, average reward: -18.05, trajectory num: 44\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6346,  0.0000],\n",
      "        [ 0.0000,  0.4280]], requires_grad=True)\n",
      "Episode [287/500] loss: -2.21, average reward: -22.36, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6212,  0.0000],\n",
      "        [ 0.0000,  0.4274]], requires_grad=True)\n",
      "Episode [288/500] loss: 0.93, average reward: -21.04, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6267,  0.0000],\n",
      "        [ 0.0000,  0.4286]], requires_grad=True)\n",
      "Episode [289/500] loss: -0.40, average reward: -18.15, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6244,  0.0000],\n",
      "        [ 0.0000,  0.4276]], requires_grad=True)\n",
      "Episode [290/500] loss: -2.25, average reward: -17.90, trajectory num: 46\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6192,  0.0000],\n",
      "        [ 0.0000,  0.3949]], requires_grad=True)\n",
      "Episode [291/500] loss: -2.63, average reward: -16.64, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6097,  0.0000],\n",
      "        [ 0.0000,  0.3673]], requires_grad=True)\n",
      "Episode [292/500] loss: -1.13, average reward: -15.03, trajectory num: 51\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6062,  0.0000],\n",
      "        [ 0.0000,  0.3520]], requires_grad=True)\n",
      "Episode [293/500] loss: -0.90, average reward: -13.38, trajectory num: 58\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6042,  0.0000],\n",
      "        [ 0.0000,  0.3357]], requires_grad=True)\n",
      "Episode [294/500] loss: 1.54, average reward: -13.75, trajectory num: 54\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.6105,  0.0000],\n",
      "        [ 0.0000,  0.3513]], requires_grad=True)\n",
      "Episode [295/500] loss: -2.54, average reward: -15.35, trajectory num: 51\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5981,  0.0000],\n",
      "        [ 0.0000,  0.3359]], requires_grad=True)\n",
      "Episode [296/500] loss: 0.53, average reward: -25.59, trajectory num: 27\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5961,  0.0000],\n",
      "        [ 0.0000,  0.3615]], requires_grad=True)\n",
      "Episode [297/500] loss: -5.40, average reward: -41.46, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5760,  0.0000],\n",
      "        [ 0.0000,  0.3011]], requires_grad=True)\n",
      "Episode [298/500] loss: 0.57, average reward: -21.81, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5853,  0.0000],\n",
      "        [ 0.0000,  0.2714]], requires_grad=True)\n",
      "Episode [299/500] loss: -0.71, average reward: -20.68, trajectory num: 36\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5871,  0.0000],\n",
      "        [ 0.0000,  0.2349]], requires_grad=True)\n",
      "Episode [300/500] loss: -3.49, average reward: -31.67, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5716,  0.0000],\n",
      "        [ 0.0000,  0.1914]], requires_grad=True)\n",
      "Episode [301/500] loss: -2.94, average reward: -31.30, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5519,  0.0000],\n",
      "        [ 0.0000,  0.1996]], requires_grad=True)\n",
      "Episode [302/500] loss: -1.90, average reward: -24.43, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5449,  0.0000],\n",
      "        [ 0.0000,  0.1594]], requires_grad=True)\n",
      "Episode [303/500] loss: -1.10, average reward: -24.39, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5388,  0.0000],\n",
      "        [ 0.0000,  0.1498]], requires_grad=True)\n",
      "Episode [304/500] loss: 1.51, average reward: -26.08, trajectory num: 23\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5368,  0.0000],\n",
      "        [ 0.0000,  0.2692]], requires_grad=True)\n",
      "Episode [305/500] loss: -0.66, average reward: -30.61, trajectory num: 23\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5295,  0.0000],\n",
      "        [ 0.0000,  0.2865]], requires_grad=True)\n",
      "Episode [306/500] loss: 1.12, average reward: -21.00, trajectory num: 36\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5325,  0.0000],\n",
      "        [ 0.0000,  0.3097]], requires_grad=True)\n",
      "Episode [307/500] loss: -7.81, average reward: -27.39, trajectory num: 27\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5153,  0.0000],\n",
      "        [ 0.0000,  0.1430]], requires_grad=True)\n",
      "Episode [308/500] loss: -0.44, average reward: -19.46, trajectory num: 35\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5127,  0.0000],\n",
      "        [ 0.0000,  0.1402]], requires_grad=True)\n",
      "Episode [309/500] loss: -2.80, average reward: -17.13, trajectory num: 41\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.5007,  0.0000],\n",
      "        [ 0.0000,  0.0701]], requires_grad=True)\n",
      "Episode [310/500] loss: -0.96, average reward: -18.39, trajectory num: 37\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4975,  0.0000],\n",
      "        [ 0.0000,  0.0038]], requires_grad=True)\n",
      "Episode [311/500] loss: -3.90, average reward: -28.46, trajectory num: 22\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4679,  0.0000],\n",
      "        [ 0.0000,  1.1151]], requires_grad=True)\n",
      "Episode [312/500] loss: -8.17, average reward: -76.26, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4389,  0.0000],\n",
      "        [ 0.0000,  1.0800]], requires_grad=True)\n",
      "Episode [313/500] loss: 2.88, average reward: -69.04, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4590,  0.0000],\n",
      "        [ 0.0000,  1.0798]], requires_grad=True)\n",
      "Episode [314/500] loss: 3.60, average reward: -70.87, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4857,  0.0000],\n",
      "        [ 0.0000,  1.0771]], requires_grad=True)\n",
      "Episode [315/500] loss: 8.01, average reward: -72.14, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4949,  0.0000],\n",
      "        [ 0.0000,  1.1386]], requires_grad=True)\n",
      "Episode [316/500] loss: -8.52, average reward: -73.04, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4836,  0.0000],\n",
      "        [ 0.0000,  1.0787]], requires_grad=True)\n",
      "Episode [317/500] loss: -0.13, average reward: -71.07, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4550,  0.0000],\n",
      "        [ 0.0000,  1.1168]], requires_grad=True)\n",
      "Episode [318/500] loss: -6.20, average reward: -74.18, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.4269,  0.0000],\n",
      "        [ 0.0000,  1.0981]], requires_grad=True)\n",
      "Episode [319/500] loss: -5.84, average reward: -79.64, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.3996,  0.0000],\n",
      "        [ 0.0000,  1.0803]], requires_grad=True)\n",
      "Episode [320/500] loss: -7.05, average reward: -71.20, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.3741,  0.0000],\n",
      "        [ 0.0000,  1.0482]], requires_grad=True)\n",
      "Episode [321/500] loss: -0.13, average reward: -76.29, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.3752,  0.0000],\n",
      "        [ 0.0000,  1.0456]], requires_grad=True)\n",
      "Episode [322/500] loss: -0.96, average reward: -76.76, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.3420,  0.0000],\n",
      "        [ 0.0000,  1.0800]], requires_grad=True)\n",
      "Episode [323/500] loss: -4.02, average reward: -78.11, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.3046,  0.0000],\n",
      "        [ 0.0000,  1.0892]], requires_grad=True)\n",
      "Episode [324/500] loss: -5.06, average reward: -77.16, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.2840,  0.0000],\n",
      "        [ 0.0000,  1.0675]], requires_grad=True)\n",
      "Episode [325/500] loss: 1.54, average reward: -69.53, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.2680,  0.0000],\n",
      "        [ 0.0000,  1.1011]], requires_grad=True)\n",
      "Episode [326/500] loss: -1.34, average reward: -66.20, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.2672,  0.0000],\n",
      "        [ 0.0000,  1.0899]], requires_grad=True)\n",
      "Episode [327/500] loss: 2.30, average reward: -69.77, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.2572,  0.0000],\n",
      "        [ 0.0000,  1.1225]], requires_grad=True)\n",
      "Episode [328/500] loss: -4.62, average reward: -67.55, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.2108,  0.0000],\n",
      "        [ 0.0000,  1.1333]], requires_grad=True)\n",
      "Episode [329/500] loss: -14.20, average reward: -76.98, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.1219,  0.0000],\n",
      "        [ 0.0000,  1.1030]], requires_grad=True)\n",
      "Episode [330/500] loss: 5.02, average reward: -59.27, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.1099,  0.0000],\n",
      "        [ 0.0000,  1.1607]], requires_grad=True)\n",
      "Episode [331/500] loss: -2.96, average reward: -63.24, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.1094,  0.0000],\n",
      "        [ 0.0000,  1.1357]], requires_grad=True)\n",
      "Episode [332/500] loss: 2.51, average reward: -63.19, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.1172,  0.0000],\n",
      "        [ 0.0000,  1.1502]], requires_grad=True)\n",
      "Episode [333/500] loss: -2.86, average reward: -63.77, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.0579,  0.0000],\n",
      "        [ 0.0000,  1.1829]], requires_grad=True)\n",
      "Episode [334/500] loss: 1.47, average reward: -68.39, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.0623,  0.0000],\n",
      "        [ 0.0000,  1.1915]], requires_grad=True)\n",
      "Episode [335/500] loss: -3.23, average reward: -62.17, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.0234,  0.0000],\n",
      "        [ 0.0000,  1.1991]], requires_grad=True)\n",
      "Episode [336/500] loss: -4.79, average reward: -51.47, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9971,  0.0000],\n",
      "        [ 0.0000,  1.1816]], requires_grad=True)\n",
      "Episode [337/500] loss: 2.72, average reward: -49.81, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9904,  0.0000],\n",
      "        [ 0.0000,  1.2104]], requires_grad=True)\n",
      "Episode [338/500] loss: 0.46, average reward: -47.25, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9992,  0.0000],\n",
      "        [ 0.0000,  1.2069]], requires_grad=True)\n",
      "Episode [339/500] loss: -0.89, average reward: -53.00, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.0079,  0.0000],\n",
      "        [ 0.0000,  1.1923]], requires_grad=True)\n",
      "Episode [340/500] loss: 0.18, average reward: -51.35, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.0003,  0.0000],\n",
      "        [ 0.0000,  1.2002]], requires_grad=True)\n",
      "Episode [341/500] loss: -0.32, average reward: -53.48, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9929,  0.0000],\n",
      "        [ 0.0000,  1.2038]], requires_grad=True)\n",
      "Episode [342/500] loss: 0.40, average reward: -43.46, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-1.0118,  0.0000],\n",
      "        [ 0.0000,  1.1915]], requires_grad=True)\n",
      "Episode [343/500] loss: -9.71, average reward: -56.56, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9415,  0.0000],\n",
      "        [ 0.0000,  1.1699]], requires_grad=True)\n",
      "Episode [344/500] loss: 2.49, average reward: -53.16, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9536,  0.0000],\n",
      "        [ 0.0000,  1.1813]], requires_grad=True)\n",
      "Episode [345/500] loss: -0.46, average reward: -42.47, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9254,  0.0000],\n",
      "        [ 0.0000,  1.2003]], requires_grad=True)\n",
      "Episode [346/500] loss: -0.90, average reward: -42.53, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.9086,  0.0000],\n",
      "        [ 0.0000,  1.2057]], requires_grad=True)\n",
      "Episode [347/500] loss: -5.61, average reward: -41.97, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8660,  0.0000],\n",
      "        [ 0.0000,  1.1914]], requires_grad=True)\n",
      "Episode [348/500] loss: 2.46, average reward: -47.74, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8901,  0.0000],\n",
      "        [ 0.0000,  1.1946]], requires_grad=True)\n",
      "Episode [349/500] loss: -1.53, average reward: -37.68, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8725,  0.0000],\n",
      "        [ 0.0000,  1.1948]], requires_grad=True)\n",
      "Episode [350/500] loss: 3.60, average reward: -33.57, trajectory num: 25\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8717,  0.0000],\n",
      "        [ 0.0000,  1.2256]], requires_grad=True)\n",
      "Episode [351/500] loss: -3.83, average reward: -50.41, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8563,  0.0000],\n",
      "        [ 0.0000,  1.2053]], requires_grad=True)\n",
      "Episode [352/500] loss: 1.97, average reward: -48.36, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8831,  0.0000],\n",
      "        [ 0.0000,  1.2027]], requires_grad=True)\n",
      "Episode [353/500] loss: -5.18, average reward: -49.41, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8460,  0.0000],\n",
      "        [ 0.0000,  1.1869]], requires_grad=True)\n",
      "Episode [354/500] loss: 0.32, average reward: -26.38, trajectory num: 31\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8461,  0.0000],\n",
      "        [ 0.0000,  1.1895]], requires_grad=True)\n",
      "Episode [355/500] loss: 0.16, average reward: -39.48, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8428,  0.0000],\n",
      "        [ 0.0000,  1.1932]], requires_grad=True)\n",
      "Episode [356/500] loss: 1.76, average reward: -50.33, trajectory num: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8706,  0.0000],\n",
      "        [ 0.0000,  1.1883]], requires_grad=True)\n",
      "Episode [357/500] loss: -2.74, average reward: -29.77, trajectory num: 28\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8625,  0.0000],\n",
      "        [ 0.0000,  1.1713]], requires_grad=True)\n",
      "Episode [358/500] loss: -0.88, average reward: -49.32, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8519,  0.0000],\n",
      "        [ 0.0000,  1.1716]], requires_grad=True)\n",
      "Episode [359/500] loss: 2.54, average reward: -30.51, trajectory num: 26\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8670,  0.0000],\n",
      "        [ 0.0000,  1.1823]], requires_grad=True)\n",
      "Episode [360/500] loss: 0.35, average reward: -38.28, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8836,  0.0000],\n",
      "        [ 0.0000,  1.1730]], requires_grad=True)\n",
      "Episode [361/500] loss: -2.28, average reward: -26.21, trajectory num: 32\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8560,  0.0000],\n",
      "        [ 0.0000,  1.1744]], requires_grad=True)\n",
      "Episode [362/500] loss: -0.09, average reward: -21.76, trajectory num: 38\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8645,  0.0000],\n",
      "        [ 0.0000,  1.1675]], requires_grad=True)\n",
      "Episode [363/500] loss: -1.08, average reward: -21.30, trajectory num: 40\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8497,  0.0000],\n",
      "        [ 0.0000,  1.1692]], requires_grad=True)\n",
      "Episode [364/500] loss: -2.15, average reward: -21.33, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8393,  0.0000],\n",
      "        [ 0.0000,  1.1584]], requires_grad=True)\n",
      "Episode [365/500] loss: 0.55, average reward: -26.46, trajectory num: 31\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8614,  0.0000],\n",
      "        [ 0.0000,  1.1471]], requires_grad=True)\n",
      "Episode [366/500] loss: -5.07, average reward: -26.18, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.8147,  0.0000],\n",
      "        [ 0.0000,  1.1380]], requires_grad=True)\n",
      "Episode [367/500] loss: -2.81, average reward: -20.49, trajectory num: 41\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7873,  0.0000],\n",
      "        [ 0.0000,  1.1330]], requires_grad=True)\n",
      "Episode [368/500] loss: -0.58, average reward: -40.81, trajectory num: 18\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7554,  0.0000],\n",
      "        [ 0.0000,  1.1501]], requires_grad=True)\n",
      "Episode [369/500] loss: -3.80, average reward: -42.25, trajectory num: 17\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7535,  0.0000],\n",
      "        [ 0.0000,  1.1182]], requires_grad=True)\n",
      "Episode [370/500] loss: 0.83, average reward: -17.58, trajectory num: 48\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7635,  0.0000],\n",
      "        [ 0.0000,  1.1190]], requires_grad=True)\n",
      "Episode [371/500] loss: -0.66, average reward: -34.17, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7491,  0.0000],\n",
      "        [ 0.0000,  1.1228]], requires_grad=True)\n",
      "Episode [372/500] loss: 0.78, average reward: -49.46, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7713,  0.0000],\n",
      "        [ 0.0000,  1.1150]], requires_grad=True)\n",
      "Episode [373/500] loss: -2.66, average reward: -34.32, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7501,  0.0000],\n",
      "        [ 0.0000,  1.1058]], requires_grad=True)\n",
      "Episode [374/500] loss: -3.10, average reward: -20.73, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.7295,  0.0000],\n",
      "        [ 0.0000,  1.0917]], requires_grad=True)\n",
      "Episode [375/500] loss: -4.46, average reward: -17.69, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.6984,  0.0000],\n",
      "        [ 0.0000,  1.0717]], requires_grad=True)\n",
      "Episode [376/500] loss: -3.49, average reward: -17.16, trajectory num: 47\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.6659,  0.0000],\n",
      "        [ 0.0000,  1.0605]], requires_grad=True)\n",
      "Episode [377/500] loss: -0.98, average reward: -21.07, trajectory num: 35\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.6544,  0.0000],\n",
      "        [ 0.0000,  1.0585]], requires_grad=True)\n",
      "Episode [378/500] loss: -4.93, average reward: -33.96, trajectory num: 20\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.6250,  0.0000],\n",
      "        [ 0.0000,  1.0301]], requires_grad=True)\n",
      "Episode [379/500] loss: -1.69, average reward: -35.46, trajectory num: 19\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.6039,  0.0000],\n",
      "        [ 0.0000,  1.0264]], requires_grad=True)\n",
      "Episode [380/500] loss: -0.82, average reward: -16.40, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5924,  0.0000],\n",
      "        [ 0.0000,  1.0253]], requires_grad=True)\n",
      "Episode [381/500] loss: -1.77, average reward: -22.72, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5827,  0.0000],\n",
      "        [ 0.0000,  1.0136]], requires_grad=True)\n",
      "Episode [382/500] loss: -1.85, average reward: -14.32, trajectory num: 54\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5645,  0.0000],\n",
      "        [ 0.0000,  1.0058]], requires_grad=True)\n",
      "Episode [383/500] loss: -0.46, average reward: -15.77, trajectory num: 46\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5619,  0.0000],\n",
      "        [ 0.0000,  1.0027]], requires_grad=True)\n",
      "Episode [384/500] loss: 0.26, average reward: -14.92, trajectory num: 51\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5889,  0.0000],\n",
      "        [ 0.0000,  0.9901]], requires_grad=True)\n",
      "Episode [385/500] loss: -2.99, average reward: -14.69, trajectory num: 51\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5566,  0.0000],\n",
      "        [ 0.0000,  0.9791]], requires_grad=True)\n",
      "Episode [386/500] loss: -2.37, average reward: -12.78, trajectory num: 57\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5332,  0.0000],\n",
      "        [ 0.0000,  0.9683]], requires_grad=True)\n",
      "Episode [387/500] loss: -2.53, average reward: -15.84, trajectory num: 42\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5105,  0.0000],\n",
      "        [ 0.0000,  0.9547]], requires_grad=True)\n",
      "Episode [388/500] loss: -1.04, average reward: -13.89, trajectory num: 54\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5074,  0.0000],\n",
      "        [ 0.0000,  0.9455]], requires_grad=True)\n",
      "Episode [389/500] loss: -1.20, average reward: -13.14, trajectory num: 56\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4979,  0.0000],\n",
      "        [ 0.0000,  0.9379]], requires_grad=True)\n",
      "Episode [390/500] loss: 0.89, average reward: -12.77, trajectory num: 58\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.5023,  0.0000],\n",
      "        [ 0.0000,  0.9451]], requires_grad=True)\n",
      "Episode [391/500] loss: -0.33, average reward: -12.38, trajectory num: 59\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4875,  0.0000],\n",
      "        [ 0.0000,  0.9494]], requires_grad=True)\n",
      "Episode [392/500] loss: -2.14, average reward: -12.58, trajectory num: 57\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4709,  0.0000],\n",
      "        [ 0.0000,  0.9354]], requires_grad=True)\n",
      "Episode [393/500] loss: -1.28, average reward: -12.27, trajectory num: 59\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4479,  0.0000],\n",
      "        [ 0.0000,  0.9333]], requires_grad=True)\n",
      "Episode [394/500] loss: -3.29, average reward: -12.72, trajectory num: 56\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4212,  0.0000],\n",
      "        [ 0.0000,  0.9109]], requires_grad=True)\n",
      "Episode [395/500] loss: -2.31, average reward: -11.03, trajectory num: 63\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4056,  0.0000],\n",
      "        [ 0.0000,  0.8929]], requires_grad=True)\n",
      "Episode [396/500] loss: -0.46, average reward: -11.59, trajectory num: 59\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4035,  0.0000],\n",
      "        [ 0.0000,  0.8886]], requires_grad=True)\n",
      "Episode [397/500] loss: -0.66, average reward: -11.14, trajectory num: 62\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4157,  0.0000],\n",
      "        [ 0.0000,  0.8757]], requires_grad=True)\n",
      "Episode [398/500] loss: -1.29, average reward: -13.56, trajectory num: 49\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4233,  0.0000],\n",
      "        [ 0.0000,  0.8574]], requires_grad=True)\n",
      "Episode [399/500] loss: -1.15, average reward: -12.03, trajectory num: 55\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3996,  0.0000],\n",
      "        [ 0.0000,  0.8557]], requires_grad=True)\n",
      "Episode [400/500] loss: -0.41, average reward: -13.46, trajectory num: 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3951,  0.0000],\n",
      "        [ 0.0000,  0.8530]], requires_grad=True)\n",
      "Episode [401/500] loss: -1.68, average reward: -13.69, trajectory num: 48\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3905,  0.0000],\n",
      "        [ 0.0000,  0.8356]], requires_grad=True)\n",
      "Episode [402/500] loss: -0.92, average reward: -11.31, trajectory num: 59\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3941,  0.0000],\n",
      "        [ 0.0000,  0.8229]], requires_grad=True)\n",
      "Episode [403/500] loss: -0.96, average reward: -12.20, trajectory num: 56\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4046,  0.0000],\n",
      "        [ 0.0000,  0.8062]], requires_grad=True)\n",
      "Episode [404/500] loss: -5.06, average reward: -25.40, trajectory num: 21\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3895,  0.0000],\n",
      "        [ 0.0000,  0.7511]], requires_grad=True)\n",
      "Episode [405/500] loss: -0.25, average reward: -9.95, trajectory num: 67\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3701,  0.0000],\n",
      "        [ 0.0000,  0.7577]], requires_grad=True)\n",
      "Episode [406/500] loss: -1.33, average reward: -10.74, trajectory num: 62\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3484,  0.0000],\n",
      "        [ 0.0000,  0.7508]], requires_grad=True)\n",
      "Episode [407/500] loss: -0.44, average reward: -11.09, trajectory num: 56\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3458,  0.0000],\n",
      "        [ 0.0000,  0.7461]], requires_grad=True)\n",
      "Episode [408/500] loss: -0.54, average reward: -9.52, trajectory num: 69\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3426,  0.0000],\n",
      "        [ 0.0000,  0.7404]], requires_grad=True)\n",
      "Episode [409/500] loss: -0.37, average reward: -10.38, trajectory num: 61\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3560,  0.0000],\n",
      "        [ 0.0000,  0.7292]], requires_grad=True)\n",
      "Episode [410/500] loss: 0.03, average reward: -11.44, trajectory num: 56\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3626,  0.0000],\n",
      "        [ 0.0000,  0.7263]], requires_grad=True)\n",
      "Episode [411/500] loss: -2.29, average reward: -11.19, trajectory num: 57\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3408,  0.0000],\n",
      "        [ 0.0000,  0.7058]], requires_grad=True)\n",
      "Episode [412/500] loss: -0.57, average reward: -10.63, trajectory num: 61\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3523,  0.0000],\n",
      "        [ 0.0000,  0.6921]], requires_grad=True)\n",
      "Episode [413/500] loss: -2.16, average reward: -10.27, trajectory num: 60\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3260,  0.0000],\n",
      "        [ 0.0000,  0.6744]], requires_grad=True)\n",
      "Episode [414/500] loss: 0.19, average reward: -9.88, trajectory num: 64\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3400,  0.0000],\n",
      "        [ 0.0000,  0.6704]], requires_grad=True)\n",
      "Episode [415/500] loss: -0.69, average reward: -10.18, trajectory num: 61\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3322,  0.0000],\n",
      "        [ 0.0000,  0.6641]], requires_grad=True)\n",
      "Episode [416/500] loss: -2.44, average reward: -11.90, trajectory num: 49\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3019,  0.0000],\n",
      "        [ 0.0000,  0.6426]], requires_grad=True)\n",
      "Episode [417/500] loss: -0.65, average reward: -12.76, trajectory num: 47\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2884,  0.0000],\n",
      "        [ 0.0000,  0.6388]], requires_grad=True)\n",
      "Episode [418/500] loss: -1.69, average reward: -11.47, trajectory num: 49\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2780,  0.0000],\n",
      "        [ 0.0000,  0.6171]], requires_grad=True)\n",
      "Episode [419/500] loss: -1.52, average reward: -10.09, trajectory num: 57\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2688,  0.0000],\n",
      "        [ 0.0000,  0.5967]], requires_grad=True)\n",
      "Episode [420/500] loss: -0.68, average reward: -12.07, trajectory num: 42\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2958,  0.0000],\n",
      "        [ 0.0000,  0.5731]], requires_grad=True)\n",
      "Episode [421/500] loss: -2.35, average reward: -11.76, trajectory num: 45\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2837,  0.0000],\n",
      "        [ 0.0000,  0.5385]], requires_grad=True)\n",
      "Episode [422/500] loss: 0.53, average reward: -9.10, trajectory num: 66\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3126,  0.0000],\n",
      "        [ 0.0000,  0.5330]], requires_grad=True)\n",
      "Episode [423/500] loss: -1.14, average reward: -9.27, trajectory num: 62\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2887,  0.0000],\n",
      "        [ 0.0000,  0.5258]], requires_grad=True)\n",
      "Episode [424/500] loss: -1.68, average reward: -8.43, trajectory num: 70\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2925,  0.0000],\n",
      "        [ 0.0000,  0.4917]], requires_grad=True)\n",
      "Episode [425/500] loss: -1.00, average reward: -11.31, trajectory num: 46\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2734,  0.0000],\n",
      "        [ 0.0000,  0.4827]], requires_grad=True)\n",
      "Episode [426/500] loss: -4.57, average reward: -17.52, trajectory num: 26\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2038,  0.0000],\n",
      "        [ 0.0000,  0.4278]], requires_grad=True)\n",
      "Episode [427/500] loss: 0.84, average reward: -8.25, trajectory num: 63\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2235,  0.0000],\n",
      "        [ 0.0000,  0.4380]], requires_grad=True)\n",
      "Episode [428/500] loss: -0.37, average reward: -8.33, trajectory num: 66\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2183,  0.0000],\n",
      "        [ 0.0000,  0.4323]], requires_grad=True)\n",
      "Episode [429/500] loss: -0.28, average reward: -8.63, trajectory num: 62\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2399,  0.0000],\n",
      "        [ 0.0000,  0.4149]], requires_grad=True)\n",
      "Episode [430/500] loss: -1.20, average reward: -12.83, trajectory num: 36\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2363,  0.0000],\n",
      "        [ 0.0000,  0.3882]], requires_grad=True)\n",
      "Episode [431/500] loss: -0.70, average reward: -8.96, trajectory num: 57\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2205,  0.0000],\n",
      "        [ 0.0000,  0.3800]], requires_grad=True)\n",
      "Episode [432/500] loss: 1.87, average reward: -7.58, trajectory num: 70\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2658,  0.0000],\n",
      "        [ 0.0000,  0.4026]], requires_grad=True)\n",
      "Episode [433/500] loss: -0.55, average reward: -7.49, trajectory num: 77\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2537,  0.0000],\n",
      "        [ 0.0000,  0.3970]], requires_grad=True)\n",
      "Episode [434/500] loss: -0.62, average reward: -9.14, trajectory num: 55\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2560,  0.0000],\n",
      "        [ 0.0000,  0.3800]], requires_grad=True)\n",
      "Episode [435/500] loss: -1.11, average reward: -8.10, trajectory num: 64\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2372,  0.0000],\n",
      "        [ 0.0000,  0.3636]], requires_grad=True)\n",
      "Episode [436/500] loss: -0.19, average reward: -7.75, trajectory num: 67\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2117,  0.0000],\n",
      "        [ 0.0000,  0.3751]], requires_grad=True)\n",
      "Episode [437/500] loss: -0.90, average reward: -7.24, trajectory num: 75\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2182,  0.0000],\n",
      "        [ 0.0000,  0.3475]], requires_grad=True)\n",
      "Episode [438/500] loss: -0.31, average reward: -8.89, trajectory num: 55\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2042,  0.0000],\n",
      "        [ 0.0000,  0.3474]], requires_grad=True)\n",
      "Episode [439/500] loss: -1.31, average reward: -9.55, trajectory num: 47\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1847,  0.0000],\n",
      "        [ 0.0000,  0.3213]], requires_grad=True)\n",
      "Episode [440/500] loss: -0.87, average reward: -8.22, trajectory num: 58\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1456,  0.0000],\n",
      "        [ 0.0000,  0.3166]], requires_grad=True)\n",
      "Episode [441/500] loss: -0.08, average reward: -7.36, trajectory num: 67\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1663,  0.0000],\n",
      "        [ 0.0000,  0.3046]], requires_grad=True)\n",
      "Episode [442/500] loss: -0.94, average reward: -7.55, trajectory num: 64\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1582,  0.0000],\n",
      "        [ 0.0000,  0.2784]], requires_grad=True)\n",
      "Episode [443/500] loss: -1.01, average reward: -8.30, trajectory num: 52\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1390,  0.0000],\n",
      "        [ 0.0000,  0.2532]], requires_grad=True)\n",
      "Episode [444/500] loss: -3.41, average reward: -20.99, trajectory num: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0432,  0.0000],\n",
      "        [ 0.0000,  0.1718]], requires_grad=True)\n",
      "Episode [445/500] loss: 0.16, average reward: -16.53, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1355,  0.0000],\n",
      "        [ 0.0000,  0.1568]], requires_grad=True)\n",
      "Episode [446/500] loss: -2.20, average reward: -20.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0956,  0.0000],\n",
      "        [ 0.0000,  0.0510]], requires_grad=True)\n",
      "Episode [447/500] loss: -0.38, average reward: -17.18, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2200,  0.0000],\n",
      "        [ 0.0000, -0.2508]], requires_grad=True)\n",
      "Episode [448/500] loss: -0.71, average reward: -7.97, trajectory num: 67\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2077,  0.0000],\n",
      "        [ 0.0000, -0.2333]], requires_grad=True)\n",
      "Episode [449/500] loss: -1.18, average reward: -7.81, trajectory num: 67\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1505,  0.0000],\n",
      "        [ 0.0000, -0.2337]], requires_grad=True)\n",
      "Episode [450/500] loss: -0.11, average reward: -10.84, trajectory num: 39\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1264,  0.0000],\n",
      "        [ 0.0000, -0.2445]], requires_grad=True)\n",
      "Episode [451/500] loss: -0.18, average reward: -9.19, trajectory num: 51\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1123,  0.0000],\n",
      "        [ 0.0000, -0.2442]], requires_grad=True)\n",
      "Episode [452/500] loss: -0.05, average reward: -9.65, trajectory num: 48\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1292,  0.0000],\n",
      "        [ 0.0000, -0.2344]], requires_grad=True)\n",
      "Episode [453/500] loss: -1.60, average reward: -8.42, trajectory num: 54\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0873,  0.0000],\n",
      "        [ 0.0000, -0.1897]], requires_grad=True)\n",
      "Episode [454/500] loss: -0.02, average reward: -10.49, trajectory num: 35\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1046,  0.0000],\n",
      "        [ 0.0000, -0.1796]], requires_grad=True)\n",
      "Episode [455/500] loss: -0.89, average reward: -8.63, trajectory num: 48\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0122,  0.0000],\n",
      "        [ 0.0000, -0.1846]], requires_grad=True)\n",
      "Episode [456/500] loss: -0.77, average reward: -16.88, trajectory num: 16\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1853,  0.0000],\n",
      "        [ 0.0000, -0.1557]], requires_grad=True)\n",
      "Episode [457/500] loss: -3.84, average reward: -24.07, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1885, 0.0000],\n",
      "        [0.0000, 0.0932]], requires_grad=True)\n",
      "Episode [458/500] loss: -0.26, average reward: -23.43, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1893, 0.0000],\n",
      "        [0.0000, 0.0646]], requires_grad=True)\n",
      "Episode [459/500] loss: -1.72, average reward: -23.24, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.1464,  0.0000],\n",
      "        [ 0.0000, -0.0726]], requires_grad=True)\n",
      "Episode [460/500] loss: -3.50, average reward: -19.60, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0677,  0.0000],\n",
      "        [ 0.0000, -0.0250]], requires_grad=True)\n",
      "Episode [461/500] loss: -0.66, average reward: -15.48, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[ 0.0387,  0.0000],\n",
      "        [ 0.0000, -0.0388]], requires_grad=True)\n",
      "Episode [462/500] loss: -2.83, average reward: -15.46, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2622,  0.0000],\n",
      "        [ 0.0000,  0.3746]], requires_grad=True)\n",
      "Episode [463/500] loss: -5.37, average reward: -34.59, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1156,  0.0000],\n",
      "        [ 0.0000,  0.3345]], requires_grad=True)\n",
      "Episode [464/500] loss: -1.01, average reward: -32.45, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0281,  0.0000],\n",
      "        [ 0.0000,  0.3345]], requires_grad=True)\n",
      "Episode [465/500] loss: -2.65, average reward: -27.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4538, 0.0000],\n",
      "        [0.0000, 0.2970]], requires_grad=True)\n",
      "Episode [466/500] loss: -3.32, average reward: -38.33, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.4277, 0.0000],\n",
      "        [0.0000, 0.2250]], requires_grad=True)\n",
      "Episode [467/500] loss: -3.97, average reward: -34.84, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3572, 0.0000],\n",
      "        [0.0000, 0.1830]], requires_grad=True)\n",
      "Episode [468/500] loss: -2.48, average reward: -32.89, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.3252, 0.0000],\n",
      "        [0.0000, 0.1105]], requires_grad=True)\n",
      "Episode [469/500] loss: -4.09, average reward: -26.84, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1733, 0.0000],\n",
      "        [0.0000, 0.1880]], requires_grad=True)\n",
      "Episode [470/500] loss: -4.47, average reward: -23.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0621, 0.0000],\n",
      "        [0.0000, 0.0543]], requires_grad=True)\n",
      "Episode [471/500] loss: 0.21, average reward: -7.15, trajectory num: 51\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.1047, 0.0000],\n",
      "        [0.0000, 0.0421]], requires_grad=True)\n",
      "Episode [472/500] loss: -0.81, average reward: -16.33, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[0.0059, 0.0000],\n",
      "        [0.0000, 0.0985]], requires_grad=True)\n",
      "Episode [473/500] loss: -2.16, average reward: -16.90, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4003,  0.0000],\n",
      "        [ 0.0000, -0.0906]], requires_grad=True)\n",
      "Episode [474/500] loss: -4.23, average reward: -30.06, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3595,  0.0000],\n",
      "        [ 0.0000,  0.1928]], requires_grad=True)\n",
      "Episode [475/500] loss: -3.32, average reward: -32.01, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3265,  0.0000],\n",
      "        [ 0.0000,  0.0831]], requires_grad=True)\n",
      "Episode [476/500] loss: -4.10, average reward: -24.73, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2502,  0.0000],\n",
      "        [ 0.0000, -0.1049]], requires_grad=True)\n",
      "Episode [477/500] loss: -3.47, average reward: -21.87, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1347,  0.0000],\n",
      "        [ 0.0000, -0.0516]], requires_grad=True)\n",
      "Episode [478/500] loss: 0.28, average reward: -6.31, trajectory num: 59\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1564,  0.0000],\n",
      "        [ 0.0000, -0.0504]], requires_grad=True)\n",
      "Episode [479/500] loss: 0.11, average reward: -6.40, trajectory num: 62\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1947,  0.0000],\n",
      "        [ 0.0000,  0.0463]], requires_grad=True)\n",
      "Episode [480/500] loss: -1.75, average reward: -17.70, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1336,  0.0000],\n",
      "        [ 0.0000, -0.0731]], requires_grad=True)\n",
      "Episode [481/500] loss: -1.45, average reward: -6.33, trajectory num: 62\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1084,  0.0000],\n",
      "        [ 0.0000,  0.0779]], requires_grad=True)\n",
      "Episode [482/500] loss: -0.52, average reward: -6.39, trajectory num: 59\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0944,  0.0000],\n",
      "        [ 0.0000,  0.0299]], requires_grad=True)\n",
      "Episode [483/500] loss: -0.06, average reward: -5.87, trajectory num: 60\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1336,  0.0000],\n",
      "        [ 0.0000, -0.1083]], requires_grad=True)\n",
      "Episode [484/500] loss: -2.99, average reward: -18.92, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0486,  0.0000],\n",
      "        [ 0.0000,  0.0621]], requires_grad=True)\n",
      "Episode [485/500] loss: -0.38, average reward: -7.14, trajectory num: 43\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0595,  0.0000],\n",
      "        [ 0.0000, -0.0059]], requires_grad=True)\n",
      "Episode [486/500] loss: -0.59, average reward: -6.96, trajectory num: 38\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1070,  0.0000],\n",
      "        [ 0.0000,  1.2599]], requires_grad=True)\n",
      "Episode [487/500] loss: -5.62, average reward: -20.84, trajectory num: 34\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.0103,  0.0000],\n",
      "        [ 0.0000,  1.2237]], requires_grad=True)\n",
      "Episode [488/500] loss: -2.10, average reward: -21.95, trajectory num: 30\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4254,  0.0000],\n",
      "        [ 0.0000,  1.2027]], requires_grad=True)\n",
      "Episode [489/500] loss: 2.76, average reward: -51.30, trajectory num: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4634,  0.0000],\n",
      "        [ 0.0000,  1.2121]], requires_grad=True)\n",
      "Episode [490/500] loss: 2.07, average reward: -56.42, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4498,  0.0000],\n",
      "        [ 0.0000,  1.2344]], requires_grad=True)\n",
      "Episode [491/500] loss: 0.54, average reward: -52.41, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3847,  0.0000],\n",
      "        [ 0.0000,  1.2626]], requires_grad=True)\n",
      "Episode [492/500] loss: -4.14, average reward: -54.37, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.4311,  0.0000],\n",
      "        [ 0.0000,  1.2156]], requires_grad=True)\n",
      "Episode [493/500] loss: -11.44, average reward: -54.85, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3581,  0.0000],\n",
      "        [ 0.0000,  1.1475]], requires_grad=True)\n",
      "Episode [494/500] loss: -0.44, average reward: -52.33, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3859,  0.0000],\n",
      "        [ 0.0000,  1.1350]], requires_grad=True)\n",
      "Episode [495/500] loss: -6.45, average reward: -47.96, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2933,  0.0000],\n",
      "        [ 0.0000,  1.1097]], requires_grad=True)\n",
      "Episode [496/500] loss: -5.68, average reward: -47.93, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.2032,  0.0000],\n",
      "        [ 0.0000,  1.0825]], requires_grad=True)\n",
      "Episode [497/500] loss: -4.80, average reward: -44.22, trajectory num: 14\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.1367,  0.0000],\n",
      "        [ 0.0000,  1.0507]], requires_grad=True)\n",
      "Episode [498/500] loss: 0.76, average reward: -39.04, trajectory num: 15\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3965,  0.0000],\n",
      "        [ 0.0000,  1.0239]], requires_grad=True)\n",
      "Episode [499/500] loss: 0.76, average reward: -18.69, trajectory num: 38\n",
      "TODO: sigma:  Parameter containing:\n",
      "tensor([[-0.3914,  0.0000],\n",
      "        [ 0.0000,  1.0333]], requires_grad=True)\n",
      "Episode [500/500] loss: -1.64, average reward: -20.82, trajectory num: 36\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('modified_gym_env:ReacherPyBulletEnv-v1', rand_init=False)\n",
    "# env.render()\n",
    "# TODO: test\n",
    "state = env.reset()\n",
    "print(state)\n",
    "\n",
    "# setup network\n",
    "policy_network = PolicyNetwork(env).to(device)\n",
    "average_reward_list, average_step_list = reinforce_with_baseline(env, policy_network,batch_size=2000, num_episodes=500,\n",
    "                                              lr=0.01, gamma=0.9, enable_baseline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(average_reward_list)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('average reward')\n",
    "plt.title('Question 2 Average Rewards at Each Iteration')\n",
    "plt.savefig('Question_2.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(average_step_list)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('average step')\n",
    "plt.title('Question 2 Average Steps at Each Iteration')\n",
    "plt.savefig('Question_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p2_policy.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(policy_network, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir=/Users/xumw1996/anaconda3/lib/python3.7/site-packages/pybullet_envs/bullet\n",
      "options= \n",
      "action:  tensor([-1.0000, -1.0000], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-1.0000, -0.9999], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-1.0000, -0.9992], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-1.0000, -0.9764], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-1.0000, -0.0418], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-1.0000,  0.6780], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-1.0000,  0.3195], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.9920,  0.2254], grad_fn=<TanhBackward>)\n",
      "action:  tensor([0.7718, 0.0472], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.0984,  0.7375], grad_fn=<TanhBackward>)\n",
      "action:  tensor([ 0.9911, -0.3658], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.2056,  0.8954], grad_fn=<TanhBackward>)\n",
      "action:  tensor([ 0.9967, -0.4595], grad_fn=<TanhBackward>)\n",
      "action:  tensor([0.0110, 0.8948], grad_fn=<TanhBackward>)\n",
      "action:  tensor([ 0.9917, -0.4209], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.2975,  0.8221], grad_fn=<TanhBackward>)\n",
      "action:  tensor([ 0.9899, -0.5644], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.4611,  0.7365], grad_fn=<TanhBackward>)\n",
      "action:  tensor([ 0.9812, -0.5065], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.4029,  0.5240], grad_fn=<TanhBackward>)\n",
      "action:  tensor([ 0.9313, -0.3513], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.5421,  0.2583], grad_fn=<TanhBackward>)\n",
      "action:  tensor([ 0.8657, -0.1522], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.4757,  0.0373], grad_fn=<TanhBackward>)\n",
      "action:  tensor([0.7463, 0.0224], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.4184, -0.0968], grad_fn=<TanhBackward>)\n",
      "action:  tensor([0.6474, 0.1107], grad_fn=<TanhBackward>)\n",
      "action:  tensor([-0.3724, -0.1459], grad_fn=<TanhBackward>)\n",
      "Finished in 28 steps\n"
     ]
    }
   ],
   "source": [
    "# load policy\n",
    "with open('p2_policy.pkl', 'rb') as pickle_file:\n",
    "    policy_network = pickle.load(pickle_file)\n",
    "\n",
    "# test policy\n",
    "env = gym.make('modified_gym_env:ReacherPyBulletEnv-v1', rand_init=False)\n",
    "env.render()\n",
    "state = env.reset()\n",
    "done = False\n",
    "steps = 0\n",
    "time.sleep(5)\n",
    "\n",
    "while not done:\n",
    "    # TODO: do not sample here\n",
    "    action, log_prob = choose_action(policy_network, state, eval_policy=True)\n",
    "    state_next, reward, done, _ = env.step(action)\n",
    "    steps += 1\n",
    "    state = state_next\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print('Finished in {} steps'.format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
